{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dksifoua/Question-Answering/blob/master/1%20-%20DrQA%2C%20Document%20reader%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMGpLvYNKR78",
    "outputId": "a44642e8-e103-4b7c-eb0f-625a56ebe146",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  5 13:25:02 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.01    Driver Version: 516.01       CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:08:00.0  On |                  N/A |\r\n",
      "|  0%   39C    P8    16W / 170W |    675MiB / 12288MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lP-9tyjdylTg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Bm6QVw_hzHB7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tqdm --upgrade >> /dev/null 2>&1\n",
    "# !pip install spacy --upgrade >> /dev/null 2>&1\n",
    "# !python -m spacy download en_core_web_lg >> /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bJQv4DSelwnB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import tqdm\n",
    "import spacy\n",
    "import pickle\n",
    "import random\n",
    "import string\n",
    "import itertools\n",
    "import functools\n",
    "import collections\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.tokens import Doc\n",
    "from typing import Any, Dict, List, NamedTuple, Union, Tuple\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /mnt/c/Users/dimit/PycharmProjects/Question-Answering/notebooks\n",
      "New current working directory: /mnt/c/Users/dimit/PycharmProjects/Question-Answering\n"
     ]
    }
   ],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "print(f\"Current working directory: {current_working_directory}\")\n",
    "\n",
    "if current_working_directory.split('/')[-1] == \"notebooks\":\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "print(f\"New current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    # torch.use_deterministic_algorithms(True)\n",
    "    # torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cw16-fZCDHHu",
    "outputId": "29d412de-e92b-46dc-d61e-f679089028fc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 546\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx9pL3Hiyn7c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare data\n",
    "\n",
    "***Download data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBy3v4Pke7dq",
    "outputId": "4d0d9d8a-d05a-4d3f-b1dd-545aa92ad6f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -rf ./data\n",
    "# !mkdir ./data\n",
    "#\n",
    "# !wget --no-check-certificate \\\n",
    "#     https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n",
    "#     -O ./data/train-v1.1.json\n",
    "#\n",
    "# !wget --no-check-certificate \\\n",
    "#     https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json \\\n",
    "#     -O ./data/dev-v1.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9H59xUnyvAR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Load JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class _UnpackingDataClassMixin:\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(dataclasses.astuple(self))\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Target(_UnpackingDataClassMixin):\n",
    "    start_index: int\n",
    "    end_index: int\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class RawDatasetItem(_UnpackingDataClassMixin):\n",
    "    id_: str\n",
    "    context: Doc\n",
    "    question: Doc\n",
    "    answer: Doc\n",
    "    answer_start_index: int\n",
    "    target: Target = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IbZQjhA5roqo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IO:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_json(path: str) -> Dict:\n",
    "        try:\n",
    "            with open(path, mode='r', encoding=\"utf-8\") as json_file:\n",
    "                return json.load(json_file)\n",
    "        except IOError:\n",
    "            raise IOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqjrkTxHr3rA",
    "outputId": "aeed0ca6-a730-499b-cd3c-8f2bed254f81",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of raw train data: 442\n",
      "Length of raw valid data: 48\n",
      "CPU times: user 365 ms, sys: 88.8 ms, total: 454 ms\n",
      "Wall time: 663 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_raw_data = IO.load_from_json(path=\"./data/train-v1.1.json\")\n",
    "valid_raw_data = IO.load_from_json(path=\"./data/dev-v1.1.json\")\n",
    "print(f\"Length of raw train data: {len(train_raw_data['data']):,}\")\n",
    "print(f\"Length of raw valid data: {len(valid_raw_data['data']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4sypWlVyxx-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Parse JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "O-6GE3YxsQsl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_squad_v1_data(data: Dict, spacy_nlp: spacy.language.Language) -> List[RawDatasetItem]:\n",
    "    qas = []\n",
    "    disabled_components = [\"parser\", \"lemmatizer\", \"tagger\", \"ner\"]\n",
    "    for paragraphs in tqdm.tqdm(data[\"data\"]):\n",
    "        for paragraph in paragraphs[\"paragraphs\"]:\n",
    "            context = spacy_nlp(paragraph[\"context\"], disable=disabled_components[:1])\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                id_ = qa[\"id\"]\n",
    "                question = spacy_nlp(qa[\"question\"], disable=disabled_components)\n",
    "                for answer in qa[\"answers\"]:\n",
    "                    qas.append(RawDatasetItem(id_=id_, context=context, question=question,\n",
    "                                              answer=spacy_nlp(answer[\"text\"], disable=disabled_components),\n",
    "                                              answer_start_index=answer[\"answer_start\"]))\n",
    "    return qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MeqBr7Ov9ZU",
    "outputId": "2dad6d53-186e-41d5-dd61-0da6ac26c314",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [07:27<00:00,  1.01s/it]\n",
      "100%|██████████| 48/48 [01:22<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train qa pairs: 87,599\n",
      "Length of valid qa pairs: 34,726\n",
      "Train example: RawDatasetItem(id_='56cc100b6d243a140015ee8d', context=During the summers at Nohant, particularly in the years 1839–43, Chopin found quiet, productive days during which he composed many works, including his Polonaise in A-flat major, Op. 53. Among the visitors to Nohant were Delacroix and the mezzo-soprano Pauline Viardot, whom Chopin had advised on piano technique and composition. Delacroix gives an account of staying at Nohant in a letter of 7 June 1842:, question=On what date did Delacroix write a letter based on his visit at Nohant?, answer=7 June 1842, answer_start_index=393, target=None)\n",
      "CPU times: user 8min 48s, sys: 3.14 s, total: 8min 51s\n",
      "Wall time: 8min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "language = spacy.load(name=\"en_core_web_lg\")\n",
    "\n",
    "train_qas = parse_squad_v1_data(data=train_raw_data, spacy_nlp=language)\n",
    "valid_qas = parse_squad_v1_data(data=valid_raw_data, spacy_nlp=language)\n",
    "print(f\"Length of train qa pairs: {len(train_qas):,}\")\n",
    "print(f\"Length of valid qa pairs: {len(valid_qas):,}\")\n",
    "print(f\"Train example: {train_qas[random.randint(a=0, b=len(train_qas) - 1)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bafKgiFv1GHa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_answer_start_indexes(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        assert qa.answer.text == qa.context.text[qa.answer_start_index:qa.answer_start_index + len(qa.answer.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tTDTQod23-g",
    "outputId": "022c7d5f-cfbf-4b12-b4f9-e6882a9cef07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:03<00:00, 22569.21it/s]\n",
      "100%|██████████| 34726/34726 [00:01<00:00, 22675.68it/s]\n"
     ]
    }
   ],
   "source": [
    "test_answer_start_indexes(qas=train_qas)\n",
    "test_answer_start_indexes(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxhCfiNY28zs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Add targets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "k4bpqV3S27SQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_targets_to_squad_v1_data(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        for i in range(len(qa.context)):\n",
    "            if qa.context[i].idx == qa.answer_start_index:\n",
    "                answer = qa.context[i:i + len(qa.answer)]\n",
    "                qa.target = Target(start_index=answer[0].i, end_index=answer[-1].i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waJedA674CCH",
    "outputId": "84672e5a-a68e-473b-8be8-c7a2e10a0698",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:02<00:00, 39848.64it/s]\n",
      "100%|██████████| 34726/34726 [00:00<00:00, 38561.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.11 s, sys: 10.2 ms, total: 3.12 s\n",
      "Wall time: 3.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "add_targets_to_squad_v1_data(qas=train_qas)\n",
    "add_targets_to_squad_v1_data(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lT65eePm4F9w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_bad_item(qa: RawDatasetItem) -> bool:\n",
    "    \"\"\"Return True if either the target is None or target indexes don't match the answer. Return False otherwise\"\"\"\n",
    "    if qa.target is None:\n",
    "        return False\n",
    "    return qa.answer.text == qa.context[qa.target.start_index:qa.target.end_index + 1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_nUlM_n4Mgc",
    "outputId": "cde0cb35-dd18-4ba5-f4a4-a63a46ec6db7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train qa pairs after filtering out bad qa pairs: 86,676\n",
      "Length of valid qa pairs after filtering out bad qa pairs: 34,364\n",
      "CPU times: user 699 ms, sys: 66 µs, total: 699 ms\n",
      "Wall time: 698 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qas = [*filter(is_bad_item, train_qas)]\n",
    "valid_qas = [*filter(is_bad_item, valid_qas)]\n",
    "print(f\"Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}\")\n",
    "print(f\"Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qKEhn4eI4P5B",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_targets(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in qas:\n",
    "        assert qa.answer.text == qa.context[qa.target.start_index:qa.target.end_index + 1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6O_fmDJl5R7V",
    "outputId": "999e5ada-e4ec-44ae-f40c-682b08cbb7b6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 674 ms, sys: 0 ns, total: 674 ms\n",
      "Wall time: 672 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_targets(qas=train_qas)\n",
    "test_targets(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkLppZOP5Vju",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Add features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O8Y038pt5VIc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TokenFeature(_UnpackingDataClassMixin):\n",
    "    exact_match: List[bool]\n",
    "    part_of_speech: List[str]\n",
    "    named_entity_type: List[str]\n",
    "    normalized_term_frequency: List[float]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DrQARawDatasetItem(RawDatasetItem):\n",
    "    token_feature: TokenFeature = None\n",
    "\n",
    "\n",
    "def add_extra_features_squad_v1(qas: List[RawDatasetItem]) -> List[DrQARawDatasetItem]:\n",
    "    \"\"\"Add extra features: Exact Match, Part-of-Speech, Name Entity Recognition & Normalized Term Frequency\"\"\"\n",
    "    qa_token_features = []\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        question = [token.text.lower() for token in qa.question]\n",
    "        count_context_tokens = collections.Counter(map(lambda token: token.text.lower(), qa.context))\n",
    "\n",
    "        frequency_context_tokens: Dict[int, int] = {}\n",
    "        for index, token in enumerate(qa.context):  # type: int, Token\n",
    "            frequency_context_tokens[index] = count_context_tokens[token.text.lower()]\n",
    "        norm_frequency_context_tokens = sum(frequency_context_tokens.values())\n",
    "\n",
    "        token_feature = TokenFeature(\n",
    "            exact_match=[qa.context[index].text.lower() in question for index in range(len(qa.context))],\n",
    "            part_of_speech=[qa.context[index].tag_ for index in range(len(qa.context))],\n",
    "            named_entity_type=[qa.context[index].ent_type_ for index in range(len(qa.context))],\n",
    "            normalized_term_frequency=[\n",
    "                frequency_context_tokens[index] / norm_frequency_context_tokens for index in range(len(qa.context))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        qa_token_features.append(\n",
    "            DrQARawDatasetItem(\n",
    "                id_=qa.id_,\n",
    "                context=qa.context,\n",
    "                question=qa.question,\n",
    "                answer=qa.answer,\n",
    "                answer_start_index=qa.answer_start_index,\n",
    "                target=qa.target,\n",
    "                token_feature=token_feature\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return qa_token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqwcbDgPSmp8",
    "outputId": "8df2a4a8-4c18-478b-980e-16ab98a78e3a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86676/86676 [00:25<00:00, 3402.42it/s]\n",
      "100%|██████████| 34364/34364 [00:11<00:00, 2895.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 s, sys: 1.45 s, total: 37.6 s\n",
      "Wall time: 37.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qas = add_extra_features_squad_v1(qas=train_qas)\n",
    "valid_qas = add_extra_features_squad_v1(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8SrKXlfoU5y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build vocabularies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, padding_token: str, unknown_token: str):\n",
    "        self.padding_token = padding_token\n",
    "        self.unknown_token = unknown_token\n",
    "\n",
    "        self.vocabulary: List[str] = []\n",
    "        self.word2count: Dict[str, int] = {}\n",
    "        self.word2index: Dict[str, int] = {}\n",
    "        self.index2word: Dict[int, str] = {}\n",
    "\n",
    "    def build(self, data: List[Union[Doc, str]], min_word_frequency: int) -> None:\n",
    "        words = []\n",
    "\n",
    "        type_ = type(data[0])\n",
    "        if type_ == Doc:\n",
    "            for item in data:  # Doc\n",
    "                words += [word.text.lower() for word in item]\n",
    "        elif type_ == str:\n",
    "            words += data\n",
    "        else:\n",
    "            raise TypeError(f\"The type {type_} is not supported!\")\n",
    "\n",
    "        self.word2count = collections.Counter(words)\n",
    "        self.vocabulary = [self.padding_token] + sorted(filter(\n",
    "            lambda word: self.word2count[word] >= min_word_frequency,\n",
    "            self.word2count\n",
    "        )) + [self.unknown_token]  # Ensure that pad token gets index 0 and unknown token gets the las index\n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocabulary)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocabulary)}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.vocabulary)\n",
    "\n",
    "    def stoi(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        Return the index of the word in the vocabulary.\n",
    "        Return the index of the unknown token if that word doesn't exist in the vocabulary.\n",
    "        \"\"\"\n",
    "        return self.word2index.get(word, self.word2index[self.unknown_token])\n",
    "\n",
    "    def itos(self, index: int) -> str:\n",
    "        \"\"\"Return the word of the index in the vocabulary.\"\"\"\n",
    "        return self.index2word[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of id vocabulary: 97,200\n",
      "Length of text vocabulary: 26,884\n",
      "Length of part of speech vocabulary: 52\n",
      "Length of named entity type vocabulary: 21\n",
      "CPU times: user 3.21 s, sys: 481 ms, total: 3.69 s\n",
      "Wall time: 3.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PADDING_TOKEN = \"<pad>\"\n",
    "UNKNOWN_TOKEN = \"<unk>\"\n",
    "MIN_FREQUENCY = 5\n",
    "\n",
    "ids = [*map(lambda qa: qa.id_, train_qas)] + [*map(lambda qa: qa.id_, valid_qas)]\n",
    "contexts, questions = zip(*map(lambda qa: (qa.context, qa.question), train_qas))\n",
    "part_of_speeches = [*itertools.chain.from_iterable(map(lambda qa: qa.token_feature.part_of_speech, train_qas))]\n",
    "named_entity_types = [*itertools.chain.from_iterable(map(lambda qa: qa.token_feature.named_entity_type, train_qas))]\n",
    "\n",
    "id_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "text_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "part_of_speech_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "named_entity_types_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "\n",
    "id_vocabulary.build(data=[*set(ids)], min_word_frequency=0)\n",
    "text_vocabulary.build(data=[*set(contexts + questions)], min_word_frequency=MIN_FREQUENCY)\n",
    "part_of_speech_vocabulary.build(data=[*set(part_of_speeches)], min_word_frequency=0)\n",
    "named_entity_types_vocabulary.build(data=[*set(named_entity_types)], min_word_frequency=0)\n",
    "\n",
    "print(f\"Length of id vocabulary: {len(id_vocabulary):,}\")\n",
    "print(f\"Length of text vocabulary: {len(text_vocabulary):,}\")\n",
    "print(f\"Length of part of speech vocabulary: {len(part_of_speech_vocabulary):,}\")\n",
    "print(f\"Length of named entity type vocabulary: {len(named_entity_types_vocabulary):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iotg02zlAflQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class DrQATensorDatasetItem(_UnpackingDataClassMixin):\n",
    "    id_: torch.LongTensor\n",
    "    context: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]\n",
    "    question: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]\n",
    "    target: torch.LongTensor\n",
    "    exact_match: torch.LongTensor\n",
    "    part_of_speech: torch.LongTensor\n",
    "    named_entity_type: torch.LongTensor\n",
    "    normalized_term_frequency: torch.FloatTensor\n",
    "\n",
    "\n",
    "class SquadV1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: List[DrQARawDatasetItem], id_vocab: Vocabulary, text_vocab: Vocabulary,\n",
    "                 pos_vocab: Vocabulary, ner_vocab: Vocabulary):\n",
    "        self.data = data\n",
    "        self.id_vocab = id_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.text_vocab = text_vocab\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> DrQATensorDatasetItem:\n",
    "        item: DrQARawDatasetItem = self.data[idx]\n",
    "        id_ = torch.LongTensor([self.id_vocab.stoi(item.id_)])\n",
    "        context = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item.context)])\n",
    "        question = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item.question)])\n",
    "        target = torch.LongTensor([item.target.start_index, item.target.end_index])\n",
    "        exact_match = torch.LongTensor(item.token_feature.exact_match)\n",
    "        part_of_speech = torch.LongTensor(\n",
    "            [*map(lambda token: self.pos_vocab.stoi(token), item.token_feature.part_of_speech)])\n",
    "        named_entity_type = torch.LongTensor(\n",
    "            [*map(lambda token: self.ner_vocab.stoi(token), item.token_feature.named_entity_type)])\n",
    "        normalized_term_frequency = torch.FloatTensor(item.token_feature.normalized_term_frequency)\n",
    "        return DrQATensorDatasetItem(\n",
    "            id_=id_,\n",
    "            context=context,\n",
    "            question=question,\n",
    "            target=target,\n",
    "            exact_match=exact_match,\n",
    "            part_of_speech=part_of_speech,\n",
    "            named_entity_type=named_entity_type,\n",
    "            normalized_term_frequency=normalized_term_frequency\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMgSisEt8ARe",
    "outputId": "735861e8-f6c2-49bb-b8e8-7d5da12ef11a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_ shape: torch.Size([1])\n",
      "context shape: torch.Size([142])\n",
      "question shape: torch.Size([14])\n",
      "target shape: torch.Size([2])\n",
      "exact_match shape: torch.Size([142])\n",
      "part_of_speech shape: torch.Size([142])\n",
      "named_entity_type shape: torch.Size([142])\n",
      "normalized_term_frequency shape: torch.Size([142])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SquadV1Dataset(\n",
    "    data=train_qas,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    pos_vocab=part_of_speech_vocabulary,\n",
    "    ner_vocab=named_entity_types_vocabulary\n",
    ")\n",
    "valid_dataset = SquadV1Dataset(\n",
    "    data=valid_qas,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    pos_vocab=part_of_speech_vocabulary,\n",
    "    ner_vocab=named_entity_types_vocabulary\n",
    ")\n",
    "\n",
    "train_dataset_item = train_dataset[0]\n",
    "print(f\"id_ shape: {train_dataset_item.id_.shape}\")\n",
    "print(f\"context shape: {train_dataset_item.context.shape}\")\n",
    "print(f\"question shape: {train_dataset_item.question.shape}\")\n",
    "print(f\"target shape: {train_dataset_item.target.shape}\")\n",
    "print(f\"exact_match shape: {train_dataset_item.exact_match.shape}\")\n",
    "print(f\"part_of_speech shape: {train_dataset_item.part_of_speech.shape}\")\n",
    "print(f\"named_entity_type shape: {train_dataset_item.named_entity_type.shape}\")\n",
    "print(f\"normalized_term_frequency shape: {train_dataset_item.normalized_term_frequency.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZQaVaHt_MDc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build data loaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cYMYz3-SBYzf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DrQATensorDatasetBatch = DrQATensorDatasetItem\n",
    "\n",
    "def add_padding_and_batch_data(batch: List[DrQATensorDatasetItem], id_vocab: Vocabulary, text_vocab: Vocabulary,\n",
    "                               pos_vocab: Vocabulary, ner_vocab: Vocabulary, include_lengths: bool,\n",
    "                               device: torch.device) -> DrQATensorDatasetBatch:\n",
    "    batch_id = [item.id_ for item in batch]\n",
    "    batch_context = [item.context for item in batch]\n",
    "    batch_question = [item.question for item in batch]\n",
    "    batch_target = [item.target for item in batch]\n",
    "    batch_exact_match = [item.exact_match for item in batch]\n",
    "    batch_part_of_speech = [item.part_of_speech for item in batch]\n",
    "    batch_named_entity_type = [item.named_entity_type for item in batch]\n",
    "    batch_normalized_term_frequency = [item.normalized_term_frequency for item in batch]\n",
    "\n",
    "    length_context, length_question = None, None\n",
    "    if include_lengths:\n",
    "        length_context = torch.LongTensor([context.size(0) for context in batch_context])  # .to(device)\n",
    "        length_question = torch.LongTensor([question.size(0) for question in batch_question])  # .to(device)\n",
    "\n",
    "    batch_padded_id = pad_sequence(batch_id,\n",
    "                                   batch_first=True,\n",
    "                                   padding_value=id_vocab.stoi(id_vocab.padding_token)).to(device)\n",
    "    batch_padded_context = pad_sequence(batch_context,\n",
    "                                        batch_first=True,\n",
    "                                        padding_value=text_vocab.stoi(text_vocab.padding_token)).to(device)\n",
    "    batch_padded_question = pad_sequence(batch_question,\n",
    "                                         batch_first=True,\n",
    "                                         padding_value=text_vocab.stoi(text_vocab.padding_token)).to(device)\n",
    "    batch_padded_target = pad_sequence(batch_target, batch_first=True).to(device)\n",
    "    batch_padded_exact_match = pad_sequence(batch_exact_match, batch_first=True).to(device)\n",
    "    batch_padded_part_of_speech = pad_sequence(batch_part_of_speech,\n",
    "                                               batch_first=True,\n",
    "                                               padding_value=pos_vocab.stoi(pos_vocab.padding_token)).to(device)\n",
    "    batch_padded_normalized_term_frequency = pad_sequence(batch_normalized_term_frequency, batch_first=True).to(device)\n",
    "    batch_padded_named_entity_type = pad_sequence(batch_named_entity_type,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=ner_vocab.stoi(ner_vocab.padding_token)).to(device)\n",
    "    return DrQATensorDatasetBatch(\n",
    "        id_=batch_padded_id,\n",
    "        context=(batch_padded_context, length_context),\n",
    "        question=(batch_padded_question, length_question),\n",
    "        target=batch_padded_target,\n",
    "        exact_match=batch_padded_exact_match,\n",
    "        part_of_speech=batch_padded_part_of_speech,\n",
    "        named_entity_type=batch_padded_named_entity_type,\n",
    "        normalized_term_frequency=batch_padded_normalized_term_frequency\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zu2ovPqxA7Ix",
    "outputId": "02a52daa-a8ec-45de-c916-995fe7e860c4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs: torch.Size([32, 1])\n",
      "Context: torch.Size([32, 253]) torch.Size([32])\n",
      "Question: torch.Size([32, 19]) torch.Size([32])\n",
      "Target: torch.Size([32, 2])\n",
      "Exact match: torch.Size([32, 253])\n",
      "Part of speech: torch.Size([32, 253])\n",
      "Named entity type: torch.Size([32, 253])\n",
      "Normalized term frequency: torch.Size([32, 253])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "collate_function = functools.partial(add_padding_and_batch_data,\n",
    "                                     id_vocab=id_vocabulary,\n",
    "                                     text_vocab=text_vocabulary,\n",
    "                                     pos_vocab=part_of_speech_vocabulary,\n",
    "                                     ner_vocab=named_entity_types_vocabulary,\n",
    "                                     include_lengths=True,\n",
    "                                     device=DEVICE)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_function)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_function)\n",
    "\n",
    "for batch in train_dataloader:  # type: DrQATensorDatasetBatch\n",
    "    print(\"IDs:\", batch.id_.shape)\n",
    "    print(\"Context:\", batch.context[0].shape, batch.context[1].shape)\n",
    "    print(\"Question:\", batch.question[0].shape, batch.question[1].shape)\n",
    "    print(\"Target:\", batch.target.shape)\n",
    "    print(\"Exact match:\", batch.exact_match.shape)\n",
    "    print(\"Part of speech:\", batch.part_of_speech.shape)\n",
    "    print(\"Named entity type:\", batch.named_entity_type.shape)\n",
    "    print(\"Normalized term frequency:\", batch.normalized_term_frequency.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2O79r_CLvGu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Download pretrained GloVe embedding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrSXYalOmRak",
    "outputId": "bc303808-01ad-4f75-c884-0a337681eb7b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# !wget --no-check-certificate \\\n",
    "#     http://nlp.stanford.edu/data/glove.840B.300d.zip \\\n",
    "#     -O ./data/glove.840B.300d.zip\n",
    "# !unzip -q ./data/glove.840B.300d.zip -d ./data\n",
    "# !rm -r ./data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BL0JZuEmmf5C",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def load_glove_embeddings(path: str) -> Dict[str, np.ndarray]:\n",
    "#     glove_embeddings = {}\n",
    "#     try:\n",
    "#         file = open(path, mode='r', encoding=\"utf-8\")\n",
    "#         for line in tqdm.tqdm(file):\n",
    "#             values = line.split(' ')\n",
    "#             glove_embeddings[values[0]] = np.asarray(values[1:], dtype=\"float32\")\n",
    "#         return glove_embeddings\n",
    "#     except IOError:\n",
    "#         raise IOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDX8b2EJm1uZ",
    "outputId": "c477bc5e-4b5f-4880-8916-fa53fd7ef300",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# glove = load_glove_embeddings(path=\"./data/glove.840B.300d.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# text_vocabulary.word2count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ELVYepbbm7ny",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def extract_embeddings(glove_embeddings: Dict[str, np.ndarray], text_vocab: Vocabulary, embedding_size: int, most_common: int) -> Tuple[np.ndarray, int, List[int]]:\n",
    "#     most_common_words = [*map(lambda x: x[0], text_vocab.word2count.most_common(most_common))]\n",
    "#     most_common_words = [*filter(lambda word: word in text_vocab.vocabulary, most_common_words)]\n",
    "#     embedding_matrix = np.zeros((len(text_vocab), embedding_size))\n",
    "#     most_common_indexes, n_words = [], 0\n",
    "#     for index, word in enumerate(text_vocab.vocabulary):\n",
    "#         if word in most_common_words:\n",
    "#             most_common_indexes.append(index)\n",
    "#         try:\n",
    "#             embedding_matrix[index] = glove[word]\n",
    "#             n_words += 1\n",
    "#         except KeyError:\n",
    "#             pass\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#     return embedding_matrix, n_words, most_common_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3CUDosl_n5HA",
    "outputId": "ce6edfc0-2a4e-41ba-dc6d-8ddf703b6501",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embedding_matrix, n_words, most_common_indexes = extract_embeddings(glove_embeddings=glove, text_vocab=text_vocabulary, embedding_size=300, most_common=1000)\n",
    "# print(f\"Words found: {n_words}/{len(text_vocabulary)}\")\n",
    "# np.save(\"../data/GloVe_DrQA.npy\", embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# n_words = 0\n",
    "# for word in tqdm.tqdm(text_vocabulary.vocabulary, total=len(text_vocabulary.vocabulary)):\n",
    "#     if nlp(word).has_vector:\n",
    "#         n_words += 1\n",
    "# print(f\"Words found: {n_words}/{len(text_vocabulary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "JZzbAOFAmfnT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Free up the RAM\n",
    "# del glove\n",
    "# del embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxnYdks-L31E",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeling\n",
    "\n",
    "***Stacked Bidirectional LSTM Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DoHYvqQQCEGw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StackedBiLSTMsLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size: int, hidden_size: int, n_layers: int, dropout: float):\n",
    "        \"\"\"\n",
    "        :param embedding_size: Size of word embedding.\n",
    "        :param hidden_size: Hidden size of lstm layers.\n",
    "        :param n_layers: Number of layers.\n",
    "        :param dropout: Dropout value in [0, 1).\n",
    "        \"\"\"\n",
    "        super(StackedBiLSTMsLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=embedding_size if i == 0 else hidden_size * 2, hidden_size=hidden_size,\n",
    "                batch_first=True, num_layers=n_layers, bidirectional=True\n",
    "            ) for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def __forward_lstm(self, layer: nn.Module, inputs: Tensor, lengths: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        :param layer: LSTM layer.\n",
    "        :param inputs: Sequence inputs. FloatTensor[batch_size, seq_len, embedding_size|hidden_size * 2]\n",
    "        :param lengths: Sequence lengths. LongTensor[batch_size,]\n",
    "        :return:\n",
    "            padded_outputs FloatTensor[batch_size, seq_len, hidden_size * 2]\n",
    "            outputs_lengths LongTensor[batch_size,]\n",
    "        \"\"\"\n",
    "        seq_len = inputs.size(1)\n",
    "        inputs = self.dropout(inputs)\n",
    "        packed_inputs = pack_padded_sequence(input=inputs, lengths=lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_outputs, _ = layer(packed_inputs)\n",
    "        padded_outputs, outputs_lengths = pad_packed_sequence(sequence=packed_outputs,\n",
    "                                                              batch_first=True,\n",
    "                                                              total_length=seq_len)\n",
    "        return padded_outputs, outputs_lengths\n",
    "\n",
    "    def forward(self, embedded_inputs: Tensor, sequence_lengths: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param embedded_inputs: Sequence inputs. FloatTensor[batch_size, seq_len, embedding_size]\n",
    "        :param sequence_lengths: Sequence lengths. LongTensor[batch_size,]\n",
    "        :return: FloatTensor[batch_size, sequence_lengths, n_layers * hidden_size * 2]\n",
    "        \"\"\"\n",
    "        outputs, lens = [embedded_inputs], sequence_lengths\n",
    "        for lstm_layer in self.lstm_layers:\n",
    "            out, lens = self.__forward_lstm(layer=lstm_layer, inputs=outputs[-1], lengths=lens)\n",
    "            outputs.append(out)\n",
    "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oazq30eW3_T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Aligned Question Embedding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ATOQC6-pWzq_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlignedQuestionEmbeddingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size: int, hidden_size: int):\n",
    "        \"\"\"\n",
    "        Aligned Question Embedding\n",
    "        $$f_{align}(p_i) = \\sum_j a_{i, j}E(q_j)$$\n",
    "        where the attention score $a_{i, j}$ captures the similarity between $p_i$ and each question words $q_j$.\n",
    "        Specifically, $a_{i, j}$ is computed by the dot products between nonlinear mappings of word embeddings:\n",
    "        $$a_{i, j} = \\frac{exp(\\alpha(E(p_i)).\\alpha(E(q_j)))}{\\sum_{j'}exp(\\alpha(E(p_i)).\\alpha(E(q_{j'})))}$$,\n",
    "        and $\\alpha(.)$ is a single dense layer with ReLU non-linearity. Compared to the exact match features, these\n",
    "        features add soft alignments between similar but non-identical words (e.g., car and vehicle)\n",
    "\n",
    "        :param embedding_size: Size of word embedding.\n",
    "        :param hidden_size: Hidden size of the dense layer.\n",
    "        \"\"\"\n",
    "        super(AlignedQuestionEmbeddingLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.dense = nn.Linear(in_features=embedding_size, out_features=hidden_size)\n",
    "\n",
    "    def forward(self, context_sequence: Tensor, question_sequence: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param context_sequence: Sequence context inputs. FloatTensor[batch_size, ctx_seq_len, embedding_size]\n",
    "        :param question_sequence: Sequence question inputs. FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, ctx_seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        context_logits = F.relu(self.dense(context_sequence))  # [batch_size, ctx_seq_len, hidden_size]\n",
    "        question_logits = F.relu(self.dense(question_sequence))  # [batch_size, qst_seq_len, hidden_size]\n",
    "        scores = torch.bmm(context_logits, question_logits.transpose(-1, -2))  # [batch_size, ctx_seq_len, qst_seq_len]\n",
    "        # Mask scores in order to force attention weights corresponding to padding tokens to be 0.\n",
    "        scores = scores.masked_fill(question_mask.unsqueeze(1) == 0, float(\"-inf\"))\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # [batch_size, ctx_seq_len, qst_seq_len]\n",
    "        return torch.bmm(attention_weights, question_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImX8ayztYjsK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Question Encoding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Whil-FgVYhgy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionEncodingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size: int, hidden_size: int, n_layers: int, dropout: float):\n",
    "        \"\"\"\n",
    "        The question encoding consists of applying a recurrent neural network on top of the word embeddings of $q_i$\n",
    "        and combine the resulting hidden units into one single vector: $\\{q_1, ..., q_l\\} \\rightarrow q$. We compute\n",
    "        $q = \\sum_j{b_j q_j}$ where $b_j$ encodes the importance of each question word:\n",
    "        $$b_j = \\frac{exp(w.q_j)}{\\sum_{j'}{exp(w.q_{j'})}}$$\n",
    "        and $w$ is a weight vector to learn\n",
    "\n",
    "        :param embedding_size:\n",
    "        :param hidden_size:\n",
    "        :param n_layers:\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super(QuestionEncodingLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.stacked_bilstm_layers = StackedBiLSTMsLayer(\n",
    "            embedding_size=embedding_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout\n",
    "        )\n",
    "        self.dense = nn.Linear(in_features=embedding_size, out_features=1, bias=False)\n",
    "\n",
    "    def __linear_self_attention(self, question_embedded: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param question_embedded: FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, qst_seq_len]\n",
    "        \"\"\"\n",
    "        scores = self.dense(question_embedded).squeeze(-1)  # [batch_size, qst_seq_len]\n",
    "        scores = scores.masked_fill(question_mask == 0, float(\"-inf\"))\n",
    "        return F.softmax(scores, dim=-1)\n",
    "\n",
    "    def forward(self, question_embedded: Tensor, question_lengths: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param question_embedded: FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_lengths: Sequence question lengths. LongTensor[batch_size,]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, n_layers * hidden_size * 2]\n",
    "        \"\"\"\n",
    "        lstm_outputs = self.stacked_bilstm_layers(embedded_inputs=question_embedded, sequence_lengths=question_lengths)\n",
    "        # lstm_outputs: [batch_size, qst_seq_len, n_layers * hidden_size * 2]\n",
    "        attention_weights = self.__linear_self_attention(\n",
    "            question_embedded=question_embedded, question_mask=question_mask\n",
    "        )  # [batch_size, qst_seq_len]\n",
    "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hFIZnmUaFAu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***BiLinear Attention Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "JZGOH3IhaEZw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BiLinearAttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, context_hidden_size: int, question_hidden_size: int):\n",
    "        \"\"\"\n",
    "        At the paragraph level, the goal is to predict the span of tokens that is most likely the correct answer.\n",
    "        We take the paragraph vectors $\\{p_1, ... , p_m\\}$ and the question vector $q$ as input, and simply train two\n",
    "        classifiers independently for predicting the two ends of the span.\n",
    "        Concretely, we use a bi-linear term to capture the similarity between $p_i$ and $q$ and compute the\n",
    "        probabilities of each token being start and end as:\n",
    "        $$\n",
    "        P_{start}(i) \\propto exp(p_i W_s q) \\\\\n",
    "        P_{end}(i) \\propto exp(p_i W_e q)\n",
    "        $$\n",
    "\n",
    "        :param context_hidden_size:\n",
    "        :param question_hidden_size:\n",
    "        \"\"\"\n",
    "        super(BiLinearAttentionLayer, self).__init__()\n",
    "        self.context_hidden_size = context_hidden_size\n",
    "        self.question_hidden_size = question_hidden_size\n",
    "\n",
    "        self.dense = nn.Linear(in_features=question_hidden_size, out_features=context_hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, context_encoded: Tensor, question_encoded: Tensor, context_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param context_encoded: FloatTensor[batch_size, ctx_seq_len, ctx_hid_size]\n",
    "        :param question_encoded: FloatTensor[batch_size, qst_seq_len]\n",
    "        :param context_mask: IntTensor[batch_size, ctx_seq_len]\n",
    "        :return FloatTensor[batch_size, ctx_seq_len]\n",
    "        \"\"\"\n",
    "        question_encoded = self.dense(question_encoded)  # [batch_size, ctx_hid_size]\n",
    "        scores = torch.bmm(context_encoded, question_encoded.unsqueeze(-1)).squeeze(-1)  # [batch_size, ctx_seq_len]\n",
    "        return scores.masked_fill(context_mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzrmk6D7agHH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Document reader Question Answering Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "qlZlTFXOae_o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "    def make_sequence_mask(self, input_sequence: Tensor) -> Tensor:\n",
    "        return input_sequence != self.padding_index\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(starts: Tensor, ends: Tensor) -> Tuple[List[int], List[int], List[float]]:\n",
    "        \"\"\"\n",
    "        :param starts: FloatTensor[batch_size, ctx_seq_len]\n",
    "        :param ends: FloatTensor[batch_size, ctx_seq_len]\n",
    "        :return: Tuple[List[int], List[int], List[float]]\n",
    "        \"\"\"\n",
    "        start_indexes, end_indexes, predicted_probabilities = [], [], []\n",
    "        for i in range(starts.size(0)):\n",
    "            probabilities = torch.ger(starts[i], ends[i])  # [ctx_seq_len, ctx_seq_len]\n",
    "            probability, index = torch.topk(probabilities.view(-1), k=1)\n",
    "\n",
    "            start_indexes.append(index.tolist()[0] // probabilities.size(0))\n",
    "            end_indexes.append(index.tolist()[0] % probabilities.size(1))\n",
    "\n",
    "            predicted_probabilities.append(probability.tolist()[0])\n",
    "\n",
    "        return start_indexes, end_indexes, predicted_probabilities\n",
    "\n",
    "    def count_parameters(self) -> int:\n",
    "        return sum(parameter.numel() for parameter in self.parameters() if parameter.requires_grad)\n",
    "\n",
    "\n",
    "class DrQA(BaseModel):\n",
    "    \n",
    "    def __init__(self, vocabulary_size: int, embedding_size, n_extra_features: int, hidden_size: int, n_layers: int,\n",
    "                 dropout: float, padding_index: int):\n",
    "        \"\"\"\n",
    "        During prediction, we choose the best span from token $i$ to token $i'$ such that $i ≤ i' ≤ i + 15$ and\n",
    "        $P_{start}(i)×P_{end}(i')$ is maximized. To make score compatible across paragraphs in one or several retrieved\n",
    "        documents, we use the un-normalized exponential and take argmax over all considered paragraph spans for our\n",
    "        final prediction.\n",
    "\n",
    "        :param vocabulary_size:\n",
    "        :param embedding_size:\n",
    "        :param n_extra_features:\n",
    "        :param hidden_size:\n",
    "        :param n_layers:\n",
    "        :param dropout:\n",
    "        :param padding_index:\n",
    "        \"\"\"\n",
    "        super(DrQA, self).__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_extra_features = n_extra_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.padding_index = padding_index\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=vocabulary_size,\n",
    "            embedding_dim=embedding_size,\n",
    "            padding_idx=padding_index\n",
    "        )\n",
    "        self.aligned_question_embedding_layer = AlignedQuestionEmbeddingLayer(\n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size\n",
    "        )\n",
    "        self.context_lstm_layer = StackedBiLSTMsLayer(\n",
    "            embedding_size=embedding_size + hidden_size + n_extra_features,\n",
    "            hidden_size=hidden_size,\n",
    "            n_layers=n_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.question_encoding_layer = QuestionEncodingLayer(\n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=dropout,\n",
    "            n_layers=n_layers\n",
    "        )\n",
    "        self.bilinear_attention_start_layer = BiLinearAttentionLayer(\n",
    "            context_hidden_size=hidden_size * n_layers * 2,\n",
    "            question_hidden_size=hidden_size * n_layers * 2\n",
    "        )\n",
    "        self.bilinear_attention_end_layer = BiLinearAttentionLayer(\n",
    "            context_hidden_size=hidden_size * n_layers * 2,\n",
    "            question_hidden_size=hidden_size * n_layers * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: DrQATensorDatasetBatch) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        :param batch: DrQATensorDatasetBatch\n",
    "        :return: Tuple[FloatTensor[batch_size, ctx_seq_len], FloatTensor[batch_size, ctx_seq_len]]\n",
    "        \"\"\"\n",
    "        context_sequence = batch.context[0]  # [batch_size, ctx_seq_len]\n",
    "        context_lengths = batch.context[1]  # [batch_size,]\n",
    "        question_sequence = batch.question[0]  # [batch_size, qst_seq_len]\n",
    "        question_lengths = batch.question[1]  # [batch_size,]\n",
    "        exact_matches = batch.exact_match  # [batch_size, ctx_seq_len]\n",
    "        part_of_speeches = batch.part_of_speech  # [batch_size, ctx_seq_len]\n",
    "        named_entity_types = batch.named_entity_type  # [batch_size, ctx_seq_len]\n",
    "        normalized_term_frequencies = batch.normalized_term_frequency  # [batch_size, ctx_seq_len]\n",
    "\n",
    "        context_mask = self.make_sequence_mask(input_sequence=context_sequence)  # [batch_size, ctx_seq_len]\n",
    "        question_mask = self.make_sequence_mask(input_sequence=question_sequence)  # [batch_size, qst_seq_len]\n",
    "\n",
    "        context_embedded = self.embedding_layer(context_sequence)  # [batch_size, ctx_seq_len, embedding_size]\n",
    "        question_embedded = self.embedding_layer(question_sequence)  # [batch_size, qst_seq_len, embedding_size]\n",
    "\n",
    "        context_aligned = self.aligned_question_embedding_layer(\n",
    "            context_sequence=context_embedded,\n",
    "            question_sequence=question_embedded,\n",
    "            question_mask=question_mask\n",
    "        )  # [batch_size, ctx_len, embedding_size]\n",
    "\n",
    "        context_inputs = torch.cat([\n",
    "            context_aligned, context_embedded, exact_matches.unsqueeze(-1), part_of_speeches.unsqueeze(-1),\n",
    "            named_entity_types.unsqueeze(-1), normalized_term_frequencies.unsqueeze(-1)\n",
    "        ], dim=-1)  # [batch_size, ctx_seq_len, embedding_size + hidden_size + 4]\n",
    "\n",
    "        context_encoded = self.context_lstm_layer(\n",
    "            embedded_inputs=context_inputs,\n",
    "            sequence_lengths=context_lengths\n",
    "        )  # [batch_size, ctx_seq_len, n_layers * hidden_size * 2]\n",
    "        question_encoded = self.question_encoding_layer(\n",
    "            question_embedded=question_embedded,\n",
    "            question_lengths=question_lengths,\n",
    "            question_mask=question_mask\n",
    "        )  # [batch_size, n_layers * hidden_size * 2]\n",
    "\n",
    "        start_scores = self.bilinear_attention_start_layer(\n",
    "            context_encoded=context_encoded,\n",
    "            question_encoded=question_encoded,\n",
    "            context_mask=context_mask\n",
    "        )  # [batch_size, ctx_seq_len]\n",
    "        end_scores = self.bilinear_attention_end_layer(\n",
    "            context_encoded=context_encoded,\n",
    "            question_encoded=question_encoded,\n",
    "            context_mask=context_mask\n",
    "        )  # [batch_size, ctx_seq_len]\n",
    "        return start_scores, end_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x575iXlz3w4m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Training routines***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "31k5BZf43uV4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    # TODO\n",
    "    #  Add typing\n",
    "\n",
    "    def __init__(self, keys: List[str]):\n",
    "        self.keys = keys\n",
    "        self.value = {key: 0. for key in keys}\n",
    "        self.sum = {key: 0. for key in keys}\n",
    "        self.count = {key: 0. for key in keys}\n",
    "        self.average = {key: 0. for key in keys}\n",
    "\n",
    "    def reset(self):\n",
    "        self.value = {key: 0. for key in self.keys}\n",
    "        self.sum = {key: 0. for key in self.keys}\n",
    "        self.count = {key: 0. for key in self.keys}\n",
    "        self.average = {key: 0. for key in self.keys}\n",
    "\n",
    "    def update(self, key: str, value: float, n: int = 1):\n",
    "        self.value[key] = value\n",
    "        self.sum[key] += value * n\n",
    "        self.count[key] += n\n",
    "        self.average[key] = self.sum[key] / self.count[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "qSmh2GmU4KXH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(answer: str) -> str:\n",
    "    \"\"\"Performs a series of cleaning steps on the ground truth and predicted answer.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(answer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "hi2JHYTX6F6A",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(prediction: str, ground_truth: str) -> Tuple[float, float]:\n",
    "    prediction, ground_truth = normalize(prediction), normalize(ground_truth)\n",
    "    prediction_tokens, ground_truth_tokens = prediction.split(), ground_truth.split()\n",
    "\n",
    "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
    "    number_same = sum(common.values())\n",
    "    f1_score = 0\n",
    "    if number_same != 0:\n",
    "        precision = 1.0 * number_same / len(prediction_tokens)\n",
    "        recall = 1.0 * number_same / len(ground_truth_tokens)\n",
    "        f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return prediction == ground_truth, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "tv9kxaI34_Oo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def max_metrics_over_ground_truths(prediction: str, ground_truths: List[str]) -> Tuple[float, float]:\n",
    "    scores = [get_scores(prediction, ground_truth) for ground_truth in ground_truths]\n",
    "    em_score = max(scores, key=lambda score: score[0])[0]\n",
    "    f1_score = max(scores, key=lambda score: score[1])[1]\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KmxMG01B5JEx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(predictions: Dict[str, str], qas: List[RawDatasetItem]) -> Tuple[float, float]:\n",
    "    ground_truths = collections.defaultdict(lambda: [])\n",
    "    for qa in qas:\n",
    "        if qa.id_ in predictions:\n",
    "            ground_truths[qa.id_].append(qa.answer.text)\n",
    "\n",
    "    em_scores, f1_scores, total = [], [], 0\n",
    "    for id_ in predictions:\n",
    "        em_score, f1_score = max_metrics_over_ground_truths(predictions[id_], ground_truths[id_])\n",
    "        em_scores.append(em_score)\n",
    "        f1_scores.append(f1_score)\n",
    "        total += 1\n",
    "\n",
    "    em_score = 100.0 * sum(em_scores) / total\n",
    "    f1_score = 100.0 * sum(f1_scores) / total\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "GHUdYB6f-NRJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model: nn.Module, optimizer: optim.Optimizer, criterion: nn.Module, id_vocab: Vocabulary,\n",
    "                 text_vocab: Vocabulary, model_path: str):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.id_vocab = id_vocab\n",
    "        self.text_vocab = text_vocab\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def get_predictions(self, batch: DrQATensorDatasetBatch, starts: Tensor, ends: Tensor) -> Dict[str, str]:\n",
    "        start_indexes, end_indexes, _ = self.model.decode(\n",
    "            starts=F.softmax(starts, dim=-1),\n",
    "            ends=F.softmax(ends, dim=-1)\n",
    "        )\n",
    "\n",
    "        predictions = {}\n",
    "        for index in range(len(start_indexes)):\n",
    "            id_ = self.id_vocab.itos(batch.id_[index].item())\n",
    "            prediction = batch.context[0][index][start_indexes[index]:end_indexes[index] + 1]\n",
    "            predictions[id_] = ' '.join([self.text_vocab.itos(ind.item()) for ind in prediction])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def compute_metrics_and_update_tracker(self, batch: DrQATensorDatasetBatch, starts: Tensor, ends: Tensor,\n",
    "                                           tracker: AverageMeter, loader: DataLoader) -> None:\n",
    "        # TODO\n",
    "        #   Make batch type general not specific since the trainer will be use for different types of models\n",
    "        predictions = self.get_predictions(batch=batch, starts=starts, ends=ends)\n",
    "        em, f1 = metrics(predictions=predictions, qas=loader.dataset.data)\n",
    "\n",
    "        tracker.update(key=\"em\", value=em)\n",
    "        tracker.update(key=\"f1\", value=f1)\n",
    "\n",
    "    def train_step(self, loader: DataLoader, epoch: int, gradient_clipping: float) -> AverageMeter:\n",
    "        tracker = AverageMeter(keys=[\"loss\", \"em\", \"f1\"])\n",
    "        self.model.train()\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for index, batch in pbar:  # type: int, DrQATensorDatasetBatch\n",
    "            self.optimizer.zero_grad()\n",
    "            starts, ends = self.model(batch)  # [batch_size, ctx_len]\n",
    "            loss = self.criterion(starts, batch.target[:, 0]) + self.criterion(ends, batch.target[:, 1])\n",
    "            loss.backward()\n",
    "            if gradient_clipping is not None:\n",
    "                nn.utils.clip_grad_norm_(parameters=self.model.parameters(), max_norm=gradient_clipping)\n",
    "            self.optimizer.step()\n",
    "            tracker.update(key=\"loss\", value=loss.item())\n",
    "            self.compute_metrics_and_update_tracker(\n",
    "                batch=batch,\n",
    "                starts=starts,\n",
    "                ends=ends,\n",
    "                tracker=tracker,\n",
    "                loader=loader\n",
    "            )\n",
    "            pbar.set_description(\n",
    "                f\"Epoch: {epoch + 1:03d} |       loss: {tracker.average['loss']:6.3f} |       \"\n",
    "                f\"em: {tracker.average['em']:6.3f} |       f1: {tracker.average['f1']:6.3f}\"\n",
    "            )\n",
    "            break\n",
    "        return tracker\n",
    "\n",
    "    def validate(self, loader: DataLoader) -> AverageMeter:\n",
    "        tracker = AverageMeter(keys=[\"loss\", \"em\", \"f1\"])\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "            for _, batch in pbar:  # type: int, DrQATensorDatasetBatch\n",
    "                starts, ends = self.model(batch)  # [batch_size, ctx_len]\n",
    "                loss = self.criterion(starts, batch.target[:, 0]) + self.criterion(ends, batch.target[:, 1])\n",
    "                tracker.update(key=\"loss\", value=loss.item())\n",
    "                self.compute_metrics_and_update_tracker(\n",
    "                    batch=batch,\n",
    "                    starts=starts,\n",
    "                    ends=ends,\n",
    "                    tracker=tracker,\n",
    "                    loader=loader\n",
    "                )\n",
    "                pbar.set_description(\n",
    "                    f\"           | valid_loss: {tracker.average['loss']:6.3f} | valid_em: {tracker.average['em']:6.3f} \"\n",
    "                    f\"| valid_f1: {tracker.average['f1']:6.3f}\"\n",
    "                )\n",
    "                break\n",
    "        return tracker\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_loader: DataLoader, n_epochs: int, gradient_clipping: float) \\\n",
    "            -> Dict[str, List[float]]:\n",
    "        history = {\n",
    "            \"loss\": [], \"valid_loss\": [],\n",
    "            \"em\": [], \"valid_em\": [],\n",
    "            \"f1\": [], \"valid_f1\": []\n",
    "        }\n",
    "        # best_loss = float('inf')\n",
    "        for epoch in range(n_epochs):\n",
    "            print(\n",
    "                \"|----------------------------------------------------------------------------------------------------\"\n",
    "                \"---------|\"\n",
    "            )\n",
    "            train_tracker = self.train_step(loader=train_loader, epoch=epoch, gradient_clipping=gradient_clipping)\n",
    "            valid_tracker = self.validate(loader=valid_loader)\n",
    "\n",
    "            history[\"loss\"].append(train_tracker.average[\"loss\"])\n",
    "            history[\"valid_loss\"].append(valid_tracker.average[\"loss\"])\n",
    "            history[\"em\"].append(train_tracker.average[\"em\"])\n",
    "            history[\"valid_em\"].append(valid_tracker.average[\"loss\"])\n",
    "            history[\"f1\"].append(train_tracker.average[\"f1\"])\n",
    "            history[\"valid_f1\"].append(valid_tracker.average[\"f1\"])\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFzM-vWUAov9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Train the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "-YCmJQLhAlqo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_LAYERS = 1\n",
    "EMBED_SIZE = 100\n",
    "HIDDEN_SIZE = 64\n",
    "DROPOUT = 0.\n",
    "N_EPOCHS = 100\n",
    "GRAD_CLIP = None\n",
    "LEARNING_RATE = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ersGVmFxBwAV",
    "outputId": "f5c11bc4-a4bb-49cb-8fc1-c472323ec253",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 2,932,532\n",
      "DrQA(\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (embedding_layer): Embedding(26884, 100, padding_idx=0)\n",
      "  (aligned_question_embedding_layer): AlignedQuestionEmbeddingLayer(\n",
      "    (dense): Linear(in_features=100, out_features=64, bias=True)\n",
      "  )\n",
      "  (context_lstm_layer): StackedBiLSTMsLayer(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (lstm_layers): ModuleList(\n",
      "      (0): LSTM(168, 64, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (question_encoding_layer): QuestionEncodingLayer(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (stacked_bilstm_layers): StackedBiLSTMsLayer(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (lstm_layers): ModuleList(\n",
      "        (0): LSTM(100, 64, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "    (dense): Linear(in_features=100, out_features=1, bias=False)\n",
      "  )\n",
      "  (bilinear_attention_start_layer): BiLinearAttentionLayer(\n",
      "    (dense): Linear(in_features=128, out_features=128, bias=False)\n",
      "  )\n",
      "  (bilinear_attention_end_layer): BiLinearAttentionLayer(\n",
      "    (dense): Linear(in_features=128, out_features=128, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "padding_token_index = text_vocabulary.stoi(word=text_vocabulary.padding_token)\n",
    "model = DrQA(\n",
    "    vocabulary_size=len(text_vocabulary),\n",
    "    embedding_size=EMBED_SIZE,\n",
    "    n_extra_features=4,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    padding_index=padding_token_index\n",
    ").to(device=DEVICE)\n",
    "# model.load_glove_embeddings('./data/GloVe_DrQA.npy', most_common_indexes, tune=True)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=padding_token_index)\n",
    "print(f'Number of parameters of the model: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "print(model)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    model_path=\"./checkpoints/drqa.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giP1Ov5_DTGr",
    "outputId": "aa776c3f-80f1-4c9f-9abb-37e38eb2841c",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001 |       loss: 10.075 |       em:  0.000 |       f1:  3.160:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.048 | valid_em:  0.000 | valid_f1:  4.736:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 002 |       loss: 10.010 |       em:  0.000 |       f1:  3.506:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.042 | valid_em:  0.000 | valid_f1:  5.569:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 003 |       loss:  9.945 |       em:  0.000 |       f1:  4.943:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.037 | valid_em:  0.000 | valid_f1:  4.213:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 004 |       loss:  9.880 |       em:  0.000 |       f1:  5.154:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.033 | valid_em:  0.000 | valid_f1:  3.981:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 005 |       loss:  9.815 |       em:  0.000 |       f1:  4.833:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.029 | valid_em:  0.000 | valid_f1:  3.981:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 006 |       loss:  9.749 |       em:  0.000 |       f1:  8.019:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.024 | valid_em:  0.000 | valid_f1:  3.981:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 007 |       loss:  9.681 |       em:  0.000 |       f1:  5.749:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.020 | valid_em:  0.000 | valid_f1:  2.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 008 |       loss:  9.611 |       em:  0.000 |       f1:  7.670:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.016 | valid_em:  0.000 | valid_f1:  3.229:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 009 |       loss:  9.539 |       em:  0.000 |       f1:  9.342:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.012 | valid_em:  0.000 | valid_f1:  2.925:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 010 |       loss:  9.464 |       em:  0.000 |       f1: 10.134:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.008 | valid_em:  0.000 | valid_f1:  4.222:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 011 |       loss:  9.386 |       em:  6.250 |       f1: 16.539:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.003 | valid_em:  0.000 | valid_f1:  6.270:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 012 |       loss:  9.303 |       em:  6.250 |       f1: 14.484:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.998 | valid_em:  0.000 | valid_f1:  6.873:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 013 |       loss:  9.216 |       em:  9.375 |       f1: 18.526:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.992 | valid_em:  0.000 | valid_f1:  6.891:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 014 |       loss:  9.124 |       em:  9.375 |       f1: 19.056:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.986 | valid_em:  0.000 | valid_f1:  6.604:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 015 |       loss:  9.026 |       em:  9.375 |       f1: 19.242:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.979 | valid_em:  0.000 | valid_f1:  6.249:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 016 |       loss:  8.922 |       em: 12.500 |       f1: 22.243:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.971 | valid_em:  0.000 | valid_f1:  6.249:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 017 |       loss:  8.811 |       em: 12.500 |       f1: 22.243:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.962 | valid_em:  0.000 | valid_f1:  6.249:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 018 |       loss:  8.693 |       em: 12.500 |       f1: 23.052:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.953 | valid_em:  0.000 | valid_f1:  8.784:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 019 |       loss:  8.567 |       em: 15.625 |       f1: 24.266:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.943 | valid_em:  0.000 | valid_f1:  8.784:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 020 |       loss:  8.432 |       em: 15.625 |       f1: 24.091:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.932 | valid_em:  0.000 | valid_f1:  8.784:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 021 |       loss:  8.289 |       em: 15.625 |       f1: 24.783:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.922 | valid_em:  0.000 | valid_f1:  8.551:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 022 |       loss:  8.136 |       em: 15.625 |       f1: 24.682:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.911 | valid_em:  0.000 | valid_f1:  8.551:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 023 |       loss:  7.973 |       em: 15.625 |       f1: 24.013:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.900 | valid_em:  0.000 | valid_f1:  8.551:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 024 |       loss:  7.799 |       em: 18.750 |       f1: 27.002:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.890 | valid_em:  0.000 | valid_f1:  8.472:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 025 |       loss:  7.615 |       em: 18.750 |       f1: 26.201:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.880 | valid_em:  0.000 | valid_f1:  4.166:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 026 |       loss:  7.418 |       em: 18.750 |       f1: 26.201:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.871 | valid_em:  0.000 | valid_f1:  4.166:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 027 |       loss:  7.210 |       em: 21.875 |       f1: 29.267:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.862 | valid_em:  0.000 | valid_f1:  4.166:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 028 |       loss:  6.989 |       em: 21.875 |       f1: 28.239:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.854 | valid_em:  0.000 | valid_f1:  3.422:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 029 |       loss:  6.754 |       em: 25.000 |       f1: 31.231:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.849 | valid_em:  0.000 | valid_f1:  3.422:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 030 |       loss:  6.507 |       em: 25.000 |       f1: 31.231:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.845 | valid_em:  0.000 | valid_f1:  3.422:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 031 |       loss:  6.246 |       em: 28.125 |       f1: 33.430:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.845 | valid_em:  0.000 | valid_f1:  3.422:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 032 |       loss:  5.974 |       em: 31.250 |       f1: 36.555:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.849 | valid_em:  0.000 | valid_f1:  3.422:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 033 |       loss:  5.694 |       em: 34.375 |       f1: 39.680:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.858 | valid_em:  0.000 | valid_f1:  3.422:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 034 |       loss:  5.409 |       em: 31.250 |       f1: 36.815:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.872 | valid_em:  0.000 | valid_f1:  3.689:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 035 |       loss:  5.124 |       em: 31.250 |       f1: 37.422:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.894 | valid_em:  0.000 | valid_f1:  3.086:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 036 |       loss:  4.844 |       em: 31.250 |       f1: 37.422:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.924 | valid_em:  0.000 | valid_f1:  3.800:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 037 |       loss:  4.573 |       em: 31.250 |       f1: 37.422:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.963 | valid_em:  0.000 | valid_f1:  3.800:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 038 |       loss:  4.315 |       em: 31.250 |       f1: 36.618:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.012 | valid_em:  0.000 | valid_f1:  4.080:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 039 |       loss:  4.065 |       em: 31.250 |       f1: 36.618:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.074 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 040 |       loss:  3.822 |       em: 31.250 |       f1: 36.618:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.147 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 041 |       loss:  3.578 |       em: 31.250 |       f1: 36.978:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.232 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 042 |       loss:  3.332 |       em: 31.250 |       f1: 36.978:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.328 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 043 |       loss:  3.090 |       em: 31.250 |       f1: 37.068:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.429 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 044 |       loss:  2.860 |       em: 34.375 |       f1: 40.193:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.529 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 045 |       loss:  2.635 |       em: 43.750 |       f1: 49.568:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.626 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 046 |       loss:  2.414 |       em: 43.750 |       f1: 52.432:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.720 | valid_em:  0.000 | valid_f1:  3.603:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 047 |       loss:  2.203 |       em: 56.250 |       f1: 63.370:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.818 | valid_em:  0.000 | valid_f1:  5.551:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 048 |       loss:  2.007 |       em: 62.500 |       f1: 70.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.924 | valid_em:  0.000 | valid_f1:  5.551:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 049 |       loss:  1.823 |       em: 62.500 |       f1: 70.783:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.043 | valid_em:  0.000 | valid_f1:  5.551:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 050 |       loss:  1.646 |       em: 68.750 |       f1: 79.235:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.170 | valid_em:  0.000 | valid_f1:  5.370:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 051 |       loss:  1.480 |       em: 68.750 |       f1: 79.235:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.298 | valid_em:  0.000 | valid_f1:  4.409:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 052 |       loss:  1.327 |       em: 75.000 |       f1: 87.494:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.420 | valid_em:  0.000 | valid_f1:  3.890:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 053 |       loss:  1.181 |       em: 78.125 |       f1: 88.047:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.539 | valid_em:  0.000 | valid_f1:  3.890:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 054 |       loss:  1.044 |       em: 84.375 |       f1: 94.085:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.665 | valid_em:  0.000 | valid_f1:  3.890:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 055 |       loss:  0.918 |       em: 84.375 |       f1: 94.085:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.807 | valid_em:  0.000 | valid_f1:  2.928:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 056 |       loss:  0.807 |       em: 84.375 |       f1: 94.085:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.972 | valid_em:  0.000 | valid_f1:  2.928:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 057 |       loss:  0.709 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.157 | valid_em:  0.000 | valid_f1:  2.928:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 058 |       loss:  0.622 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.356 | valid_em:  0.000 | valid_f1:  2.928:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 059 |       loss:  0.545 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.562 | valid_em:  0.000 | valid_f1:  2.928:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 060 |       loss:  0.476 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.770 | valid_em:  0.000 | valid_f1:  2.928:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 061 |       loss:  0.416 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.978 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 062 |       loss:  0.361 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.185 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 063 |       loss:  0.314 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.398 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 064 |       loss:  0.275 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.616 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 065 |       loss:  0.240 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.842 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 066 |       loss:  0.209 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.065 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 067 |       loss:  0.181 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.284 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 068 |       loss:  0.157 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.494 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 069 |       loss:  0.136 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.695 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 070 |       loss:  0.118 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.888 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 071 |       loss:  0.103 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.075 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 072 |       loss:  0.090 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.256 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 073 |       loss:  0.079 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.431 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 074 |       loss:  0.070 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.601 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 075 |       loss:  0.062 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.765 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 076 |       loss:  0.056 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.920 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 077 |       loss:  0.050 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.069 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 078 |       loss:  0.045 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.210 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 079 |       loss:  0.040 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.343 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 080 |       loss:  0.037 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.470 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 081 |       loss:  0.033 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.588 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 082 |       loss:  0.030 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.699 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 083 |       loss:  0.028 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.803 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 084 |       loss:  0.025 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.903 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 085 |       loss:  0.023 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.997 | valid_em:  0.000 | valid_f1:  1.948:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 086 |       loss:  0.022 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.082 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 087 |       loss:  0.020 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.165 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 088 |       loss:  0.019 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.240 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 089 |       loss:  0.018 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.314 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 090 |       loss:  0.016 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.384 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 091 |       loss:  0.015 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.446 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 092 |       loss:  0.015 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.506 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 093 |       loss:  0.014 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.565 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 094 |       loss:  0.013 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.620 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 095 |       loss:  0.012 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.673 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 096 |       loss:  0.012 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.724 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 097 |       loss:  0.011 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.771 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 098 |       loss:  0.011 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.816 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 099 |       loss:  0.010 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.861 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100 |       loss:  0.010 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 17.904 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./checkpoints\n",
    "history = trainer.train(\n",
    "    train_loader=train_dataloader,\n",
    "    valid_loader=valid_dataloader,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    gradient_clipping=GRAD_CLIP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "8C-bSJpY-qZM",
    "outputId": "db26fdee-279c-4fe8-b5d6-7f26a8587271",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['valid_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['em'], label='train')\n",
    "axes[1].plot(history['valid_em'], label='valid')\n",
    "axes[1].set_title('Exact match history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Exact match (%)')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(history['f1'], label='train')\n",
    "axes[2].plot(history['valid_f1'], label='valid')\n",
    "axes[2].set_title('F1 history')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 (%)')\n",
    "axes[2].grid(True)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_99dtAVn5CL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Inference***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk9dSwSR_OM9",
    "outputId": "dfc3f33a-a716-44fd-ae2d-3ce5fdaa745f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"./checkpoints/drqa.pth\"))\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "p1CVgakLDtsU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def inference(model: nn.Module, context: spacy.tokens.doc.Doc, question: spacy.tokens.doc.Doc,\n",
    "              text_vocab: Vocabulary, pos_vocab: Vocabulary, ner_vocab: Vocabulary, device: torch.device):\n",
    "    # Build extra features\n",
    "    question = [token.text.lower() for token in question]\n",
    "    counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
    "    freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
    "    freqs_norm = sum(freqs.values())\n",
    "    em, pos, ner, ntf = zip(\n",
    "        *map(lambda index: [\n",
    "            context[index].text.lower() in question, context[index].tag_,\n",
    "            context[index].ent_type_ or 'None',\n",
    "            freqs[index] / freqs_norm\n",
    "        ], range(len(context)))\n",
    "    )\n",
    "\n",
    "    # Build tensors\n",
    "    batch = DrQATensorDatasetBatch(\n",
    "        id_=None,\n",
    "        context=(\n",
    "            torch.LongTensor([*map(lambda word: text_vocab.stoi(word), context)]).unsqueeze(0).to(device),\n",
    "            torch.LongTensor([len(context)])\n",
    "        ), question=(\n",
    "            torch.LongTensor([*map(lambda word: text_vocab.stoi(word), question)]).unsqueeze(0).to(device),\n",
    "            torch.LongTensor([len(question)])\n",
    "        ), target=None,\n",
    "        exact_match=torch.LongTensor(em).unsqueeze(0).to(device),\n",
    "        part_of_speech=torch.LongTensor([*map(lambda x: pos_vocab.stoi(x), pos)]).unsqueeze(0).to(device),\n",
    "        named_entity_type=torch.LongTensor([*map(lambda x: ner_vocab.stoi(x), ner)]).unsqueeze(0).to(device),\n",
    "        normalized_term_frequency=torch.LongTensor(ntf).unsqueeze(0).to(device)\n",
    "    )\n",
    "\n",
    "    # Prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Feed the model\n",
    "        start, end = model(batch)\n",
    "    \n",
    "        # Decode the result indexes\n",
    "        start_index, end_index, proba = model.decode(starts=F.softmax(start, dim=-1), ends=F.softmax(end, dim=-1))\n",
    "        print(start_index, end_index)\n",
    "\n",
    "        # Extract the answer\n",
    "        answer = context[start_index[0]:end_index[0] + 1]\n",
    "\n",
    "    return answer, proba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dI-ME2Q1-WzB",
    "outputId": "7ddd80ef-e885-476d-a8e7-32e1a031417b",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21] [37]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The next major step occurred when James Watt developed (1763–1775) an improved version of Newcomen's engine, with a separate condenser. Boulton and Watt's early engines used half as much coal as John Smeaton's improved version of Newcomen's. Newcomen's and Watt's early engines were \"atmospheric\". They were powered by air pressure pushing a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam. The engine cylinders had to be large because the only usable force acting on them was due to atmospheric pressure.</span><br /><span><b>Question:</b> Compared to Smeaton's improvement on Newcomen's engine, how much coal did Watt's engine use?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">half</li><li style=\"color:blue\">half as much</li><li style=\"color:blue\">half as much coal</li><li style=\"color:blue\">half</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=a separate condenser. Boulton and Watt's early engines used half as much coal as John=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.024%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[32] [74]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The game's media day, which was typically held on the Tuesday afternoon prior to the game, was moved to the Monday evening and re-branded as Super Bowl Opening Night. The event was held on February 1, 2016 at SAP Center in San Jose. Alongside the traditional media availabilities, the event featured an opening ceremony with player introductions on a replica of the Golden Gate Bridge.</span><br /><span><b>Question:</b> What was the name of the Media Day event for Super Bowl 50?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Super Bowl Opening Night</li><li style=\"color:blue\">Super Bowl Opening Night</li><li style=\"color:blue\">Super Bowl Opening Night.</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=Opening Night. The event was held on February 1, 2016 at SAP Center in San Jose. Alongside the traditional media availabilities, the event featured an opening ceremony with player introductions on a replica of the Golden Gate Bridge.=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.172%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[1] [126]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Newcastle replaced him in January 1756 with Lord Loudoun, with Major General James Abercrombie as his second in command. Neither of these men had as much campaign experience as the trio of officers France sent to North America. French regular army reinforcements arrived in New France in May 1756, led by Major General Louis-Joseph de Montcalm and seconded by the Chevalier de Lévis and Colonel François-Charles de Bourlamaque, all experienced veterans from the War of the Austrian Succession. During that time in Europe, on May 18, 1756, England formally declared war on France, which expanded the war into Europe, which was later to be known as the Seven Years' War.</span><br /><span><b>Question:</b> Who led New France reinforcements in 1756?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Major General Louis-Joseph de Montcalm</li><li style=\"color:blue\">Major General Louis-Joseph de Montcalm</li><li style=\"color:blue\">Lord Loudoun</li><li style=\"color:blue\">Major General Louis-Joseph de Montcalm</li><li style=\"color:blue\">Major General Louis-Joseph de Montcalm</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=replaced him in January 1756 with Lord Loudoun, with Major General James Abercrombie as his second in command. Neither of these men had as much campaign experience as the trio of officers France sent to North America. French regular army reinforcements arrived in New France in May 1756, led by Major General Louis-Joseph de Montcalm and seconded by the Chevalier de Lévis and Colonel François-Charles de Bourlamaque, all experienced veterans from the War of the Austrian Succession. During that time in Europe, on May 18, 1756, England formally declared war on France, which expanded the war into Europe, which was later to be known as the Seven Years' War.=</span><br /><span style=\"color:green\"><b>Probability:</b> 2.334%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[22] [115]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.</span><br /><span><b>Question:</b> Who was the Most Valuable Player for the 2015 NFL season?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Cam Newton</li><li style=\"color:blue\">Cam Newton</li><li style=\"color:blue\">Cam Newton</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=(MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.047%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[2] [102]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Doctor Who is a British science-fiction television programme produced by the BBC since 1963. The programme depicts the adventures of the Doctor, a Time Lord—a space and time-travelling humanoid alien. He explores the universe in his TARDIS, a sentient time-travelling space ship. Its exterior appears as a blue British police box, which was a common sight in Britain in 1963 when the series first aired. Accompanied by companions, the Doctor combats a variety of foes, while working to save civilisations and help people in need.</span><br /><span><b>Question:</b> What year did Doctor Who first show on TV?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">1963</li><li style=\"color:blue\">1963</li><li style=\"color:blue\">1963</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=is a British science-fiction television programme produced by the BBC since 1963. The programme depicts the adventures of the Doctor, a Time Lord—a space and time-travelling humanoid alien. He explores the universe in his TARDIS, a sentient time-travelling space ship. Its exterior appears as a blue British police box, which was a common sight in Britain in 1963 when the series first aired. Accompanied by companions, the Doctor combats a variety of foes, while working to save civilisations and help people in need.=</span><br /><span style=\"color:green\"><b>Probability:</b> 2.437%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[45] [106]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Grissom, White, and Chaffee decided to name their flight Apollo 1 as a motivational focus on the first manned flight. They trained and conducted tests of their spacecraft at North American, and in the altitude chamber at the Kennedy Space Center. A \"plugs-out\" test was planned for January, which would simulate a launch countdown on LC-34 with the spacecraft transferring from pad-supplied to internal power. If successful, this would be followed by a more rigorous countdown simulation test closer to the February 21 launch, with both spacecraft and launch vehicle fueled.</span><br /><span><b>Question:</b> What other location did Apollo 1 test at besides Kennedy Space Center?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">North American</li><li style=\"color:blue\">North American</li><li style=\"color:blue\">North American</li><li style=\"color:blue\">North American</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=. A \"plugs-out\" test was planned for January, which would simulate a launch countdown on LC-34 with the spacecraft transferring from pad-supplied to internal power. If successful, this would be followed by a more rigorous countdown simulation test closer to the February 21 launch, with both spacecraft and launch vehicle fueled.=</span><br /><span style=\"color:green\"><b>Probability:</b> 13.240%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[31] [66]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Teachers in Wales can be registered members of trade unions such as ATL, NUT or NASUWT and reports in recent years suggest that the average age of teachers in Wales is falling with teachers being younger than in previous years. A growing cause of concern are that attacks on teachers in Welsh schools which reached an all-time high between 2005 and 2010.</span><br /><span><b>Question:</b> What group can teachers in Wales register with?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">trade unions</li><li style=\"color:blue\">ATL, NUT or NASUWT</li><li style=\"color:blue\">trade unions</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=is falling with teachers being younger than in previous years. A growing cause of concern are that attacks on teachers in Welsh schools which reached an all-time high between 2005 and 2010.=</span><br /><span style=\"color:green\"><b>Probability:</b> 4.704%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[1] [2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In 1981, the Presidential Working Party on the Second University was commissioned to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system. The committee recommended that the 7–4–2–3 system be changed to an 8–4–4 system (eight years in primary, four years in secondary, and four years in university education). The table under Present-day education in Kenya below shows the structure of the 8–4–4 system. Although the 7–4–2–3 system theoretically ended with the introduction of the new 8–4–4 system in 1985, the last batch of students from the former system graduated from Kenyan Universities in 1992.</span><br /><span><b>Question:</b> What was the Presidential Working Party on the Second University commissioned to do?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system</li><li style=\"color:blue\">look at both the possibilities</li><li style=\"color:blue\">look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=1981,=</span><br /><span style=\"color:green\"><b>Probability:</b> 4.063%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[2] [2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> During the mass high school education movement from 1910–1940, there was an increase in skilled workers, which led to a decrease in the price of skilled labor. High school education during the period was designed to equip students with necessary skill sets to be able to perform at work. In fact, it differs from the present high school education, which is regarded as a stepping-stone to acquire college and advanced degrees. This decrease in wages caused a period of compression and decreased inequality between skilled and unskilled workers. Education is very important for the growth of the economy, however educational inequality in gender also influence towards the economy. Lagerlof and Galor stated that gender inequality in education can result to low economic growth, and continued gender inequality in education, thus creating a poverty trap. It is suggested that a large gap in male and female education may indicate backwardness and so may be associated with lower economic growth, which can explain why there is economic inequality between countries.</span><br /><span><b>Question:</b> What impact did the high school education movement have on the presence of skilled workers?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">increase</li><li style=\"color:blue\">an increase</li><li style=\"color:blue\">increase</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=mass=</span><br /><span style=\"color:green\"><b>Probability:</b> 7.069%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[35] [28]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> John Schmitt and Ben Zipperer (2006) of the CEPR point to economic liberalism and the reduction of business regulation along with the decline of union membership as one of the causes of economic inequality. In an analysis of the effects of intensive Anglo-American liberal policies in comparison to continental European liberalism, where unions have remained strong, they concluded \"The U.S. economic and social model is associated with substantial levels of social exclusion, including high levels of income inequality, high relative and absolute poverty rates, poor and unequal educational outcomes, poor health outcomes, and high rates of crime and incarceration. At the same time, the available evidence provides little support for the view that U.S.-style labor-market flexibility dramatically improves labor-market outcomes. Despite popular prejudices to the contrary, the U.S. economy consistently affords a lower level of economic mobility than all the continental European countries for which data is available.\"</span><br /><span><b>Question:</b> What is economic liberalism one of the causes of?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">economic inequality</li><li style=\"color:blue\">economic inequality</li><li style=\"color:blue\">economic inequality</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 1.032%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[32] [143]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> During the ITV network strike of 1979, viewership peaked at 16 million.[citation needed] Figures remained respectable into the 1980s, but fell noticeably after the programme's 23rd series was postponed in 1985 and the show was off the air for 18 months. Its late 1980s performance of three to five million viewers was seen as poor at the time and was, according to the BBC Board of Control, a leading cause of the programme's 1989 suspension. Some fans considered this disingenuous, since the programme was scheduled against the soap opera Coronation Street, the most popular show at the time. After the series' revival in 2005 (the third notable period of high ratings), it has consistently had high viewership levels for the evening on which the episode is broadcast.</span><br /><span><b>Question:</b> When was the third period of high viewership for the Doctor Who series?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">After the series' revival in 2005</li><li style=\"color:blue\">the series' revival in 2005</li><li style=\"color:blue\">2005</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=postponed in 1985 and the show was off the air for 18 months. Its late 1980s performance of three to five million viewers was seen as poor at the time and was, according to the BBC Board of Control, a leading cause of the programme's 1989 suspension. Some fans considered this disingenuous, since the programme was scheduled against the soap opera Coronation Street, the most popular show at the time. After the series' revival in 2005 (the third notable period of high ratings), it has consistently had high viewership levels for the evening on which the episode is broadcast.=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.092%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[38] [119]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Eventually, the Normans merged with the natives, combining languages and traditions. In the course of the Hundred Years' War, the Norman aristocracy often identified themselves as English. The Anglo-Norman language became distinct from the Latin language, something that was the subject of some humour by Geoffrey Chaucer. The Anglo-Norman language was eventually absorbed into the Anglo-Saxon language of their subjects (see Old English) and influenced it, helping (along with the Norse language of the earlier Anglo-Norse settlers and the Latin used by the church) in the development of Middle English. It in turn evolved into Modern English.</span><br /><span><b>Question:</b> What was the Anglo-Norman language's final form?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Modern English</li><li style=\"color:blue\">Modern English</li><li style=\"color:blue\">Modern English</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=became distinct from the Latin language, something that was the subject of some humour by Geoffrey Chaucer. The Anglo-Norman language was eventually absorbed into the Anglo-Saxon language of their subjects (see Old English) and influenced it, helping (along with the Norse language of the earlier Anglo-Norse settlers and the Latin used by the church) in the development of Middle English. It in turn evolved into Modern English.=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.608%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[11] [52]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The best, worst and average case complexity refer to three different ways of measuring the time complexity (or any other complexity measure) of different inputs of the same size. Since some inputs of size n may be faster to solve than others, we define the following complexities:</span><br /><span><b>Question:</b> What are the three primary expressions used to represent case complexity?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">best, worst and average</li><li style=\"color:blue\">best, worst and average case</li><li style=\"color:blue\">best, worst and average case complexity</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=different ways of measuring the time complexity (or any other complexity measure) of different inputs of the same size. Since some inputs of size n may be faster to solve than others, we define the following complexities:=</span><br /><span style=\"color:green\"><b>Probability:</b> 3.990%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[5] [135]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> After the revocation of the Edict of Nantes, the Dutch Republic received the largest group of Huguenot refugees, an estimated total of 75,000 to 100,000 people. Amongst them were 200 clergy. Many came from the region of the Cévennes, for instance, the village of Fraissinet-de-Lozère. This was a huge influx as the entire population of the Dutch Republic amounted to ca. 2 million at that time. Around 1700, it is estimated that nearly 25% of the Amsterdam population was Huguenot.[citation needed] In 1705, Amsterdam and the area of West Frisia were the first areas to provide full citizens rights to Huguenot immigrants, followed by the Dutch Republic in 1715. Huguenots intermarried with Dutch from the outset.</span><br /><span><b>Question:</b> What country initially received the largest number of Huguenot refugees?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">the Dutch Republic</li><li style=\"color:blue\">Dutch Republic</li><li style=\"color:blue\">Dutch Republic</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=Edict of Nantes, the Dutch Republic received the largest group of Huguenot refugees, an estimated total of 75,000 to 100,000 people. Amongst them were 200 clergy. Many came from the region of the Cévennes, for instance, the village of Fraissinet-de-Lozère. This was a huge influx as the entire population of the Dutch Republic amounted to ca. 2 million at that time. Around 1700, it is estimated that nearly 25% of the Amsterdam population was Huguenot.[citation needed] In 1705, Amsterdam and the area of West Frisia were the first areas to provide full citizens rights to Huguenot immigrants, followed by the Dutch Republic in 1715. Huguenots intermarried with Dutch from the outset.=</span><br /><span style=\"color:green\"><b>Probability:</b> 3.167%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[38] [43]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> By the 6th century, the Rhine was within the borders of Francia. In the 9th, it formed part of the border between Middle and Western Francia, but in the 10th century, it was fully within the Holy Roman Empire, flowing through Swabia, Franconia and Lower Lorraine. The mouths of the Rhine, in the county of Holland, fell to the Burgundian Netherlands in the 15th century; Holland remained contentious territory throughout the European wars of religion and the eventual collapse of the Holy Roman Empire, when the length of the Rhine fell to the First French Empire and its client states. The Alsace on the left banks of the Upper Rhine was sold to Burgundy by Archduke Sigismund of Austria in 1469 and eventually fell to France in the Thirty Years' War. The numerous historic castles in Rhineland-Palatinate attest to the importance of the river as a commercial route.</span><br /><span><b>Question:</b> The Rhine flowed through Swabia, Franconia and what other location in the 10th Century?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Lower Lorraine</li><li style=\"color:blue\">Lower Lorraine</li><li style=\"color:blue\">Lower Lorraine</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=fully within the Holy Roman Empire=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.284%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[16] [113]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The principle of inclusions and components states that, with sedimentary rocks, if inclusions (or clasts) are found in a formation, then the inclusions must be older than the formation that contains them. For example, in sedimentary rocks, it is common for gravel from an older formation to be ripped up and included in a newer layer. A similar situation with igneous rocks occurs when xenoliths are found. These foreign bodies are picked up as magma or lava flows, and are incorporated, later to cool in the matrix. As a result, xenoliths are older than the rock which contains them.</span><br /><span><b>Question:</b> What is the principle that states that with sedimentary rocks, inclusions must be older than the formation that contains them?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">The principle of inclusions and components</li><li style=\"color:blue\">principle of inclusions and components</li><li style=\"color:blue\">The principle of inclusions and components</li><li style=\"color:blue\">inclusions and components</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=or clasts) are found in a formation, then the inclusions must be older than the formation that contains them. For example, in sedimentary rocks, it is common for gravel from an older formation to be ripped up and included in a newer layer. A similar situation with igneous rocks occurs when xenoliths are found. These foreign bodies are picked up as magma or lava flows, and are incorporated, later to cool in the matrix. As a result, xenoliths are older than the rock which contains them.=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.806%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[4] [128]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In World War II, Charles de Gaulle and the Free French used the overseas colonies as bases from which they fought to liberate France. However after 1945 anti-colonial movements began to challenge the Empire. France fought and lost a bitter war in Vietnam in the 1950s. Whereas they won the war in Algeria, the French leader at the time, Charles de Gaulle, decided to grant Algeria independence anyway in 1962. Its settlers and many local supporters relocated to France. Nearly all of France's colonies gained independence by 1960, but France retained great financial and diplomatic influence. It has repeatedly sent troops to assist its former colonies in Africa in suppressing insurrections and coups d’état.</span><br /><span><b>Question:</b> Where did France lose a war in the 1950's?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Vietnam</li><li style=\"color:blue\">Vietnam</li><li style=\"color:blue\">Vietnam</li><li style=\"color:blue\">Vietnam</li><li style=\"color:blue\">Vietnam</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=, Charles de Gaulle and the Free French used the overseas colonies as bases from which they fought to liberate France. However after 1945 anti-colonial movements began to challenge the Empire. France fought and lost a bitter war in Vietnam in the 1950s. Whereas they won the war in Algeria, the French leader at the time, Charles de Gaulle, decided to grant Algeria independence anyway in 1962. Its settlers and many local supporters relocated to France. Nearly all of France's colonies gained independence by 1960, but France retained great financial and diplomatic influence. It has repeatedly sent troops to assist its former colonies in Africa in suppressing insurrections and coups d’état.=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.549%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[116] [131]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> One of its earliest massive implementations was brought about by Egyptians against the British occupation in the 1919 Revolution. Civil disobedience is one of the many ways people have rebelled against what they deem to be unfair laws. It has been used in many nonviolent resistance movements in India (Gandhi's campaigns for independence from the British Empire), in Czechoslovakia's Velvet Revolution and in East Germany to oust their communist governments, In South Africa in the fight against apartheid, in the American Civil Rights Movement, in the Singing Revolution to bring independence to the Baltic countries from the Soviet Union, recently with the 2003 Rose Revolution in Georgia and the 2004 Orange Revolution in Ukraine, among other various movements worldwide.</span><br /><span><b>Question:</b> In 2004 the Orange revolution occurred in what country?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Ukraine</li><li style=\"color:blue\">Ukraine</li><li style=\"color:blue\">Ukraine</li><li style=\"color:blue\">Ukraine</li><li style=\"color:blue\">Ukraine</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=in Georgia and the 2004 Orange Revolution in Ukraine, among other various movements worldwide.=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.198%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[261] [261]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Some have described the internal strife between various people groups as a form of imperialism or colonialism. This internal form is distinct from informal U.S. imperialism in the form of political and financial hegemony. This internal form of imperialism is also distinct from the United States' formation of \"colonies\" abroad. Through the treatment of its indigenous peoples during westward expansion, the United States took on the form of an imperial power prior to any attempts at external imperialism. This internal form of empire has been referred to as \"internal colonialism\". Participation in the African slave trade and the subsequent treatment of its 12 to 15 million Africans is viewed by some to be a more modern extension of America's \"internal colonialism\". However, this internal colonialism faced resistance, as external colonialism did, but the anti-colonial presence was far less prominent due to the nearly complete dominance that the United States was able to assert over both indigenous peoples and African-Americans. In his lecture on April 16, 2003, Edward Said made a bold statement on modern imperialism in the United States, whom he described as using aggressive means of attack towards the contemporary Orient, \"due to their backward living, lack of democracy and the violation of women’s rights. The western world forgets during this process of converting the other that enlightenment and democracy are concepts that not all will agree upon\".</span><br /><span><b>Question:</b> the US expansion Westward could be viewed as what type of colonialism?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">\"internal colonialism\"</li><li style=\"color:blue\">internal colonialism</li><li style=\"color:blue\">internal colonialism</li><li style=\"color:blue\">internal colonialism</li><li style=\"color:blue\">internal</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=.=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.518%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[15] [15]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The Broncos defeated the Pittsburgh Steelers in the divisional round, 23–16, by scoring 11 points in the final three minutes of the game. They then beat the defending Super Bowl XLIX champion New England Patriots in the AFC Championship Game, 20–18, by intercepting a pass on New England's 2-point conversion attempt with 17 seconds left on the clock. Despite Manning's problems with interceptions during the season, he didn't throw any in their two playoff games.</span><br /><span><b>Question:</b> How many seconds were left in the game when the Patriots failed their 2-point conversion?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">17</li><li style=\"color:blue\">17</li><li style=\"color:blue\">17</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=11=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.695%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[37] [28]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Uptake of O\n",
       "2 from the air is the essential purpose of respiration, so oxygen supplementation is used in medicine. Treatment not only increases oxygen levels in the patient's blood, but has the secondary effect of decreasing resistance to blood flow in many types of diseased lungs, easing work load on the heart. Oxygen therapy is used to treat emphysema, pneumonia, some heart disorders (congestive heart failure), some disorders that cause increased pulmonary artery pressure, and any disease that impairs the body's ability to take up and use gaseous oxygen.</span><br /><span><b>Question:</b> By decreasing resistance to blood flow in the lungs, what organ's workload  can be eased?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">heart</li><li style=\"color:blue\">the heart</li><li style=\"color:blue\">heart</li><li style=\"color:blue\">the heart</li><li style=\"color:blue\">heart</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 0.465%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[120] [124]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Oxygen toxicity to the lungs and central nervous system can also occur in deep scuba diving and surface supplied diving. Prolonged breathing of an air mixture with an O\n",
       "2 partial pressure more than 60 kPa can eventually lead to permanent pulmonary fibrosis. Exposure to a O\n",
       "2 partial pressures greater than 160 kPa (about 1.6 atm) may lead to convulsions (normally fatal for divers). Acute oxygen toxicity (causing seizures, its most feared effect for divers) can occur by breathing an air mixture with 21% O\n",
       "2 at 66 m or more of depth; the same thing can occur by breathing 100% O\n",
       "2 at only 6 m.</span><br /><span><b>Question:</b> What health condition can deep sea diving cause?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Oxygen toxicity</li><li style=\"color:blue\">Oxygen toxicity</li><li style=\"color:blue\">Oxygen toxicity</li><li style=\"color:blue\">Oxygen toxicity</li><li style=\"color:blue\">Oxygen toxicity to the lungs and central nervous system</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=2 at only 6 m.=</span><br /><span style=\"color:green\"><b>Probability:</b> 1.831%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[87] [103]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Bolshevik leaders had effectively reestablished a polity with roughly the same extent as that empire by 1921, however with an internationalist ideology: Lenin in particular asserted the right to limited self-determination for national minorities within the new territory. Beginning in 1923, the policy of \"Indigenization\" [korenizatsiia] was intended to support non-Russians develop their national cultures within a socialist framework. Never formally revoked, it stopped being implemented after 1932. After World War II, the Soviet Union installed socialist regimes modeled on those it had installed in 1919–20 in the old Tsarist Empire in areas its forces occupied in Eastern Europe. The Soviet Union and the People’s Republic of China supported post–World War II communist movements in foreign nations and colonies to advance their own interests, but were not always successful.</span><br /><span><b>Question:</b> After WW-II where did Russia apply its old Tsarist regimes?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Eastern Europe</li><li style=\"color:blue\">Eastern Europe</li><li style=\"color:blue\">in areas its forces occupied in Eastern Europe</li><li style=\"color:blue\">1919–20</li><li style=\"color:blue\">Eastern Europe</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=, the Soviet Union installed socialist regimes modeled on those it had installed in 1919–20 in the=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.283%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[81] [94]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In 1973, Nixon named William E. Simon as the first Administrator of the Federal Energy Office, a short-term organization created to coordinate the response to the embargo. Simon allocated states the same amount of domestic oil for 1974 that each had consumed in 1972, which worked for states whose populations were not increasing. In other states, lines at gasoline stations were common. The American Automobile Association reported that in the last week of February 1974, 20% of American gasoline stations had no fuel.</span><br /><span><b>Question:</b> When was he elected by Nixon?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">In 1973</li><li style=\"color:blue\">1973</li><li style=\"color:blue\">1973</li><li style=\"color:blue\">1973</li><li style=\"color:blue\">1973</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=of February 1974, 20% of American gasoline stations had no fuel.=</span><br /><span style=\"color:green\"><b>Probability:</b> 2.608%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[95] [101]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In some rural areas in the United Kingdom, there are dispensing physicians who are allowed to both prescribe and dispense prescription-only medicines to their patients from within their practices. The law requires that the GP practice be located in a designated rural area and that there is also a specified, minimum distance (currently 1.6 kilometres) between a patient's home and the nearest retail pharmacy. This law also exists in Austria for general physicians if the nearest pharmacy is more than 4 kilometers away, or where none is registered in the city.</span><br /><span><b>Question:</b> Where are some physicians permitted to prescribe and give out medications within their practices?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">In some rural areas in the United Kingdom</li><li style=\"color:blue\">rural areas in the United Kingdom</li><li style=\"color:blue\">prescribe and dispense prescription-only medicines to their patients from within their practices</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=none is registered in the city.=</span><br /><span style=\"color:green\"><b>Probability:</b> 2.691%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for index in np.random.choice(len(valid_qas), size=25, replace=False):\n",
    "    id = valid_qas[index].id_\n",
    "    context = valid_qas[index].context\n",
    "    question = valid_qas[index].question\n",
    "\n",
    "    answers = []\n",
    "    for qa in valid_qas:\n",
    "        if id == qa.id_:\n",
    "            answers.append(qa.answer)\n",
    "\n",
    "    prediction, proba = inference(\n",
    "        model=model,\n",
    "        context=context,\n",
    "        question=question,\n",
    "        text_vocab=text_vocabulary,\n",
    "        pos_vocab=part_of_speech_vocabulary,\n",
    "        ner_vocab=named_entity_types_vocabulary,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    html = f'<p><span><b>Context:</b> {context.text}</span><br />'\n",
    "    html += f'<span><b>Question:</b> {question.text}</span><br />'\n",
    "    html += f'<span style=\"color:blue\"><b>Possible answers:</b><br /><ul>'\n",
    "    for answer in answers:\n",
    "        html += f'<li style=\"color:blue\">{answer.text}</li>'\n",
    "    html += '</ul></span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Prediction:</b>={prediction}=</span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Probability:</b> {proba * 100:.3f}%</span><br />'\n",
    "    display(HTML(html))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7JFJMsaEQAL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbESkBXxHvfxvShB4a49KZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1 - DrQA, Document reader Question Answering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
