{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dksifoua/Question-Answering/blob/master/1%20-%20DrQA%2C%20Document%20reader%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMGpLvYNKR78",
    "outputId": "a44642e8-e103-4b7c-eb0f-625a56ebe146",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct  4 19:31:03 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.01    Driver Version: 516.01       CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:08:00.0  On |                  N/A |\r\n",
      "|  0%   38C    P8    15W / 170W |    519MiB / 12288MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lP-9tyjdylTg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bm6QVw_hzHB7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tqdm --upgrade >> /dev/null 2>&1\n",
    "# !pip install spacy --upgrade >> /dev/null 2>&1\n",
    "# !python -m spacy download en_core_web_lg >> /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "bJQv4DSelwnB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import tqdm\n",
    "import spacy\n",
    "import pickle\n",
    "import random\n",
    "import string\n",
    "import itertools\n",
    "import functools\n",
    "import collections\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.tokens import Doc\n",
    "from typing import Any, Dict, List, NamedTuple, Union, Tuple\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /mnt/c/Users/dimit/PycharmProjects/Question-Answering/notebooks\n",
      "New current working directory: /mnt/c/Users/dimit/PycharmProjects/Question-Answering\n"
     ]
    }
   ],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "print(f\"Current working directory: {current_working_directory}\")\n",
    "\n",
    "if current_working_directory.split('/')[-1] == \"notebooks\":\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "print(f\"New current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    # torch.use_deterministic_algorithms(True)\n",
    "    # torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cw16-fZCDHHu",
    "outputId": "29d412de-e92b-46dc-d61e-f679089028fc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 546\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx9pL3Hiyn7c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare data\n",
    "\n",
    "***Download data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBy3v4Pke7dq",
    "outputId": "4d0d9d8a-d05a-4d3f-b1dd-545aa92ad6f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -rf ./data\n",
    "# !mkdir ./data\n",
    "#\n",
    "# !wget --no-check-certificate \\\n",
    "#     https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n",
    "#     -O ./data/train-v1.1.json\n",
    "#\n",
    "# !wget --no-check-certificate \\\n",
    "#     https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json \\\n",
    "#     -O ./data/dev-v1.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9H59xUnyvAR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Load JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class _UnpackingDataClassMixin:\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(dataclasses.astuple(self))\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Target(_UnpackingDataClassMixin):\n",
    "    start_index: int\n",
    "    end_index: int\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class RawDatasetItem(_UnpackingDataClassMixin):\n",
    "    id_: str\n",
    "    context: Doc\n",
    "    question: Doc\n",
    "    answer: Doc\n",
    "    answer_start_index: int\n",
    "    target: Target = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IbZQjhA5roqo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IO:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_json(path: str) -> Dict:\n",
    "        try:\n",
    "            with open(path, mode='r', encoding=\"utf-8\") as json_file:\n",
    "                return json.load(json_file)\n",
    "        except IOError:\n",
    "            raise IOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqjrkTxHr3rA",
    "outputId": "aeed0ca6-a730-499b-cd3c-8f2bed254f81",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of raw train data: 442\n",
      "Length of raw valid data: 48\n",
      "CPU times: user 407 ms, sys: 44.8 ms, total: 452 ms\n",
      "Wall time: 675 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_raw_data = IO.load_from_json(path=\"./data/train-v1.1.json\")\n",
    "valid_raw_data = IO.load_from_json(path=\"./data/dev-v1.1.json\")\n",
    "print(f\"Length of raw train data: {len(train_raw_data['data']):,}\")\n",
    "print(f\"Length of raw valid data: {len(valid_raw_data['data']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4sypWlVyxx-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Parse JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O-6GE3YxsQsl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_squad_v1_data(data: Dict, spacy_nlp: spacy.language.Language) -> List[RawDatasetItem]:\n",
    "    qas = []\n",
    "    disabled_components = [\"parser\", \"lemmatizer\", \"tagger\", \"ner\"]\n",
    "    for paragraphs in tqdm.tqdm(data[\"data\"]):\n",
    "        for paragraph in paragraphs[\"paragraphs\"]:\n",
    "            context = spacy_nlp(paragraph[\"context\"], disable=disabled_components[:1])\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                id_ = qa[\"id\"]\n",
    "                question = spacy_nlp(qa[\"question\"], disable=disabled_components)\n",
    "                for answer in qa[\"answers\"]:\n",
    "                    qas.append(RawDatasetItem(id_=id_, context=context, question=question,\n",
    "                                              answer=spacy_nlp(answer[\"text\"], disable=disabled_components),\n",
    "                                              answer_start_index=answer[\"answer_start\"]))\n",
    "    return qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MeqBr7Ov9ZU",
    "outputId": "2dad6d53-186e-41d5-dd61-0da6ac26c314",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [07:30<00:00,  1.02s/it]\n",
      "100%|██████████| 48/48 [01:21<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train qa pairs: 87,599\n",
      "Length of valid qa pairs: 34,726\n",
      "Train example: RawDatasetItem(id_='56cc100b6d243a140015ee8d', context=During the summers at Nohant, particularly in the years 1839–43, Chopin found quiet, productive days during which he composed many works, including his Polonaise in A-flat major, Op. 53. Among the visitors to Nohant were Delacroix and the mezzo-soprano Pauline Viardot, whom Chopin had advised on piano technique and composition. Delacroix gives an account of staying at Nohant in a letter of 7 June 1842:, question=On what date did Delacroix write a letter based on his visit at Nohant?, answer=7 June 1842, answer_start_index=393, target=None)\n",
      "CPU times: user 8min 50s, sys: 3.45 s, total: 8min 53s\n",
      "Wall time: 8min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "language = spacy.load(name=\"en_core_web_lg\")\n",
    "\n",
    "train_qas = parse_squad_v1_data(data=train_raw_data, spacy_nlp=language)\n",
    "valid_qas = parse_squad_v1_data(data=valid_raw_data, spacy_nlp=language)\n",
    "print(f\"Length of train qa pairs: {len(train_qas):,}\")\n",
    "print(f\"Length of valid qa pairs: {len(valid_qas):,}\")\n",
    "print(f\"Train example: {train_qas[random.randint(a=0, b=len(train_qas) - 1)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bafKgiFv1GHa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_answer_start_indexes(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        assert qa.answer.text == qa.context.text[qa.answer_start_index:qa.answer_start_index + len(qa.answer.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tTDTQod23-g",
    "outputId": "022c7d5f-cfbf-4b12-b4f9-e6882a9cef07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:03<00:00, 21973.32it/s]\n",
      "100%|██████████| 34726/34726 [00:01<00:00, 22938.37it/s]\n"
     ]
    }
   ],
   "source": [
    "test_answer_start_indexes(qas=train_qas)\n",
    "test_answer_start_indexes(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxhCfiNY28zs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Add targets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "k4bpqV3S27SQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_targets_to_squad_v1_data(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        for i in range(len(qa.context)):\n",
    "            if qa.context[i].idx == qa.answer_start_index:\n",
    "                answer = qa.context[i:i + len(qa.answer)]\n",
    "                qa.target = Target(start_index=answer[0].i, end_index=answer[-1].i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waJedA674CCH",
    "outputId": "84672e5a-a68e-473b-8be8-c7a2e10a0698",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:02<00:00, 38221.87it/s]\n",
      "100%|██████████| 34726/34726 [00:00<00:00, 39306.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 50 ms, total: 3.2 s\n",
      "Wall time: 3.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "add_targets_to_squad_v1_data(qas=train_qas)\n",
    "add_targets_to_squad_v1_data(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lT65eePm4F9w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_bad_item(qa: RawDatasetItem) -> bool:\n",
    "    \"\"\"Return True if either the target is None or target indexes don't match the answer. Return False otherwise\"\"\"\n",
    "    if qa.target is None:\n",
    "        return False\n",
    "    return qa.answer.text == qa.context[qa.target.start_index:qa.target.end_index + 1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_nUlM_n4Mgc",
    "outputId": "cde0cb35-dd18-4ba5-f4a4-a63a46ec6db7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train qa pairs after filtering out bad qa pairs: 86,676\n",
      "Length of valid qa pairs after filtering out bad qa pairs: 34,364\n",
      "CPU times: user 740 ms, sys: 80 µs, total: 740 ms\n",
      "Wall time: 738 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qas = [*filter(is_bad_item, train_qas)]\n",
    "valid_qas = [*filter(is_bad_item, valid_qas)]\n",
    "print(f\"Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}\")\n",
    "print(f\"Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qKEhn4eI4P5B",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_targets(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in qas:\n",
    "        assert qa.answer.text == qa.context[qa.target.start_index:qa.target.end_index + 1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6O_fmDJl5R7V",
    "outputId": "999e5ada-e4ec-44ae-f40c-682b08cbb7b6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 680 ms, sys: 0 ns, total: 680 ms\n",
      "Wall time: 678 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_targets(qas=train_qas)\n",
    "test_targets(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkLppZOP5Vju",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Add features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "O8Y038pt5VIc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TokenFeature(_UnpackingDataClassMixin):\n",
    "    exact_match: List[bool]\n",
    "    part_of_speech: List[str]\n",
    "    named_entity_type: List[str]\n",
    "    normalized_term_frequency: List[float]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DrQARawDatasetItem(RawDatasetItem):\n",
    "    token_feature: TokenFeature = None\n",
    "\n",
    "\n",
    "def add_extra_features_squad_v1(qas: List[RawDatasetItem]) -> List[DrQARawDatasetItem]:\n",
    "    \"\"\"Add extra features: Exact Match, Part-of-Speech, Name Entity Recognition & Normalized Term Frequency\"\"\"\n",
    "    qa_token_features = []\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        question = [token.text.lower() for token in qa.question]\n",
    "        count_context_tokens = collections.Counter(map(lambda token: token.text.lower(), qa.context))\n",
    "\n",
    "        frequency_context_tokens: Dict[int, int] = {}\n",
    "        for index, token in enumerate(qa.context):  # type: int, Token\n",
    "            frequency_context_tokens[index] = count_context_tokens[token.text.lower()]\n",
    "        norm_frequency_context_tokens = sum(frequency_context_tokens.values())\n",
    "\n",
    "        token_feature = TokenFeature(\n",
    "            exact_match=[qa.context[index].text.lower() in question for index in range(len(qa.context))],\n",
    "            part_of_speech=[qa.context[index].tag_ for index in range(len(qa.context))],\n",
    "            named_entity_type=[qa.context[index].ent_type_ for index in range(len(qa.context))],\n",
    "            normalized_term_frequency=[\n",
    "                frequency_context_tokens[index] / norm_frequency_context_tokens for index in range(len(qa.context))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        qa_token_features.append(\n",
    "            DrQARawDatasetItem(\n",
    "                id_=qa.id_,\n",
    "                context=qa.context,\n",
    "                question=qa.question,\n",
    "                answer=qa.answer,\n",
    "                answer_start_index=qa.answer_start_index,\n",
    "                target=qa.target,\n",
    "                token_feature=token_feature\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return qa_token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqwcbDgPSmp8",
    "outputId": "8df2a4a8-4c18-478b-980e-16ab98a78e3a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86676/86676 [00:27<00:00, 3155.07it/s]\n",
      "100%|██████████| 34364/34364 [00:10<00:00, 3360.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 1.33 s, total: 37.9 s\n",
      "Wall time: 37.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qas = add_extra_features_squad_v1(qas=train_qas)\n",
    "valid_qas = add_extra_features_squad_v1(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8SrKXlfoU5y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build vocabularies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, padding_token: str, unknown_token: str):\n",
    "        self.padding_token = padding_token\n",
    "        self.unknown_token = unknown_token\n",
    "\n",
    "        self.vocabulary: List[str] = []\n",
    "        self.word2count: Dict[str, int] = {}\n",
    "        self.word2index: Dict[str, int] = {}\n",
    "        self.index2word: Dict[int, str] = {}\n",
    "\n",
    "    def build(self, data: List[Union[Doc, str]], min_word_frequency: int) -> None:\n",
    "        words = []\n",
    "\n",
    "        type_ = type(data[0])\n",
    "        if type_ == Doc:\n",
    "            for item in data:  # Doc\n",
    "                words += [word.text.lower() for word in item]\n",
    "        elif type_ == str:\n",
    "            words += data\n",
    "        else:\n",
    "            raise TypeError(f\"The type {type_} is not supported!\")\n",
    "\n",
    "        self.word2count = collections.Counter(words)\n",
    "        self.vocabulary = [self.padding_token] + sorted(filter(\n",
    "            lambda word: self.word2count[word] >= min_word_frequency,\n",
    "            self.word2count\n",
    "        )) + [self.unknown_token]\n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocabulary)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocabulary)}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.vocabulary)\n",
    "\n",
    "    def stoi(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        Return the index of the word in the vocabulary.\n",
    "        Return the index of the unknown token if that word doesn't exist in the vocabulary.\n",
    "        \"\"\"\n",
    "        return self.word2index.get(word, self.word2index[self.unknown_token])\n",
    "\n",
    "    def itos(self, index: int) -> str:\n",
    "        \"\"\"Return the word of the index in the vocabulary.\"\"\"\n",
    "        return self.index2word[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of id vocabulary: 97,200\n",
      "Length of text vocabulary: 26,884\n",
      "Length of part of speech vocabulary: 52\n",
      "Length of named entity type vocabulary: 21\n",
      "CPU times: user 14.4 s, sys: 170 ms, total: 14.6 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PADDING_TOKEN = \"<pad>\"\n",
    "UNKNOWN_TOKEN = \"<unk>\"\n",
    "MIN_FREQUENCY = 5\n",
    "\n",
    "ids = [*map(lambda qa: qa.id_, train_qas)] + [*map(lambda qa: qa.id_, valid_qas)]\n",
    "contexts, questions = zip(*map(lambda qa: (qa.context, qa.question), train_qas))\n",
    "part_of_speeches = [*itertools.chain.from_iterable(map(lambda qa: qa.token_feature.part_of_speech, train_qas))]\n",
    "named_entity_types = [*itertools.chain.from_iterable(map(lambda qa: qa.token_feature.named_entity_type, train_qas))]\n",
    "\n",
    "id_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "text_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "part_of_speech_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "named_entity_types_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "\n",
    "id_vocabulary.build(data=[*set(ids)], min_word_frequency=0)\n",
    "text_vocabulary.build(data=[*set(contexts + questions)], min_word_frequency=MIN_FREQUENCY)\n",
    "part_of_speech_vocabulary.build(data=[*set(part_of_speeches)], min_word_frequency=0)\n",
    "named_entity_types_vocabulary.build(data=[*set(named_entity_types)], min_word_frequency=0)\n",
    "\n",
    "print(f\"Length of id vocabulary: {len(id_vocabulary):,}\")\n",
    "print(f\"Length of text vocabulary: {len(text_vocabulary):,}\")\n",
    "print(f\"Length of part of speech vocabulary: {len(part_of_speech_vocabulary):,}\")\n",
    "print(f\"Length of named entity type vocabulary: {len(named_entity_types_vocabulary):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "iotg02zlAflQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class DrQATensorDatasetItem(_UnpackingDataClassMixin):\n",
    "    id_: torch.LongTensor\n",
    "    context: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]\n",
    "    question: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]\n",
    "    target: torch.LongTensor\n",
    "    exact_match: torch.LongTensor\n",
    "    part_of_speech: torch.LongTensor\n",
    "    named_entity_type: torch.LongTensor\n",
    "    normalized_term_frequency: torch.FloatTensor\n",
    "\n",
    "\n",
    "class SquadV1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: List[DrQARawDatasetItem], id_vocab: Vocabulary, text_vocab: Vocabulary,\n",
    "                 pos_vocab: Vocabulary, ner_vocab: Vocabulary):\n",
    "        self.data = data\n",
    "        self.id_vocab = id_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.text_vocab = text_vocab\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> DrQATensorDatasetItem:\n",
    "        item: DrQARawDatasetItem = self.data[idx]\n",
    "        id_ = torch.LongTensor([self.id_vocab.stoi(item.id_)])\n",
    "        context = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item.context)])\n",
    "        question = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item.question)])\n",
    "        target = torch.LongTensor([item.target.start_index, item.target.end_index])\n",
    "        exact_match = torch.LongTensor(item.token_feature.exact_match)\n",
    "        part_of_speech = torch.LongTensor(\n",
    "            [*map(lambda token: self.pos_vocab.stoi(token), item.token_feature.part_of_speech)])\n",
    "        named_entity_type = torch.LongTensor(\n",
    "            [*map(lambda token: self.ner_vocab.stoi(token), item.token_feature.named_entity_type)])\n",
    "        normalized_term_frequency = torch.FloatTensor(item.token_feature.normalized_term_frequency)\n",
    "        return DrQATensorDatasetItem(\n",
    "            id_=id_,\n",
    "            context=context,\n",
    "            question=question,\n",
    "            target=target,\n",
    "            exact_match=exact_match,\n",
    "            part_of_speech=part_of_speech,\n",
    "            named_entity_type=named_entity_type,\n",
    "            normalized_term_frequency=normalized_term_frequency\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMgSisEt8ARe",
    "outputId": "735861e8-f6c2-49bb-b8e8-7d5da12ef11a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_ shape: torch.Size([1])\n",
      "context shape: torch.Size([142])\n",
      "question shape: torch.Size([14])\n",
      "target shape: torch.Size([2])\n",
      "exact_match shape: torch.Size([142])\n",
      "part_of_speech shape: torch.Size([142])\n",
      "named_entity_type shape: torch.Size([142])\n",
      "normalized_term_frequency shape: torch.Size([142])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SquadV1Dataset(\n",
    "    data=train_qas,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    pos_vocab=part_of_speech_vocabulary,\n",
    "    ner_vocab=named_entity_types_vocabulary\n",
    ")\n",
    "valid_dataset = SquadV1Dataset(\n",
    "    data=valid_qas,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    pos_vocab=part_of_speech_vocabulary,\n",
    "    ner_vocab=named_entity_types_vocabulary\n",
    ")\n",
    "\n",
    "train_dataset_item = train_dataset[0]\n",
    "print(f\"id_ shape: {train_dataset_item.id_.shape}\")\n",
    "print(f\"context shape: {train_dataset_item.context.shape}\")\n",
    "print(f\"question shape: {train_dataset_item.question.shape}\")\n",
    "print(f\"target shape: {train_dataset_item.target.shape}\")\n",
    "print(f\"exact_match shape: {train_dataset_item.exact_match.shape}\")\n",
    "print(f\"part_of_speech shape: {train_dataset_item.part_of_speech.shape}\")\n",
    "print(f\"named_entity_type shape: {train_dataset_item.named_entity_type.shape}\")\n",
    "print(f\"normalized_term_frequency shape: {train_dataset_item.normalized_term_frequency.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZQaVaHt_MDc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build data loaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "cYMYz3-SBYzf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DrQATensorDatasetBatch = DrQATensorDatasetItem\n",
    "\n",
    "def add_padding_and_batch_data(batch: List[DrQATensorDatasetItem], id_vocab: Vocabulary, text_vocab: Vocabulary,\n",
    "                               pos_vocab: Vocabulary, ner_vocab: Vocabulary, include_lengths: bool,\n",
    "                               device: torch.device) -> DrQATensorDatasetBatch:\n",
    "    batch_id = [item.id_ for item in batch]\n",
    "    batch_context = [item.context for item in batch]\n",
    "    batch_question = [item.question for item in batch]\n",
    "    batch_target = [item.target for item in batch]\n",
    "    batch_exact_match = [item.exact_match for item in batch]\n",
    "    batch_part_of_speech = [item.part_of_speech for item in batch]\n",
    "    batch_named_entity_type = [item.named_entity_type for item in batch]\n",
    "    batch_normalized_term_frequency = [item.normalized_term_frequency for item in batch]\n",
    "\n",
    "    length_context, length_question = None, None\n",
    "    if include_lengths:\n",
    "        length_context = torch.LongTensor([context.size(0) for context in batch_context])  # .to(device)\n",
    "        length_question = torch.LongTensor([question.size(0) for question in batch_question])  # .to(device)\n",
    "\n",
    "    batch_padded_id = pad_sequence(batch_id,\n",
    "                                   batch_first=True,\n",
    "                                   padding_value=id_vocab.stoi(id_vocab.padding_token)).to(device)\n",
    "    batch_padded_context = pad_sequence(batch_context,\n",
    "                                        batch_first=True,\n",
    "                                        padding_value=text_vocab.stoi(text_vocab.padding_token)).to(device)\n",
    "    batch_padded_question = pad_sequence(batch_question,\n",
    "                                         batch_first=True,\n",
    "                                         padding_value=text_vocab.stoi(text_vocab.padding_token)).to(device)\n",
    "    batch_padded_target = pad_sequence(batch_target, batch_first=True).to(device)\n",
    "    batch_padded_exact_match = pad_sequence(batch_exact_match, batch_first=True).to(device)\n",
    "    batch_padded_part_of_speech = pad_sequence(batch_part_of_speech,\n",
    "                                               batch_first=True,\n",
    "                                               padding_value=pos_vocab.stoi(pos_vocab.padding_token)).to(device)\n",
    "    batch_padded_normalized_term_frequency = pad_sequence(batch_normalized_term_frequency, batch_first=True).to(device)\n",
    "    batch_padded_named_entity_type = pad_sequence(batch_named_entity_type,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=ner_vocab.stoi(ner_vocab.padding_token)).to(device)\n",
    "    return DrQATensorDatasetBatch(\n",
    "        id_=batch_padded_id,\n",
    "        context=(batch_padded_context, length_context),\n",
    "        question=(batch_padded_question, length_question),\n",
    "        target=batch_padded_target,\n",
    "        exact_match=batch_padded_exact_match,\n",
    "        part_of_speech=batch_padded_part_of_speech,\n",
    "        named_entity_type=batch_padded_named_entity_type,\n",
    "        normalized_term_frequency=batch_padded_normalized_term_frequency\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zu2ovPqxA7Ix",
    "outputId": "02a52daa-a8ec-45de-c916-995fe7e860c4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs: torch.Size([32, 1])\n",
      "Context: torch.Size([32, 253]) torch.Size([32])\n",
      "Question: torch.Size([32, 19]) torch.Size([32])\n",
      "Target: torch.Size([32, 2])\n",
      "Exact match: torch.Size([32, 253])\n",
      "Part of speech: torch.Size([32, 253])\n",
      "Named entity type: torch.Size([32, 253])\n",
      "Normalized term frequency: torch.Size([32, 253])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "collate_function = functools.partial(add_padding_and_batch_data,\n",
    "                                     id_vocab=id_vocabulary,\n",
    "                                     text_vocab=text_vocabulary,\n",
    "                                     pos_vocab=part_of_speech_vocabulary,\n",
    "                                     ner_vocab=named_entity_types_vocabulary,\n",
    "                                     include_lengths=True,\n",
    "                                     device=DEVICE)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_function)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_function)\n",
    "\n",
    "for batch in train_dataloader:  # type: DrQATensorDatasetBatch\n",
    "    print(\"IDs:\", batch.id_.shape)\n",
    "    print(\"Context:\", batch.context[0].shape, batch.context[1].shape)\n",
    "    print(\"Question:\", batch.question[0].shape, batch.question[1].shape)\n",
    "    print(\"Target:\", batch.target.shape)\n",
    "    print(\"Exact match:\", batch.exact_match.shape)\n",
    "    print(\"Part of speech:\", batch.part_of_speech.shape)\n",
    "    print(\"Named entity type:\", batch.named_entity_type.shape)\n",
    "    print(\"Normalized term frequency:\", batch.normalized_term_frequency.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2O79r_CLvGu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Download pretrained GloVe embedding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrSXYalOmRak",
    "outputId": "bc303808-01ad-4f75-c884-0a337681eb7b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# !wget --no-check-certificate \\\n",
    "#     http://nlp.stanford.edu/data/glove.840B.300d.zip \\\n",
    "#     -O ./data/glove.840B.300d.zip\n",
    "# !unzip -q ./data/glove.840B.300d.zip -d ./data\n",
    "# !rm -r ./data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "BL0JZuEmmf5C",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def load_glove_embeddings(path: str) -> Dict[str, np.ndarray]:\n",
    "#     glove_embeddings = {}\n",
    "#     try:\n",
    "#         file = open(path, mode='r', encoding=\"utf-8\")\n",
    "#         for line in tqdm.tqdm(file):\n",
    "#             values = line.split(' ')\n",
    "#             glove_embeddings[values[0]] = np.asarray(values[1:], dtype=\"float32\")\n",
    "#         return glove_embeddings\n",
    "#     except IOError:\n",
    "#         raise IOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDX8b2EJm1uZ",
    "outputId": "c477bc5e-4b5f-4880-8916-fa53fd7ef300",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# glove = load_glove_embeddings(path=\"./data/glove.840B.300d.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# text_vocabulary.word2count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "ELVYepbbm7ny",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def extract_embeddings(glove_embeddings: Dict[str, np.ndarray], text_vocab: Vocabulary, embedding_size: int, most_common: int) -> Tuple[np.ndarray, int, List[int]]:\n",
    "#     most_common_words = [*map(lambda x: x[0], text_vocab.word2count.most_common(most_common))]\n",
    "#     most_common_words = [*filter(lambda word: word in text_vocab.vocabulary, most_common_words)]\n",
    "#     embedding_matrix = np.zeros((len(text_vocab), embedding_size))\n",
    "#     most_common_indexes, n_words = [], 0\n",
    "#     for index, word in enumerate(text_vocab.vocabulary):\n",
    "#         if word in most_common_words:\n",
    "#             most_common_indexes.append(index)\n",
    "#         try:\n",
    "#             embedding_matrix[index] = glove[word]\n",
    "#             n_words += 1\n",
    "#         except KeyError:\n",
    "#             pass\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#     return embedding_matrix, n_words, most_common_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3CUDosl_n5HA",
    "outputId": "ce6edfc0-2a4e-41ba-dc6d-8ddf703b6501",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embedding_matrix, n_words, most_common_indexes = extract_embeddings(glove_embeddings=glove, text_vocab=text_vocabulary, embedding_size=300, most_common=1000)\n",
    "# print(f\"Words found: {n_words}/{len(text_vocabulary)}\")\n",
    "# np.save(\"../data/GloVe_DrQA.npy\", embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# n_words = 0\n",
    "# for word in tqdm.tqdm(text_vocabulary.vocabulary, total=len(text_vocabulary.vocabulary)):\n",
    "#     if nlp(word).has_vector:\n",
    "#         n_words += 1\n",
    "# print(f\"Words found: {n_words}/{len(text_vocabulary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "JZzbAOFAmfnT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Free up the RAM\n",
    "# del glove\n",
    "# del embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxnYdks-L31E",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeling\n",
    "\n",
    "***Stacked Bidirectional LSTM Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "DoHYvqQQCEGw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StackedBiLSTMsLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size: int, hidden_size: int, n_layers: int, dropout: float):\n",
    "        \"\"\"\n",
    "        :param embedding_size: Size of word embedding.\n",
    "        :param hidden_size: Hidden size of lstm layers.\n",
    "        :param n_layers: Number of layers.\n",
    "        :param dropout: Dropout value in [0, 1).\n",
    "        \"\"\"\n",
    "        super(StackedBiLSTMsLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=embedding_size if i == 0 else hidden_size * 2, hidden_size=hidden_size,\n",
    "                batch_first=True, num_layers=n_layers, bidirectional=True\n",
    "            ) for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def __forward_lstm(self, layer: nn.Module, inputs: Tensor, lengths: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        :param layer: LSTM layer.\n",
    "        :param inputs: Sequence inputs. FloatTensor[batch_size, seq_len, embedding_size|hidden_size * 2]\n",
    "        :param lengths: Sequence lengths. LongTensor[batch_size,]\n",
    "        :return:\n",
    "            padded_outputs FloatTensor[batch_size, seq_len, hidden_size * 2]\n",
    "            outputs_lengths LongTensor[batch_size,]\n",
    "        \"\"\"\n",
    "        seq_len = inputs.size(1)\n",
    "        inputs = self.dropout(inputs)\n",
    "        packed_inputs = pack_padded_sequence(input=inputs, lengths=lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_outputs, _ = layer(packed_inputs)\n",
    "        padded_outputs, outputs_lengths = pad_packed_sequence(sequence=packed_outputs,\n",
    "                                                              batch_first=True,\n",
    "                                                              total_length=seq_len)\n",
    "        return padded_outputs, outputs_lengths\n",
    "\n",
    "    def forward(self, embedded_inputs: Tensor, sequence_lengths: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param embedded_inputs: Sequence inputs. FloatTensor[batch_size, seq_len, embedding_size]\n",
    "        :param sequence_lengths: Sequence lengths. LongTensor[batch_size,]\n",
    "        :return: FloatTensor[batch_size, sequence_lengths, n_layers * hidden_size * 2]\n",
    "        \"\"\"\n",
    "        outputs, lens = [embedded_inputs], sequence_lengths\n",
    "        for lstm_layer in self.lstm_layers:\n",
    "            out, lens = self.__forward_lstm(layer=lstm_layer, inputs=outputs[-1], lengths=lens)\n",
    "            outputs.append(out)\n",
    "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oazq30eW3_T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Aligned Question Embedding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "ATOQC6-pWzq_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlignedQuestionEmbeddingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size: int, hidden_size: int):\n",
    "        \"\"\"\n",
    "        Aligned Question Embedding\n",
    "        $$f_{align}(p_i) = \\sum_j a_{i, j}E(q_j)$$\n",
    "        where the attention score $a_{i, j}$ captures the similarity between $p_i$ and each question words $q_j$.\n",
    "        Specifically, $a_{i, j}$ is computed by the dot products between nonlinear mappings of word embeddings:\n",
    "        $$a_{i, j} = \\frac{exp(\\alpha(E(p_i)).\\alpha(E(q_j)))}{\\sum_{j'}exp(\\alpha(E(p_i)).\\alpha(E(q_{j'})))}$$,\n",
    "        and $\\alpha(.)$ is a single dense layer with ReLU non-linearity. Compared to the exact match features, these\n",
    "        features add soft alignments between similar but non-identical words (e.g., car and vehicle)\n",
    "\n",
    "        :param embedding_size: Size of word embedding.\n",
    "        :param hidden_size: Hidden size of the dense layer.\n",
    "        \"\"\"\n",
    "        super(AlignedQuestionEmbeddingLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.dense = nn.Linear(in_features=embedding_size, out_features=hidden_size)\n",
    "\n",
    "    def forward(self, context_sequence: Tensor, question_sequence: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param context_sequence: Sequence context inputs. FloatTensor[batch_size, ctx_seq_len, embedding_size]\n",
    "        :param question_sequence: Sequence question inputs. FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, ctx_seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        context_logits = F.relu(self.dense(context_sequence))  # [batch_size, ctx_seq_len, hidden_size]\n",
    "        question_logits = F.relu(self.dense(question_sequence))  # [batch_size, qst_seq_len, hidden_size]\n",
    "        scores = torch.bmm(context_logits, question_logits.transpose(-1, -2))  # [batch_size, ctx_seq_len, qst_seq_len]\n",
    "        # Mask scores in order to force attention weights corresponding to padding tokens to be 0.\n",
    "        scores = scores.masked_fill(question_mask.unsqueeze(1) == 0, float(\"-inf\"))\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # [batch_size, ctx_seq_len, qst_seq_len]\n",
    "        return torch.bmm(attention_weights, question_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImX8ayztYjsK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Question Encoding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "Whil-FgVYhgy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionEncodingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size: int, hidden_size: int, n_layers: int, dropout: float):\n",
    "        \"\"\"\n",
    "        The question encoding consists of applying a recurrent neural network on top of the word embeddings of $q_i$\n",
    "        and combine the resulting hidden units into one single vector: $\\{q_1, ..., q_l\\} \\rightarrow q$. We compute\n",
    "        $q = \\sum_j{b_j q_j}$ where $b_j$ encodes the importance of each question word:\n",
    "        $$b_j = \\frac{exp(w.q_j)}{\\sum_{j'}{exp(w.q_{j'})}}$$\n",
    "        and $w$ is a weight vector to learn\n",
    "\n",
    "        :param embedding_size:\n",
    "        :param hidden_size:\n",
    "        :param n_layers:\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super(QuestionEncodingLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.stacked_bilstm_layers = StackedBiLSTMsLayer(\n",
    "            embedding_size=embedding_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout\n",
    "        )\n",
    "        self.dense = nn.Linear(in_features=embedding_size, out_features=1, bias=False)\n",
    "\n",
    "    def __linear_self_attention(self, question_embedded: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param question_embedded: FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, qst_seq_len]\n",
    "        \"\"\"\n",
    "        scores = self.dense(question_embedded).squeeze(-1)  # [batch_size, qst_seq_len]\n",
    "        scores = scores.masked_fill(question_mask == 0, float(\"-inf\"))\n",
    "        return F.softmax(scores, dim=-1)\n",
    "\n",
    "    def forward(self, question_embedded: Tensor, question_lengths: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param question_embedded: FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_lengths: Sequence question lengths. LongTensor[batch_size,]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, n_layers * hidden_size * 2]\n",
    "        \"\"\"\n",
    "        lstm_outputs = self.stacked_bilstm_layers(embedded_inputs=question_embedded, sequence_lengths=question_lengths)\n",
    "        # lstm_outputs: [batch_size, qst_seq_len, n_layers * hidden_size * 2]\n",
    "        attention_weights = self.__linear_self_attention(\n",
    "            question_embedded=question_embedded, question_mask=question_mask\n",
    "        )  # [batch_size, qst_seq_len]\n",
    "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hFIZnmUaFAu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***BiLinear Attention Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "JZGOH3IhaEZw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BiLinearAttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, context_hidden_size: int, question_hidden_size: int):\n",
    "        \"\"\"\n",
    "        At the paragraph level, the goal is to predict the span of tokens that is most likely the correct answer.\n",
    "        We take the paragraph vectors $\\{p_1, ... , p_m\\}$ and the question vector $q$ as input, and simply train two\n",
    "        classifiers independently for predicting the two ends of the span.\n",
    "        Concretely, we use a bi-linear term to capture the similarity between $p_i$ and $q$ and compute the\n",
    "        probabilities of each token being start and end as:\n",
    "        $$\n",
    "        P_{start}(i) \\propto exp(p_i W_s q) \\\\\n",
    "        P_{end}(i) \\propto exp(p_i W_e q)\n",
    "        $$\n",
    "\n",
    "        :param context_hidden_size:\n",
    "        :param question_hidden_size:\n",
    "        \"\"\"\n",
    "        super(BiLinearAttentionLayer, self).__init__()\n",
    "        self.context_hidden_size = context_hidden_size\n",
    "        self.question_hidden_size = question_hidden_size\n",
    "\n",
    "        self.dense = nn.Linear(in_features=question_hidden_size, out_features=context_hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, context_encoded: Tensor, question_encoded: Tensor, context_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param context_encoded: FloatTensor[batch_size, ctx_seq_len, ctx_hid_size]\n",
    "        :param question_encoded: FloatTensor[batch_size, qst_seq_len]\n",
    "        :param context_mask: IntTensor[batch_size, ctx_seq_len]\n",
    "        :return FloatTensor[batch_size, ctx_seq_len]\n",
    "        \"\"\"\n",
    "        question_encoded = self.dense(question_encoded)  # [batch_size, ctx_hid_size]\n",
    "        scores = torch.bmm(context_encoded, question_encoded.unsqueeze(-1)).squeeze(-1)  # [batch_size, ctx_seq_len]\n",
    "        return scores.masked_fill(context_mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzrmk6D7agHH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Document reader Question Answering Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "qlZlTFXOae_o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "    def make_sequence_mask(self, input_sequence: Tensor) -> Tensor:\n",
    "        return input_sequence != self.padding_index\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(starts: Tensor, ends: Tensor) -> Tuple[List[int], List[int], List[float]]:\n",
    "        \"\"\"\n",
    "        :param starts: FloatTensor[batch_size, ctx_seq_len]\n",
    "        :param ends: FloatTensor[batch_size, ctx_seq_len]\n",
    "        :return: Tuple[List[int], List[int], List[float]]\n",
    "        \"\"\"\n",
    "        start_indexes, end_indexes, predicted_probabilities = [], [], []\n",
    "        for i in range(starts.size(0)):\n",
    "            probabilities = torch.ger(starts[i], ends[i])  # [ctx_seq_len, ctx_seq_len]\n",
    "            probability, index = torch.topk(probabilities.view(-1), k=1)\n",
    "\n",
    "            start_indexes.append(index.tolist()[0] // probabilities.size(0))\n",
    "            end_indexes.append(index.tolist()[0] % probabilities.size(1))\n",
    "\n",
    "            predicted_probabilities.append(probability.tolist()[0])\n",
    "\n",
    "        return start_indexes, end_indexes, predicted_probabilities\n",
    "\n",
    "    def count_parameters(self) -> int:\n",
    "        return sum(parameter.numel() for parameter in self.parameters() if parameter.requires_grad)\n",
    "\n",
    "\n",
    "class DrQA(BaseModel):\n",
    "    \n",
    "    def __init__(self, vocabulary_size: int, embedding_size, n_extra_features: int, hidden_size: int, n_layers: int,\n",
    "                 dropout: float, padding_index: int):\n",
    "        \"\"\"\n",
    "        During prediction, we choose the best span from token $i$ to token $i'$ such that $i ≤ i' ≤ i + 15$ and\n",
    "        $P_{start}(i)×P_{end}(i')$ is maximized. To make score compatible across paragraphs in one or several retrieved\n",
    "        documents, we use the un-normalized exponential and take argmax over all considered paragraph spans for our\n",
    "        final prediction.\n",
    "\n",
    "        :param vocabulary_size:\n",
    "        :param embedding_size:\n",
    "        :param n_extra_features:\n",
    "        :param hidden_size:\n",
    "        :param n_layers:\n",
    "        :param dropout:\n",
    "        :param padding_index:\n",
    "        \"\"\"\n",
    "        super(DrQA, self).__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_extra_features = n_extra_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.padding_index = padding_index\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=vocabulary_size,\n",
    "            embedding_dim=embedding_size,\n",
    "            padding_idx=padding_index\n",
    "        )\n",
    "        self.aligned_question_embedding_layer = AlignedQuestionEmbeddingLayer(\n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size\n",
    "        )\n",
    "        self.context_lstm_layer = StackedBiLSTMsLayer(\n",
    "            embedding_size=embedding_size + hidden_size + n_extra_features,\n",
    "            hidden_size=hidden_size,\n",
    "            n_layers=n_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.question_encoding_layer = QuestionEncodingLayer(\n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=dropout,\n",
    "            n_layers=n_layers\n",
    "        )\n",
    "        self.bilinear_attention_start_layer = BiLinearAttentionLayer(\n",
    "            context_hidden_size=hidden_size * n_layers * 2,\n",
    "            question_hidden_size=hidden_size * n_layers * 2\n",
    "        )\n",
    "        self.bilinear_attention_end_layer = BiLinearAttentionLayer(\n",
    "            context_hidden_size=hidden_size * n_layers * 2,\n",
    "            question_hidden_size=hidden_size * n_layers * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: DrQATensorDatasetBatch) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        :param batch: DrQATensorDatasetBatch\n",
    "        :return: Tuple[FloatTensor[batch_size, ctx_seq_len], FloatTensor[batch_size, ctx_seq_len]]\n",
    "        \"\"\"\n",
    "        context_sequence = batch.context[0]  # [batch_size, ctx_seq_len]\n",
    "        context_lengths = batch.context[1]  # [batch_size,]\n",
    "        question_sequence = batch.question[0]  # [batch_size, qst_seq_len]\n",
    "        question_lengths = batch.question[1]  # [batch_size,]\n",
    "        exact_matches = batch.exact_match  # [batch_size, ctx_seq_len]\n",
    "        part_of_speeches = batch.part_of_speech  # [batch_size, ctx_seq_len]\n",
    "        named_entity_types = batch.named_entity_type  # [batch_size, ctx_seq_len]\n",
    "        normalized_term_frequencies = batch.normalized_term_frequency  # [batch_size, ctx_seq_len]\n",
    "\n",
    "        context_mask = self.make_sequence_mask(input_sequence=context_sequence)  # [batch_size, ctx_seq_len]\n",
    "        question_mask = self.make_sequence_mask(input_sequence=question_sequence)  # [batch_size, qst_seq_len]\n",
    "\n",
    "        context_embedded = self.embedding_layer(context_sequence)  # [batch_size, ctx_seq_len, embedding_size]\n",
    "        question_embedded = self.embedding_layer(question_sequence)  # [batch_size, qst_seq_len, embedding_size]\n",
    "\n",
    "        context_aligned = self.aligned_question_embedding_layer(\n",
    "            context_sequence=context_embedded,\n",
    "            question_sequence=question_embedded,\n",
    "            question_mask=question_mask\n",
    "        )  # [batch_size, ctx_len, embedding_size]\n",
    "\n",
    "        context_inputs = torch.cat([\n",
    "            context_aligned, context_embedded, exact_matches.unsqueeze(-1), part_of_speeches.unsqueeze(-1),\n",
    "            named_entity_types.unsqueeze(-1), normalized_term_frequencies.unsqueeze(-1)\n",
    "        ], dim=-1)  # [batch_size, ctx_seq_len, embedding_size + hidden_size + 4]\n",
    "\n",
    "        context_encoded = self.context_lstm_layer(\n",
    "            embedded_inputs=context_inputs,\n",
    "            sequence_lengths=context_lengths\n",
    "        )  # [batch_size, ctx_seq_len, n_layers * hidden_size * 2]\n",
    "        question_encoded = self.question_encoding_layer(\n",
    "            question_embedded=question_embedded,\n",
    "            question_lengths=question_lengths,\n",
    "            question_mask=question_mask\n",
    "        )  # [batch_size, n_layers * hidden_size * 2]\n",
    "\n",
    "        start_scores = self.bilinear_attention_start_layer(\n",
    "            context_encoded=context_encoded,\n",
    "            question_encoded=question_encoded,\n",
    "            context_mask=context_mask\n",
    "        )  # [batch_size, ctx_seq_len]\n",
    "        end_scores = self.bilinear_attention_end_layer(\n",
    "            context_encoded=context_encoded,\n",
    "            question_encoded=question_encoded,\n",
    "            context_mask=context_mask\n",
    "        )  # [batch_size, ctx_seq_len]\n",
    "        return start_scores, end_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x575iXlz3w4m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Training routines***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "31k5BZf43uV4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    # TODO\n",
    "    #  Add typing\n",
    "\n",
    "    def __init__(self):\n",
    "        self.value = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "        self.average = 0.\n",
    "\n",
    "    def reset(self):\n",
    "        self.value = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "        self.average = 0.\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.value = value\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "        self.average = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "qSmh2GmU4KXH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(answer: str) -> str:\n",
    "    \"\"\"Performs a series of cleaning steps on the ground truth and predicted answer.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(answer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "hi2JHYTX6F6A",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(prediction: str, ground_truth: str) -> Tuple[float, float]:\n",
    "    prediction, ground_truth = normalize(prediction), normalize(ground_truth)\n",
    "    prediction_tokens, ground_truth_tokens = prediction.split(), ground_truth.split()\n",
    "\n",
    "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
    "    number_same = sum(common.values())\n",
    "    f1_score = 0\n",
    "    if number_same != 0:\n",
    "        precision = 1.0 * number_same / len(prediction_tokens)\n",
    "        recall = 1.0 * number_same / len(ground_truth_tokens)\n",
    "        f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return prediction == ground_truth, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "tv9kxaI34_Oo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def max_metrics_over_ground_truths(prediction: str, ground_truths: List[str]) -> Tuple[float, float]:\n",
    "    scores = [get_scores(prediction, ground_truth) for ground_truth in ground_truths]\n",
    "    em_score = max(scores, key=lambda score: score[0])[0]\n",
    "    f1_score = max(scores, key=lambda score: score[1])[1]\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "KmxMG01B5JEx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(predictions: Dict[str, str], qas: List[RawDatasetItem]) -> Tuple[float, float]:\n",
    "    ground_truths = collections.defaultdict(lambda: [])\n",
    "    for qa in qas:\n",
    "        if qa.id_ in predictions:\n",
    "            ground_truths[qa.id_].append(qa.answer.text)\n",
    "\n",
    "    em_scores, f1_scores, total = [], [], 0\n",
    "    for id_ in predictions:\n",
    "        em_score, f1_score = max_metrics_over_ground_truths(predictions[id_], ground_truths[id_])\n",
    "        em_scores.append(em_score)\n",
    "        f1_scores.append(f1_score)\n",
    "        total += 1\n",
    "\n",
    "    em_score = 100.0 * sum(em_scores) / total\n",
    "    f1_score = 100.0 * sum(f1_scores) / total\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "GHUdYB6f-NRJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model: nn.Module, optimizer: optim.Optimizer, criterion: nn.Module, id_vocab: Vocabulary,\n",
    "                 text_vocab: Vocabulary, model_path: str):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.id_vocab = id_vocab\n",
    "        self.text_vocab = text_vocab\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def train_step(self, loader: DataLoader, epoch: int, gradient_clipping: float) -> float:\n",
    "        tracker = AverageMeter()\n",
    "        self.model.train()\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for index, batch in pbar:  # type: int, DrQATensorDatasetBatch\n",
    "            self.optimizer.zero_grad()\n",
    "            starts, ends = self.model(batch)  # [batch_size, ctx_len]\n",
    "            loss = self.criterion(starts, batch.target[:, 0]) + self.criterion(ends, batch.target[:, 1])\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(parameters=self.model.parameters(), max_norm=gradient_clipping)\n",
    "            self.optimizer.step()\n",
    "            tracker.update(loss.item())\n",
    "            pbar.set_description(f\"Epoch: {epoch + 1:02d} -     loss: {tracker.average:.3f}\")\n",
    "        return tracker.average\n",
    "\n",
    "    def validate(self, loader: DataLoader, epoch: int) -> Tuple[float, Dict]:\n",
    "        tracker, predictions = AverageMeter(), {}\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "            for _, batch in pbar:  # type: int, DrQATensorDatasetBatch\n",
    "                starts, ends = self.model(batch)  # [batch_size, ctx_len]\n",
    "                loss = self.criterion(starts, batch.target[:, 0]) + self.criterion(ends, batch.target[:, 1])\n",
    "                start_indexes, end_indexes, _ = self.model.decode(\n",
    "                    starts=F.softmax(starts, dim=-1),\n",
    "                    ends=F.softmax(ends, dim=-1)\n",
    "                )\n",
    "                for index in range(starts.size(0)):\n",
    "                    id_ = self.id_vocab.itos(batch.id_[index].item())\n",
    "                    prediction = batch.context[0][index][start_indexes[index]:end_indexes[index] + 1]\n",
    "                    predictions[id_] = ' '.join([self.text_vocab.itos(ind.item()) for ind in prediction])\n",
    "\n",
    "                tracker.update(loss.item())\n",
    "                pbar.set_description(f\"Epoch: {epoch + 1:02d} - valid_loss: {tracker.average:.3f}\")\n",
    "        return tracker.average, predictions\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_loader: DataLoader, n_epochs: int, gradient_clipping: float) \\\n",
    "            -> Dict[str, List[float]]:\n",
    "        history, best_loss = {\"loss\": [], \"valid_loss\": [], \"exact_match\": [], \"f1\": []}, float('inf')\n",
    "        for epoch in range(n_epochs):\n",
    "            loss = self.train_step(loader=train_loader, epoch=epoch, gradient_clipping=gradient_clipping)\n",
    "            valid_loss, predictions = self.validate(loader=valid_loader, epoch=epoch)\n",
    "\n",
    "            history[\"loss\"].append(loss)\n",
    "            history[\"valid_loss\"].append(valid_loss)\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFzM-vWUAov9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Train the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "-YCmJQLhAlqo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_LAYERS = 3\n",
    "EMBED_SIZE = 300\n",
    "HIDDEN_SIZE = 128\n",
    "DROPOUT = 0.3\n",
    "N_EPOCHS = 5\n",
    "GRAD_CLIP = 1.0\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ersGVmFxBwAV",
    "outputId": "f5c11bc4-a4bb-49cb-8fc1-c472323ec253",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 16,623,708\n",
      "DrQA(\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (embedding_layer): Embedding(26884, 300, padding_idx=0)\n",
      "  (aligned_question_embedding_layer): AlignedQuestionEmbeddingLayer(\n",
      "    (dense): Linear(in_features=300, out_features=128, bias=True)\n",
      "  )\n",
      "  (context_lstm_layer): StackedBiLSTMsLayer(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (lstm_layers): ModuleList(\n",
      "      (0): LSTM(432, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "      (1): LSTM(256, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "      (2): LSTM(256, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (question_encoding_layer): QuestionEncodingLayer(\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (stacked_bilstm_layers): StackedBiLSTMsLayer(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (lstm_layers): ModuleList(\n",
      "        (0): LSTM(300, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "        (1): LSTM(256, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "        (2): LSTM(256, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "    (dense): Linear(in_features=300, out_features=1, bias=False)\n",
      "  )\n",
      "  (bilinear_attention_start_layer): BiLinearAttentionLayer(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=False)\n",
      "  )\n",
      "  (bilinear_attention_end_layer): BiLinearAttentionLayer(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "padding_token_index = text_vocabulary.stoi(word=text_vocabulary.padding_token)\n",
    "model = DrQA(\n",
    "    vocabulary_size=len(text_vocabulary),\n",
    "    embedding_size=EMBED_SIZE,\n",
    "    n_extra_features=4,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    padding_index=padding_token_index\n",
    ").to(device=DEVICE)\n",
    "# model.load_glove_embeddings('./data/GloVe_DrQA.npy', most_common_indexes, tune=True)\n",
    "optimizer = optim.Adamax(params=model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=padding_token_index)\n",
    "print(f'Number of parameters of the model: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "print(model)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    model_path=\"./checkpoints/drqa.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giP1Ov5_DTGr",
    "outputId": "aa776c3f-80f1-4c9f-9abb-37e38eb2841c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 01 -     loss: 5.463: 100%|██████████| 2709/2709 [09:32<00:00,  4.73it/s]\n",
      "Epoch: 01 - valid_loss: 4.579: 100%|██████████| 1074/1074 [02:00<00:00,  8.93it/s]\n",
      "Epoch: 02 -     loss: 4.387: 100%|██████████| 2709/2709 [09:08<00:00,  4.94it/s]\n",
      "Epoch: 02 - valid_loss: 4.266: 100%|██████████| 1074/1074 [01:46<00:00, 10.07it/s]\n",
      "Epoch: 03 -     loss: 4.021: 100%|██████████| 2709/2709 [09:21<00:00,  4.83it/s]\n",
      "Epoch: 03 - valid_loss: 4.125: 100%|██████████| 1074/1074 [01:43<00:00, 10.38it/s]\n",
      "Epoch: 04 -     loss: 3.783: 100%|██████████| 2709/2709 [09:15<00:00,  4.87it/s]\n",
      "Epoch: 04 - valid_loss: 4.011: 100%|██████████| 1074/1074 [01:42<00:00, 10.53it/s]\n",
      "Epoch: 05 -     loss: 3.613: 100%|██████████| 2709/2709 [18:50<00:00,  2.40it/s]    \n",
      "Epoch: 05 - valid_loss: 4.006: 100%|██████████| 1074/1074 [01:52<00:00,  9.53it/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./checkpoints\n",
    "history = trainer.train(\n",
    "    train_loader=train_dataloader,\n",
    "    valid_loader=valid_dataloader,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    gradient_clipping=GRAD_CLIP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "8C-bSJpY-qZM",
    "outputId": "db26fdee-279c-4fe8-b5d6-7f26a8587271",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['valid_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "# axes[1].plot(history['em'], label='valid')\n",
    "# axes[1].set_title('Exact match history')\n",
    "# axes[1].set_xlabel('Epoch')\n",
    "# axes[1].set_ylabel('Exact match (%)')\n",
    "# axes[1].grid(True)\n",
    "# axes[1].legend()\n",
    "\n",
    "# axes[2].plot(history['f1'], label='valid')\n",
    "# axes[2].set_title('F1 history')\n",
    "# axes[2].set_xlabel('Epoch')\n",
    "# axes[2].set_ylabel('F1 (%)')\n",
    "# axes[2].grid(True)\n",
    "# axes[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_99dtAVn5CL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Inference***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk9dSwSR_OM9",
    "outputId": "dfc3f33a-a716-44fd-ae2d-3ce5fdaa745f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"./checkpoints/drqa.pth\"))\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "p1CVgakLDtsU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def inference(model: nn.Module, context: spacy.tokens.doc.Doc, question: spacy.tokens.doc.Doc,\n",
    "              text_vocab: Vocabulary, pos_vocab: Vocabulary, ner_vocab: Vocabulary, device: torch.device):\n",
    "    # Build extra features\n",
    "    question = [token.text.lower() for token in question]\n",
    "    counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
    "    freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
    "    freqs_norm = sum(freqs.values())\n",
    "    em, pos, ner, ntf = zip(\n",
    "        *map(lambda index: [\n",
    "            context[index].text.lower() in question, context[index].tag_,\n",
    "            context[index].ent_type_ or 'None',\n",
    "            freqs[index] / freqs_norm\n",
    "        ], range(len(context)))\n",
    "    )\n",
    "\n",
    "    # Build tensors\n",
    "    batch = DrQATensorDatasetBatch(\n",
    "        id_=None,\n",
    "        context=(\n",
    "            torch.LongTensor([*map(lambda word: text_vocab.stoi(word), context)]).unsqueeze(0).to(device),\n",
    "            torch.LongTensor([len(context)])\n",
    "        ), question=(\n",
    "            torch.LongTensor([*map(lambda word: text_vocab.stoi(word), question)]).unsqueeze(0).to(device),\n",
    "            torch.LongTensor([len(question)])\n",
    "        ), target=None,\n",
    "        exact_match=torch.LongTensor(em).unsqueeze(0).to(device),\n",
    "        part_of_speech=torch.LongTensor([*map(lambda x: pos_vocab.stoi(x), pos)]).unsqueeze(0).to(device),\n",
    "        named_entity_type=torch.LongTensor([*map(lambda x: ner_vocab.stoi(x), ner)]).unsqueeze(0).to(device),\n",
    "        normalized_term_frequency=torch.LongTensor(ntf).unsqueeze(0).to(device)\n",
    "    )\n",
    "\n",
    "    # Prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Feed the model\n",
    "        start, end = model(batch)\n",
    "    \n",
    "        # Decode the result indexes\n",
    "        start_index, end_index, proba = model.decode(starts=F.softmax(start, dim=-1), ends=F.softmax(end, dim=-1))\n",
    "\n",
    "        # Extract the answer\n",
    "        answer = context[start_index[0]:end_index[0] + 1]\n",
    "\n",
    "    return answer, proba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dI-ME2Q1-WzB",
    "outputId": "7ddd80ef-e885-476d-a8e7-32e1a031417b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The first direct elections for native Kenyans to the Legislative Council took place in 1957. Despite British hopes of handing power to \"moderate\" local rivals, it was the Kenya African National Union (KANU) of Jomo Kenyatta that formed a government. The Colony of Kenya and the Protectorate of Kenya each came to an end on 12 December 1963 with independence being conferred on all of Kenya. The United Kingdom ceded sovereignty over the Colony of Kenya and, under an agreement dated 8 October 1963, the Sultan of Zanzibar agreed that simultaneous with independence for the Colony of Kenya, the Sultan would cease to have sovereignty over the Protectorate of Kenya so that all of Kenya would be one sovereign, independent state. In this way, Kenya became an independent country under the Kenya Independence Act 1963 of the United Kingdom. Exactly 12 months later on 12 December 1964, Kenya became a republic under the name \"Republic of Kenya\".</span><br /><span><b>Question:</b> What did Kenya name itself on December 12, 1964? </span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Republic of Kenya</li><li style=\"color:blue\">Republic of Kenya</li><li style=\"color:blue\">Republic of Kenya</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 1963 with independence being conferred on all of Kenya. The United Kingdom ceded sovereignty over the Colony of Kenya and, under an agreement dated 8 October 1963, the Sultan of Zanzibar agreed that simultaneous with independence for the Colony of Kenya, the Sultan would cease to have sovereignty over the Protectorate of Kenya so that all of Kenya would be one sovereign, independent state. In this way, Kenya became an independent country under the Kenya Independence Act 1963 of the United Kingdom. Exactly 12 months later on 12 December 1964, Kenya became a republic under the name \"Republic of Kenya\".</span><br /><span style=\"color:green\"><b>Probability:</b> 1.583%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The most basic method of checking the primality of a given integer n is called trial division. This routine consists of dividing n by each integer m that is greater than 1 and less than or equal to the square root of n. If the result of any of these divisions is an integer, then n is not a prime, otherwise it is a prime. Indeed, if  is composite (with a and b ≠ 1) then one of the factors a or b is necessarily at most . For example, for , the trial divisions are by m = 2, 3, 4, 5, and 6. None of these numbers divides 37, so 37 is prime. This routine can be implemented more efficiently if a complete list of primes up to  is known—then trial divisions need to be checked only for those m that are prime. For example, to check the primality of 37, only three divisions are necessary (m = 2, 3, and 5), given that 4 and 6 are composite.</span><br /><span><b>Question:</b> What must the integer m be less than or equal to when performing trial division?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">the square root of n.</li><li style=\"color:blue\">the square root of n.</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 1.053%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> However, in 1883–84 Germany began to build a colonial empire in Africa and the South Pacific, before losing interest in imperialism. Historians have debated exactly why Germany made this sudden and short-lived move.[verification needed] Bismarck was aware that public opinion had started to demand colonies for reasons of German prestige. He was influenced by Hamburg merchants and traders, his neighbors at Friedrichsruh. The establishment of the German colonial empire proceeded smoothly, starting with German New Guinea in 1884.</span><br /><span><b>Question:</b> What was the name of the first German settlement?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">New Guinea</li><li style=\"color:blue\">German New Guinea</li><li style=\"color:blue\">German New Guinea</li><li style=\"color:blue\">German New Guinea</li><li style=\"color:blue\">German New Guinea</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> colonial empire proceeded smoothly, starting with German New Guinea in 1884.</span><br /><span style=\"color:green\"><b>Probability:</b> 0.560%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.</span><br /><span><b>Question:</b> Which team did not get a chance to defend their Super Bowl XLIX win in Super Bowl 50?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">New England Patriots</li><li style=\"color:blue\">the New England Patriots</li><li style=\"color:blue\">New England Patriots</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.</span><br /><span style=\"color:green\"><b>Probability:</b> 0.984%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Iqbal expressed fears that not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence. In his travels to Egypt, Afghanistan, Palestine and Syria, he promoted ideas of greater Islamic political co-operation and unity, calling for the shedding of nationalist differences. Sir Muhammad Iqbal was elected president of the Muslim League in 1930 at its session in Allahabad as well as for the session in Lahore in 1932. In his Allahabad Address on 29 December 1930, Iqbal outlined a vision of an independent state for Muslim-majority provinces in northwestern India. This address later inspired the Pakistan movement.</span><br /><span><b>Question:</b> What did Iqbal fear would weaken the spiritual foundations of Islam and Muslim society?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">secularism and secular nationalism</li><li style=\"color:blue\">secularism and secular nationalism</li><li style=\"color:blue\">secularism</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 1.108%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The league announced on October 16, 2012, that the two finalists were Sun Life Stadium and Levi's Stadium. The South Florida/Miami area has previously hosted the event 10 times (tied for most with New Orleans), with the most recent one being Super Bowl XLIV in 2010. The San Francisco Bay Area last hosted in 1985 (Super Bowl XIX), held at Stanford Stadium in Stanford, California, won by the home team 49ers. The Miami bid depended on whether the stadium underwent renovations. However, on May 3, 2013, the Florida legislature refused to approve the funding plan to pay for the renovations, dealing a significant blow to Miami's chances.</span><br /><span><b>Question:</b> What date were the top two stadium choices for Super Bowl 50 announced?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">October 16, 2012</li><li style=\"color:blue\">October 16, 2012</li><li style=\"color:blue\">October 16, 2012,</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 2012, that the two finalists were Sun Life Stadium and Levi's Stadium. The South Florida/Miami area has previously hosted the event 10 times (tied for most with New Orleans), with the most recent one being Super Bowl XLIV in 2010. The San Francisco Bay Area last hosted in 1985 (Super Bowl XIX), held at Stanford Stadium in Stanford, California, won by the home team 49ers. The Miami bid depended on whether the stadium underwent renovations. However, on May 3, 2013, the Florida legislature refused to approve the funding plan to pay for the renovations, dealing a significant blow to Miami's chances.</span><br /><span style=\"color:green\"><b>Probability:</b> 0.594%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The Free Movement of Workers Regulation articles 1 to 7 set out the main provisions on equal treatment of workers. First, articles 1 to 4 generally require that workers can take up employment, conclude contracts, and not suffer discrimination compared to nationals of the member state. In a famous case, the Belgian Football Association v Bosman, a Belgian footballer named Jean-Marc Bosman claimed that he should be able to transfer from R.F.C. de Liège to USL Dunkerque when his contract finished, regardless of whether Dunkerque could afford to pay Liège the habitual transfer fees. The Court of Justice held \"the transfer rules constitute[d] an obstacle to free movement\" and were unlawful unless they could be justified in the public interest, but this was unlikely. In Groener v Minister for Education the Court of Justice accepted that a requirement to speak Gaelic to teach in a Dublin design college could be justified as part of the public policy of promoting the Irish language, but only if the measure was not disproportionate. By contrast in Angonese v Cassa di Risparmio di Bolzano SpA a bank in Bolzano, Italy, was not allowed to require Mr Angonese to have a bilingual certificate that could only be obtained in Bolzano. The Court of Justice, giving \"horizontal\" direct effect to TFEU article 45, reasoned that people from other countries would have little chance of acquiring the certificate, and because it was \"impossible to submit proof of the required linguistic knowledge by any other means\", the measure was disproportionate. Second, article 7(2) requires equal treatment in respect of tax. In Finanzamt Köln Altstadt v Schumacker the Court of Justice held that it contravened TFEU art 45 to deny tax benefits (e.g. for married couples, and social insurance expense deductions) to a man who worked in Germany, but was resident in Belgium when other German residents got the benefits. By contrast in Weigel v Finanzlandesdirektion für Vorarlberg the Court of Justice rejected Mr Weigel's claim that a re-registration charge upon bringing his car to Austria violated his right to free movement. Although the tax was \"likely to have a negative bearing on the decision of migrant workers to exercise their right to freedom of movement\", because the charge applied equally to Austrians, in absence of EU legislation on the matter it had to be regarded as justified. Third, people must receive equal treatment regarding \"social advantages\", although the Court has approved residential qualifying periods. In Hendrix v Employee Insurance Institute the Court of Justice held that a Dutch national was not entitled to continue receiving incapacity benefits when he moved to Belgium, because the benefit was \"closely linked to the socio-economic situation\" of the Netherlands. Conversely, in Geven v Land Nordrhein-Westfalen the Court of Justice held that a Dutch woman living in the Netherlands, but working between 3 and 14 hours a week in Germany, did not have a right to receive German child benefits, even though the wife of a man who worked full-time in Germany but was resident in Austria could. The general justifications for limiting free movement in TFEU article 45(3) are \"public policy, public security or public health\", and there is also a general exception in article 45(4) for \"employment in the public service\".</span><br /><span><b>Question:</b> Which Belgian footballer claimed that he should be allowed to transfer from one football club to another when his contract was fulfilled?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Jean-Marc Bosman</li><li style=\"color:blue\">the Belgian Football Association v Bosman</li><li style=\"color:blue\">Jean-Marc Bosman</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> named Jean-Marc Bosman claimed that he should be able to transfer from R.F.C. de Liège to USL Dunkerque when his contract finished, regardless of whether Dunkerque could afford to pay Liège the habitual transfer fees. The Court of Justice held \"the transfer rules constitute[d] an obstacle to free movement\" and were unlawful unless they could be justified in the public interest, but this was unlikely. In Groener v Minister for Education the Court of Justice accepted that a requirement to speak Gaelic to teach in a Dublin design college could be justified as part of the public policy of promoting the Irish language, but only if the measure was not disproportionate. By contrast in Angonese v Cassa di Risparmio di Bolzano SpA a bank in Bolzano, Italy, was not allowed to require Mr Angonese to have a bilingual certificate that could only be obtained in Bolzano. The Court of Justice, giving \"horizontal\" direct effect to TFEU article 45, reasoned that people from other countries would have little chance of acquiring the certificate, and because it was \"impossible to submit proof of the required linguistic knowledge by any other means\", the measure was disproportionate. Second, article 7(2) requires equal treatment in respect of tax. In Finanzamt Köln Altstadt v Schumacker the Court of Justice held that it contravened TFEU art 45 to deny tax benefits (e.g. for married couples, and social insurance expense deductions) to a man who worked in Germany, but was resident in Belgium when other German residents got the benefits. By contrast in Weigel v Finanzlandesdirektion für Vorarlberg the Court of Justice rejected Mr Weigel's claim that a re-registration charge upon bringing his car to Austria violated his right to free movement. Although the tax was \"likely to have a negative bearing on the decision of migrant workers to exercise their right to freedom of movement\", because the charge applied equally to Austrians, in absence of EU legislation on the matter it had to be regarded as justified. Third, people must receive equal treatment regarding \"social advantages\", although the Court has approved residential qualifying periods. In Hendrix v Employee Insurance Institute the Court of Justice held that a Dutch national was not entitled to continue receiving incapacity benefits when he moved to Belgium, because the benefit was \"closely linked to the socio-economic situation\" of the Netherlands. Conversely, in Geven v Land Nordrhein-Westfalen the Court of Justice held that a Dutch woman living in the Netherlands, but working between 3 and 14 hours a week in Germany, did not have a right to receive German child benefits, even though the wife of a man who worked full-time in Germany but was resident in Austria could. The general justifications for limiting free movement in TFEU article 45(3) are \"public policy, public security or public health\", and there is also a general exception in article 45(4) for \"employment in the public service\".</span><br /><span style=\"color:green\"><b>Probability:</b> 0.292%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The acme of the horizontal engine was the Corliss steam engine, patented in 1849, which was a four-valve counter flow engine with separate steam admission and exhaust valves and automatic variable steam cutoff. When Corliss was given the Rumford medal the committee said that \"no one invention since Watt's time has so enhanced the efficiency of the steam engine\". In addition to using 30% less steam, it provided more uniform speed due to variable steam cut off, making it well suited to manufacturing, especially cotton spinning.</span><br /><span><b>Question:</b> How many valves did the Corliss engine use?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">four</li><li style=\"color:blue\">four</li><li style=\"color:blue\">four</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> of</span><br /><span style=\"color:green\"><b>Probability:</b> 34.122%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> A computational problem can be viewed as an infinite collection of instances together with a solution for every instance. The input string for a computational problem is referred to as a problem instance, and should not be confused with the problem itself. In computational complexity theory, a problem refers to the abstract question to be solved. In contrast, an instance of this problem is a rather concrete utterance, which can serve as the input for a decision problem. For example, consider the problem of primality testing. The instance is a number (e.g. 15) and the solution is \"yes\" if the number is prime and \"no\" otherwise (in this case \"no\"). Stated another way, the instance is a particular input to the problem, and the solution is the output corresponding to the given input.</span><br /><span><b>Question:</b> In computational complexity theory, what is the term given to describe the baseline abstract question needing to be solved? </span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">the problem</li><li style=\"color:blue\">a problem</li><li style=\"color:blue\">problem</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> a problem refers to the abstract question to be solved. In contrast, an instance of this problem is a rather concrete utterance, which can serve as the input for a decision problem. For example, consider the problem of primality testing. The instance is a number (e.g. 15) and the solution is \"yes\" if the number is prime and \"no\" otherwise (in this case \"no\"). Stated another way, the instance is a particular input to the problem, and the solution is the output corresponding to the given input.</span><br /><span style=\"color:green\"><b>Probability:</b> 0.575%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> AppleTalk was a proprietary suite of networking protocols developed by Apple Inc. in 1985 for Apple Macintosh computers. It was the primary protocol used by Apple devices through the 1980s and 90s. AppleTalk included features that allowed local area networks to be established ad hoc without the requirement for a centralized router or server. The AppleTalk system automatically assigned addresses, updated the distributed namespace, and configured any required inter-network routing. It was a plug-n-play system.</span><br /><span><b>Question:</b> This type of system is known as </span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">a plug-n-play system</li><li style=\"color:blue\">plug-n-play</li><li style=\"color:blue\">plug-n-play</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> a</span><br /><span style=\"color:green\"><b>Probability:</b> 4.519%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In between the French and the British, large areas were dominated by native tribes. To the north, the Mi'kmaq and the Abenaki were engaged in Father Le Loutre's War and still held sway in parts of Nova Scotia, Acadia, and the eastern portions of the province of Canada, as well as much of present-day Maine. The Iroquois Confederation dominated much of present-day Upstate New York and the Ohio Country, although the latter also included Algonquian-speaking populations of Delaware and Shawnee, as well as Iroquoian-speaking Mingo. These tribes were formally under Iroquois rule, and were limited by them in authority to make agreements.</span><br /><span><b>Question:</b> In between French and British, what groups controlled land?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">native tribes</li><li style=\"color:blue\">native tribes</li><li style=\"color:blue\">native tribes</li><li style=\"color:blue\">native tribes</li><li style=\"color:blue\">native tribes</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> large areas were dominated by native tribes. To the north, the Mi'kmaq and the Abenaki were engaged in Father Le Loutre's War and still held sway in parts of Nova Scotia, Acadia, and the eastern portions of the province of Canada, as well as much of present-day Maine. The Iroquois Confederation dominated much of present-day Upstate New York and the Ohio Country, although the latter also included Algonquian-speaking populations of Delaware and Shawnee, as well as Iroquoian-speaking Mingo. These tribes were formally under Iroquois rule, and were limited by them in authority to make agreements.</span><br /><span style=\"color:green\"><b>Probability:</b> 1.175%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The name Rijn, from here on, is used only for smaller streams farther to the north, which together formed the main river Rhine in Roman times. Though they retained the name, these streams no longer carry water from the Rhine, but are used for draining the surrounding land and polders. From Wijk bij Duurstede, the old north branch of the Rhine is called Kromme Rijn (\"Bent Rhine\") past Utrecht, first Leidse Rijn (\"Rhine of Leiden\") and then, Oude Rijn (\"Old Rhine\"). The latter flows west into a sluice at Katwijk, where its waters can be discharged into the North Sea. This branch once formed the line along which the Limes Germanicus were built. During periods of lower sea levels within the various ice ages, the Rhine took a left turn, creating the Channel River, the course of which now lies below the English Channel.</span><br /><span><b>Question:</b> What is the name of the old north branch of the Rhine?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Kromme Rijn</li><li style=\"color:blue\">Kromme Rijn</li><li style=\"color:blue\">Kromme Rijn</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Rijn, from here on, is used only for smaller streams farther to the north, which together formed the main river Rhine in Roman times. Though they retained the name, these streams no longer carry water from the Rhine, but are used for draining the surrounding land and polders. From Wijk bij Duurstede,</span><br /><span style=\"color:green\"><b>Probability:</b> 1.048%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Bolshevik leaders had effectively reestablished a polity with roughly the same extent as that empire by 1921, however with an internationalist ideology: Lenin in particular asserted the right to limited self-determination for national minorities within the new territory. Beginning in 1923, the policy of \"Indigenization\" [korenizatsiia] was intended to support non-Russians develop their national cultures within a socialist framework. Never formally revoked, it stopped being implemented after 1932. After World War II, the Soviet Union installed socialist regimes modeled on those it had installed in 1919–20 in the old Tsarist Empire in areas its forces occupied in Eastern Europe. The Soviet Union and the People’s Republic of China supported post–World War II communist movements in foreign nations and colonies to advance their own interests, but were not always successful.</span><br /><span><b>Question:</b> Who had established the Russian empire to its former glory prior to 1921?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Bolshevik leaders</li><li style=\"color:blue\">Bolshevik leaders</li><li style=\"color:blue\">Bolshevik leaders</li><li style=\"color:blue\">Bolshevik leaders</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> , however with an internationalist ideology: Lenin in particular asserted the right to limited self-determination for national minorities within the new territory. Beginning in 1923, the policy of \"Indigenization\" [korenizatsiia] was intended to support non-Russians develop their national cultures within a socialist framework. Never formally revoked, it stopped being implemented after 1932. After World War II, the Soviet Union installed socialist regimes modeled on those it had installed in 1919–20 in the old Tsarist Empire in areas its forces occupied in Eastern Europe. The Soviet Union and the People’s Republic of China supported post–World War II communist movements in foreign nations and colonies to advance their own interests, but were not always successful.</span><br /><span style=\"color:green\"><b>Probability:</b> 1.413%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> For the third straight season, the number one seeds from both conferences met in the Super Bowl. The Carolina Panthers became one of only ten teams to have completed a regular season with only one loss, and one of only six teams to have acquired a 15–1 record, while the Denver Broncos became one of four teams to have made eight appearances in the Super Bowl. The Broncos made their second Super Bowl appearance in three years, having reached Super Bowl XLVIII, while the Panthers made their second Super Bowl appearance in franchise history, their other appearance being Super Bowl XXXVIII. Coincidentally, both teams were coached by John Fox in their last Super Bowl appearance prior to Super Bowl 50.</span><br /><span><b>Question:</b> Before Super Bowl 50, what was the coach's name that coached both teams for their last Super Bowl appearances?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">John Fox</li><li style=\"color:blue\">John Fox</li><li style=\"color:blue\">John Fox</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 0.441%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In 1993, for the franchise's 30th anniversary, another charity special, titled Dimensions in Time was produced for Children in Need, featuring all of the surviving actors who played the Doctor and a number of previous companions. It also featured a crossover with the soap opera EastEnders, the action taking place in the latter's Albert Square location and around Greenwich. The special was one of several special 3D programmes the BBC produced at the time, using a 3D system that made use of the Pulfrich effect requiring glasses with one darkened lens; the picture would look normal to those viewers who watched without the glasses.</span><br /><span><b>Question:</b> What type of lenses were needed to see the 3D effects in Dimension in Time?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">glasses with one darkened lens</li><li style=\"color:blue\">glasses with one darkened lens</li><li style=\"color:blue\">one darkened lens</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 1993, for the franchise's 30th anniversary, another charity special, titled Dimensions in Time was produced for Children in Need, featuring all of the surviving actors who played the Doctor and a number of previous companions. It also featured a crossover with the soap opera EastEnders, the action taking place in the latter's Albert Square location and around Greenwich. The special was one of several special 3D programmes the BBC produced at the time, using a 3D system that made use of the Pulfrich effect requiring glasses with one darkened lens; the picture would look normal to those viewers who watched without the glasses.</span><br /><span style=\"color:green\"><b>Probability:</b> 3.063%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Exceptional examples of the bourgeois architecture of the later periods were not restored by the communist authorities after the war (like mentioned Kronenberg Palace and Insurance Company Rosja building) or they were rebuilt in socialist realism style (like Warsaw Philharmony edifice originally inspired by Palais Garnier in Paris). Despite that the Warsaw University of Technology building (1899–1902) is the most interesting of the late 19th-century architecture. Some 19th-century buildings in the Praga district (the Vistula’s right bank) have been restored although many have been poorly maintained. Warsaw’s municipal government authorities have decided to rebuild the Saxon Palace and the Brühl Palace, the most distinctive buildings in prewar Warsaw.</span><br /><span><b>Question:</b> What style was the Warsaw Philharmony edifice built in?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">socialist realism</li><li style=\"color:blue\">socialist realism</li><li style=\"color:blue\">socialist realism</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> by Palais Garnier in Paris). Despite that</span><br /><span style=\"color:green\"><b>Probability:</b> 0.499%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Steam engines are external combustion engines, where the working fluid is separate from the combustion products. Non-combustion heat sources such as solar power, nuclear power or geothermal energy may be used. The ideal thermodynamic cycle used to analyze this process is called the Rankine cycle. In the cycle, water is heated and transforms into steam within a boiler operating at a high pressure. When expanded through pistons or turbines, mechanical work is done. The reduced-pressure steam is then condensed and pumped back into the boiler.</span><br /><span><b>Question:</b> In the Rankine cycle, what does water turn into when heated?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">steam</li><li style=\"color:blue\">steam</li><li style=\"color:blue\">steam</li><li style=\"color:blue\">steam</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> and transforms into steam within a boiler operating at a high pressure. When expanded through pistons or turbines, mechanical work is done. The reduced-pressure steam is then condensed and pumped back into the boiler.</span><br /><span style=\"color:green\"><b>Probability:</b> 4.248%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> After Malaysia's independence in 1957, the government instructed all schools to surrender their properties and be assimilated into the National School system. This caused an uproar among the Chinese and a compromise was achieved in that the schools would instead become \"National Type\" schools. Under such a system, the government is only in charge of the school curriculum and teaching personnel while the lands still belonged to the schools. While Chinese primary schools were allowed to retain Chinese as the medium of instruction, Chinese secondary schools are required to change into English-medium schools. Over 60 schools converted to become National Type schools.</span><br /><span><b>Question:</b> What language is used in Chinese primary schools in Malaysia?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Chinese</li><li style=\"color:blue\">Chinese</li><li style=\"color:blue\">Chinese</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 's independence in 1957, the government instructed all schools to surrender their properties and be assimilated into the National School system. This caused an uproar among the Chinese and a compromise was achieved in that the schools would instead become \"National Type\" schools. Under such a system, the government is only in charge of the school curriculum and teaching personnel while the lands still belonged to the schools. While Chinese primary schools were allowed to retain Chinese as the medium of instruction, Chinese secondary schools are required to change into English-medium schools. Over 60 schools converted to become National Type schools.</span><br /><span style=\"color:green\"><b>Probability:</b> 2.906%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Always in search of new programs that would help it compete with NBC and CBS, ABC's management believed that sports could be a major catalyst in improving the network's market share. On April 29, 1961, ABC debuted Wide World of Sports, an anthology series created by Edgar Scherick through his company Sports Programs, Inc. and produced by a young Roone Arledge which featured a different sporting event each broadcast. ABC purchased Sports Programs, Inc. in exchange for shares in the company, leading it to become the future core of ABC Sports, with Arledge as the executive producer of that division's shows. Wide World of Sports, in particular, was not merely devoted to a single sport, but rather to generally all sporting events.</span><br /><span><b>Question:</b> ABC purchased which of Edgar Scherick's company?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Sports Programs, Inc.</li><li style=\"color:blue\">Sports Programs, Inc.</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 0.190%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> After a punt from both teams, Carolina got on track with a 9-play, 73-yard scoring drive. Newton completed 4 of 4 passes for 51 yards and rushed twice for 25 yards, while Jonathan Stewart finished the drive with a 1-yard touchdown run, cutting the score to 10–7 with 11:28 left in the second quarter. Later on, Broncos receiver Jordan Norwood received Brad Nortman's short 28-yard punt surrounded by Panthers players, but none of them attempted to make a tackle, apparently thinking Norwood had called a fair catch. Norwood had not done so, and with no resistance around him, he took off for a Super Bowl record 61-yard return before Mario Addison dragged him down on the Panthers 14-yard line. Despite Denver's excellent field position, they could not get the ball into the end zone, so McManus kicked a 33-yard field goal that increased their lead to 13–7.</span><br /><span><b>Question:</b> Who scored the Panthers first touchdown? </span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Jonathan Stewart</li><li style=\"color:blue\">Jonathan Stewart</li><li style=\"color:blue\">Stewart</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> . Later on, Broncos receiver Jordan Norwood received Brad Nortman's short 28-yard punt surrounded by Panthers players, but none of them attempted to make a tackle, apparently thinking Norwood had called a fair catch. Norwood had not done so, and with no resistance around him, he took off for a Super Bowl record 61-yard return before Mario Addison dragged him down on the Panthers 14-yard line. Despite Denver's excellent field position, they could not get the ball into the end zone, so McManus kicked a 33-yard field goal that increased their lead to 13–7.</span><br /><span style=\"color:green\"><b>Probability:</b> 1.193%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Newton's First Law of Motion states that objects continue to move in a state of constant velocity unless acted upon by an external net force or resultant force. This law is an extension of Galileo's insight that constant velocity was associated with a lack of net force (see a more detailed description of this below). Newton proposed that every object with mass has an innate inertia that functions as the fundamental equilibrium \"natural state\" in place of the Aristotelian idea of the \"natural state of rest\". That is, the first law contradicts the intuitive Aristotelian belief that a net force is required to keep an object moving with constant velocity. By making rest physically indistinguishable from non-zero constant velocity, Newton's First Law directly connects inertia with the concept of relative velocities. Specifically, in systems where objects are moving with different velocities, it is impossible to determine which object is \"in motion\" and which object is \"at rest\". In other words, to phrase matters more technically, the laws of physics are the same in every inertial frame of reference, that is, in all frames related by a Galilean transformation.</span><br /><span><b>Question:</b> Whose First Law of Motion says that unless acted upon be forces, objects would continue to move at a constant velocity?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Newton</li><li style=\"color:blue\">Newton's</li><li style=\"color:blue\">Newton's</li><li style=\"color:blue\">Newton's</li><li style=\"color:blue\">Newton's</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 0.386%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The serial format changed for the 2005 revival, with each series usually consisting of 13 45-minute, self-contained episodes (60 minutes with adverts, on overseas commercial channels), and an extended episode broadcast on Christmas Day. Each series includes several standalone and multi-part stories, linked with a loose story arc that resolves in the series finale. As in the early \"classic\" era, each episode, whether standalone or part of a larger story, has its own title. Occasionally, regular-series episodes will exceed the 45-minute run time; notably, the episodes \"Journey's End\" from 2008 and \"The Eleventh Hour\" from 2010 exceeded an hour in length.</span><br /><span><b>Question:</b> In what year did the serial format change for the Doctor Who series?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">2005</li><li style=\"color:blue\">2005</li><li style=\"color:blue\">2005</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> changed for the 2005 revival, with each series usually consisting of 13 45-minute, self-contained episodes (60 minutes with adverts, on overseas commercial channels), and an extended episode broadcast on Christmas Day. Each series includes several standalone and multi-part stories, linked with a loose story arc that resolves in the series finale. As in the early \"classic\" era, each episode, whether standalone or part of a larger story, has its own title. Occasionally, regular-series episodes will exceed the 45-minute run time; notably, the episodes \"Journey's End\" from 2008 and \"The Eleventh Hour\" from 2010 exceeded an hour in length.</span><br /><span style=\"color:green\"><b>Probability:</b> 0.663%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> On 30 July 1891, at the age of 35, Tesla became a naturalized citizen of the United States, and established his South Fifth Avenue laboratory, and later another at 46 E. Houston Street, in New York. He lit electric lamps wirelessly at both locations, demonstrating the potential of wireless power transmission. In the same year, he patented the Tesla coil.</span><br /><span><b>Question:</b> Where was Tesla's laboratory established?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">New York</li><li style=\"color:blue\">South Fifth Avenue</li><li style=\"color:blue\">South Fifth Avenue</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> coil.</span><br /><span style=\"color:green\"><b>Probability:</b> 1.697%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Concentrated O\n",
       "2 will allow combustion to proceed rapidly and energetically. Steel pipes and storage vessels used to store and transmit both gaseous and liquid oxygen will act as a fuel; and therefore the design and manufacture of O\n",
       "2 systems requires special training to ensure that ignition sources are minimized. The fire that killed the Apollo 1 crew in a launch pad test spread so rapidly because the capsule was pressurized with pure O\n",
       "2 but at slightly more than atmospheric pressure, instead of the 1⁄3 normal pressure that would be used in a mission.[k]</span><br /><span><b>Question:</b> To ensure safety of future space missions Oxygen was used at _____ of the normal pressure.</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">1⁄3</li><li style=\"color:blue\">1⁄3</li><li style=\"color:blue\">1⁄3</li><li style=\"color:blue\">1⁄3</li><li style=\"color:blue\">1⁄3 normal pressure</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 0.365%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> To measure the difficulty of solving a computational problem, one may wish to see how much time the best algorithm requires to solve the problem. However, the running time may, in general, depend on the instance. In particular, larger instances will require more time to solve. Thus the time required to solve a problem (or the space required, or any measure of complexity) is calculated as a function of the size of the instance. This is usually taken to be the size of the input in bits. Complexity theory is interested in how algorithms scale with an increase in the input size. For instance, in the problem of finding whether a graph is connected, how much more time does it take to solve a problem for a graph with 2n vertices compared to the time taken for a graph with n vertices?</span><br /><span><b>Question:</b> How is the time needed to obtain the solution to a problem calculated?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">as a function of the size of the instance</li><li style=\"color:blue\">as a function of the size of the instance</li><li style=\"color:blue\">a function of the size of the instance</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> much time the best algorithm requires to solve the problem. However, the running time may, in general, depend on the instance. In particular, larger instances will require more time to solve. Thus the time required to solve a problem (or the space required, or any measure of complexity) is calculated as a function of the size of the instance. This is usually taken to be the size of the input in bits. Complexity theory is interested in how algorithms scale with an increase in the input size. For instance, in the problem of finding whether a graph is connected, how much more time does it take to solve a problem for a graph with 2n vertices compared to the time taken for a graph with n vertices?</span><br /><span style=\"color:green\"><b>Probability:</b> 0.131%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for index in np.random.choice(len(valid_qas), size=25, replace=False):\n",
    "    id = valid_qas[index].id_\n",
    "    context = valid_qas[index].context\n",
    "    question = valid_qas[index].question\n",
    "\n",
    "    answers = []\n",
    "    for qa in valid_qas:\n",
    "        if id == qa.id_:\n",
    "            answers.append(qa.answer)\n",
    "\n",
    "    prediction, proba = inference(\n",
    "        model=model,\n",
    "        context=context,\n",
    "        question=question,\n",
    "        text_vocab=text_vocabulary,\n",
    "        pos_vocab=part_of_speech_vocabulary,\n",
    "        ner_vocab=named_entity_types_vocabulary,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    html = f'<p><span><b>Context:</b> {context.text}</span><br />'\n",
    "    html += f'<span><b>Question:</b> {question.text}</span><br />'\n",
    "    html += f'<span style=\"color:blue\"><b>Possible answers:</b><br /><ul>'\n",
    "    for answer in answers:\n",
    "        html += f'<li style=\"color:blue\">{answer.text}</li>'\n",
    "    html += '</ul></span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Prediction:</b> {prediction}</span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Probability:</b> {proba * 100:.3f}%</span><br />'\n",
    "    display(HTML(html))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7JFJMsaEQAL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbESkBXxHvfxvShB4a49KZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1 - DrQA, Document reader Question Answering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
