{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dksifoua/Question-Answering/blob/master/1%20-%20DrQA%2C%20Document%20reader%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMGpLvYNKR78",
    "outputId": "a44642e8-e103-4b7c-eb0f-625a56ebe146",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 12 21:36:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.01    Driver Version: 516.01       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:08:00.0  On |                  N/A |\n",
      "|  0%   39C    P8    15W / 170W |    865MiB / 12288MiB |      6%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lP-9tyjdylTg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bm6QVw_hzHB7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tqdm --upgrade >> /dev/null 2>&1\n",
    "# !pip install spacy --upgrade >> /dev/null 2>&1\n",
    "# !python -m spacy download en_core_web_lg >> /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bJQv4DSelwnB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import tqdm\n",
    "import spacy\n",
    "import pickle\n",
    "import random\n",
    "import string\n",
    "import itertools\n",
    "import functools\n",
    "import collections\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.tokens import Doc\n",
    "from typing import Any, Dict, List, NamedTuple, Union, Tuple\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /mnt/c/Users/dimit/PycharmProjects/Question-Answering/notebooks\n",
      "New current working directory: /mnt/c/Users/dimit/PycharmProjects/Question-Answering\n"
     ]
    }
   ],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "print(f\"Current working directory: {current_working_directory}\")\n",
    "\n",
    "if current_working_directory.split('/')[-1] == \"notebooks\":\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "print(f\"New current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    # torch.use_deterministic_algorithms(True)\n",
    "    # torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cw16-fZCDHHu",
    "outputId": "29d412de-e92b-46dc-d61e-f679089028fc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 546\n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx9pL3Hiyn7c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare data\n",
    "\n",
    "***Download data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBy3v4Pke7dq",
    "outputId": "4d0d9d8a-d05a-4d3f-b1dd-545aa92ad6f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -rf ./data\n",
    "# !mkdir ./data\n",
    "#\n",
    "# !wget --no-check-certificate \\\n",
    "#     https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n",
    "#     -O ./data/train-v1.1.json\n",
    "#\n",
    "# !wget --no-check-certificate \\\n",
    "#     https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json \\\n",
    "#     -O ./data/dev-v1.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9H59xUnyvAR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Load JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class _UnpackingDataClassMixin:\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(dataclasses.astuple(self))\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Target(_UnpackingDataClassMixin):\n",
    "    start_index: int\n",
    "    end_index: int\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class RawDatasetItem(_UnpackingDataClassMixin):\n",
    "    id_: str\n",
    "    context: Doc\n",
    "    question: Doc\n",
    "    answer: Doc\n",
    "    answer_start_index: int\n",
    "    target: Target = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IbZQjhA5roqo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IO:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_json(path: str) -> Dict:\n",
    "        try:\n",
    "            with open(path, mode='r', encoding=\"utf-8\") as json_file:\n",
    "                return json.load(json_file)\n",
    "        except IOError:\n",
    "            raise IOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqjrkTxHr3rA",
    "outputId": "aeed0ca6-a730-499b-cd3c-8f2bed254f81",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of raw train data: 442\n",
      "Length of raw valid data: 48\n",
      "CPU times: user 435 ms, sys: 41.1 ms, total: 476 ms\n",
      "Wall time: 675 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_raw_data = IO.load_from_json(path=\"./data/train-v1.1.json\")\n",
    "valid_raw_data = IO.load_from_json(path=\"./data/dev-v1.1.json\")\n",
    "print(f\"Length of raw train data: {len(train_raw_data['data']):,}\")\n",
    "print(f\"Length of raw valid data: {len(valid_raw_data['data']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4sypWlVyxx-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Parse JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O-6GE3YxsQsl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_squad_v1_data(data: Dict, spacy_nlp: spacy.language.Language) -> List[RawDatasetItem]:\n",
    "    qas = []\n",
    "    disabled_components = [\"parser\", \"lemmatizer\", \"tagger\", \"ner\"]\n",
    "    for paragraphs in tqdm.tqdm(data[\"data\"]):\n",
    "        for paragraph in paragraphs[\"paragraphs\"]:\n",
    "            context = spacy_nlp(paragraph[\"context\"], disable=disabled_components[:1])\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                id_ = qa[\"id\"]\n",
    "                question = spacy_nlp(qa[\"question\"], disable=disabled_components)\n",
    "                for answer in qa[\"answers\"]:\n",
    "                    qas.append(RawDatasetItem(id_=id_, context=context, question=question,\n",
    "                                              answer=spacy_nlp(answer[\"text\"], disable=disabled_components),\n",
    "                                              answer_start_index=answer[\"answer_start\"]))\n",
    "    return qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MeqBr7Ov9ZU",
    "outputId": "2dad6d53-186e-41d5-dd61-0da6ac26c314",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [06:58<00:00,  1.06it/s]\n",
      "100%|██████████| 48/48 [01:15<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train qa pairs: 87,599\n",
      "Length of valid qa pairs: 34,726\n",
      "Train example: RawDatasetItem(id_='56cc100b6d243a140015ee8d', context=During the summers at Nohant, particularly in the years 1839–43, Chopin found quiet, productive days during which he composed many works, including his Polonaise in A-flat major, Op. 53. Among the visitors to Nohant were Delacroix and the mezzo-soprano Pauline Viardot, whom Chopin had advised on piano technique and composition. Delacroix gives an account of staying at Nohant in a letter of 7 June 1842:, question=On what date did Delacroix write a letter based on his visit at Nohant?, answer=7 June 1842, answer_start_index=393, target=None)\n",
      "CPU times: user 8min 12s, sys: 2.99 s, total: 8min 15s\n",
      "Wall time: 8min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "language = spacy.load(name=\"en_core_web_lg\")\n",
    "\n",
    "train_qas = parse_squad_v1_data(data=train_raw_data, spacy_nlp=language)\n",
    "valid_qas = parse_squad_v1_data(data=valid_raw_data, spacy_nlp=language)\n",
    "print(f\"Length of train qa pairs: {len(train_qas):,}\")\n",
    "print(f\"Length of valid qa pairs: {len(valid_qas):,}\")\n",
    "print(f\"Train example: {train_qas[random.randint(a=0, b=len(train_qas) - 1)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bafKgiFv1GHa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_answer_start_indexes(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        assert qa.answer.text == qa.context.text[qa.answer_start_index:qa.answer_start_index + len(qa.answer.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tTDTQod23-g",
    "outputId": "022c7d5f-cfbf-4b12-b4f9-e6882a9cef07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:03<00:00, 24876.04it/s]\n",
      "100%|██████████| 34726/34726 [00:01<00:00, 25926.47it/s]\n"
     ]
    }
   ],
   "source": [
    "test_answer_start_indexes(qas=train_qas)\n",
    "test_answer_start_indexes(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxhCfiNY28zs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Add targets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "k4bpqV3S27SQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_targets_to_squad_v1_data(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        for i in range(len(qa.context)):\n",
    "            if qa.context[i].idx == qa.answer_start_index:\n",
    "                answer = qa.context[i:i + len(qa.answer)]\n",
    "                qa.target = Target(start_index=answer[0].i, end_index=answer[-1].i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waJedA674CCH",
    "outputId": "84672e5a-a68e-473b-8be8-c7a2e10a0698",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:02<00:00, 39131.55it/s]\n",
      "100%|██████████| 34726/34726 [00:00<00:00, 38254.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 10.2 ms, total: 3.17 s\n",
      "Wall time: 3.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "add_targets_to_squad_v1_data(qas=train_qas)\n",
    "add_targets_to_squad_v1_data(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lT65eePm4F9w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_bad_item(qa: RawDatasetItem) -> bool:\n",
    "    \"\"\"Return True if either the target is None or target indexes don't match the answer. Return False otherwise\"\"\"\n",
    "    if qa.target is None:\n",
    "        return False\n",
    "    return qa.answer.text == qa.context[qa.target.start_index:qa.target.end_index + 1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_nUlM_n4Mgc",
    "outputId": "cde0cb35-dd18-4ba5-f4a4-a63a46ec6db7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train qa pairs after filtering out bad qa pairs: 86,676\n",
      "Length of valid qa pairs after filtering out bad qa pairs: 34,364\n",
      "CPU times: user 682 ms, sys: 9 µs, total: 682 ms\n",
      "Wall time: 680 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qas = [*filter(is_bad_item, train_qas)]\n",
    "valid_qas = [*filter(is_bad_item, valid_qas)]\n",
    "print(f\"Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}\")\n",
    "print(f\"Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qKEhn4eI4P5B",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_targets(qas: List[RawDatasetItem]) -> None:\n",
    "    for qa in qas:\n",
    "        assert qa.answer.text == qa.context[qa.target.start_index:qa.target.end_index + 1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6O_fmDJl5R7V",
    "outputId": "999e5ada-e4ec-44ae-f40c-682b08cbb7b6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 645 ms, sys: 34 µs, total: 645 ms\n",
      "Wall time: 643 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_targets(qas=train_qas)\n",
    "test_targets(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkLppZOP5Vju",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Add features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "O8Y038pt5VIc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TokenFeature(_UnpackingDataClassMixin):\n",
    "    exact_match: List[bool]\n",
    "    part_of_speech: List[str]\n",
    "    named_entity_type: List[str]\n",
    "    normalized_term_frequency: List[float]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DrQARawDatasetItem(RawDatasetItem):\n",
    "    token_feature: TokenFeature = None\n",
    "\n",
    "\n",
    "def add_extra_features_squad_v1(qas: List[RawDatasetItem]) -> List[DrQARawDatasetItem]:\n",
    "    \"\"\"Add extra features: Exact Match, Part-of-Speech, Name Entity Recognition & Normalized Term Frequency\"\"\"\n",
    "    qa_token_features = []\n",
    "    for qa in tqdm.tqdm(qas):  # type: RawDatasetItem\n",
    "        question = [token.text.lower() for token in qa.question]\n",
    "        count_context_tokens = collections.Counter(map(lambda token: token.text.lower(), qa.context))\n",
    "\n",
    "        frequency_context_tokens: Dict[int, int] = {}\n",
    "        for index, token in enumerate(qa.context):  # type: int, Token\n",
    "            frequency_context_tokens[index] = count_context_tokens[token.text.lower()]\n",
    "        norm_frequency_context_tokens = sum(frequency_context_tokens.values())\n",
    "\n",
    "        token_feature = TokenFeature(\n",
    "            exact_match=[qa.context[index].text.lower() in question for index in range(len(qa.context))],\n",
    "            part_of_speech=[qa.context[index].tag_ for index in range(len(qa.context))],\n",
    "            named_entity_type=[qa.context[index].ent_type_ for index in range(len(qa.context))],\n",
    "            normalized_term_frequency=[\n",
    "                frequency_context_tokens[index] / norm_frequency_context_tokens for index in range(len(qa.context))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        qa_token_features.append(\n",
    "            DrQARawDatasetItem(\n",
    "                id_=qa.id_,\n",
    "                context=qa.context,\n",
    "                question=qa.question,\n",
    "                answer=qa.answer,\n",
    "                answer_start_index=qa.answer_start_index,\n",
    "                target=qa.target,\n",
    "                token_feature=token_feature\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return qa_token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqwcbDgPSmp8",
    "outputId": "8df2a4a8-4c18-478b-980e-16ab98a78e3a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86676/86676 [00:25<00:00, 3452.10it/s]\n",
      "100%|██████████| 34364/34364 [00:09<00:00, 3510.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 s, sys: 1.59 s, total: 35.1 s\n",
      "Wall time: 34.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_qas = add_extra_features_squad_v1(qas=train_qas)\n",
    "valid_qas = add_extra_features_squad_v1(qas=valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8SrKXlfoU5y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build vocabularies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, padding_token: str, unknown_token: str):\n",
    "        self.padding_token = padding_token\n",
    "        self.unknown_token = unknown_token\n",
    "\n",
    "        self.vocabulary: List[str] = []\n",
    "        self.word2count: Dict[str, int] = {}\n",
    "        self.word2index: Dict[str, int] = {}\n",
    "        self.index2word: Dict[int, str] = {}\n",
    "\n",
    "    def build(self, data: List[Union[Doc, str]], min_word_frequency: int) -> None:\n",
    "        words = []\n",
    "\n",
    "        type_ = type(data[0])\n",
    "        if type_ == Doc:\n",
    "            for item in data:  # Doc\n",
    "                words += [word.text.lower() for word in item]\n",
    "        elif type_ == str:\n",
    "            words += data\n",
    "        else:\n",
    "            raise TypeError(f\"The type {type_} is not supported!\")\n",
    "\n",
    "        self.word2count = collections.Counter(words)\n",
    "        self.vocabulary = [self.padding_token] + sorted(filter(\n",
    "            lambda word: self.word2count[word] >= min_word_frequency,\n",
    "            self.word2count\n",
    "        )) + [self.unknown_token]  # Ensure that pad token gets index 0 and unknown token gets the las index\n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocabulary)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocabulary)}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.vocabulary)\n",
    "\n",
    "    def stoi(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        Return the index of the word in the vocabulary.\n",
    "        Return the index of the unknown token if that word doesn't exist in the vocabulary.\n",
    "        \"\"\"\n",
    "        return self.word2index.get(word, self.word2index[self.unknown_token])\n",
    "\n",
    "    def itos(self, index: int) -> str:\n",
    "        \"\"\"Return the word of the index in the vocabulary.\"\"\"\n",
    "        return self.index2word[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of id vocabulary: 97,200\n",
      "Length of text vocabulary: 26,884\n",
      "Length of part of speech vocabulary: 52\n",
      "Length of named entity type vocabulary: 21\n",
      "CPU times: user 4.53 s, sys: 290 ms, total: 4.82 s\n",
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PADDING_TOKEN = \"<pad>\"\n",
    "UNKNOWN_TOKEN = \"<unk>\"\n",
    "MIN_FREQUENCY = 5\n",
    "\n",
    "ids = [*map(lambda qa: qa.id_, train_qas)] + [*map(lambda qa: qa.id_, valid_qas)]\n",
    "contexts, questions = zip(*map(lambda qa: (qa.context, qa.question), train_qas))\n",
    "part_of_speeches = [*itertools.chain.from_iterable(map(lambda qa: qa.token_feature.part_of_speech, train_qas))]\n",
    "named_entity_types = [*itertools.chain.from_iterable(map(lambda qa: qa.token_feature.named_entity_type, train_qas))]\n",
    "\n",
    "id_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "text_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "part_of_speech_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "named_entity_types_vocabulary = Vocabulary(padding_token=PADDING_TOKEN, unknown_token=UNKNOWN_TOKEN)\n",
    "\n",
    "id_vocabulary.build(data=[*set(ids)], min_word_frequency=0)\n",
    "text_vocabulary.build(data=[*set(contexts + questions)], min_word_frequency=MIN_FREQUENCY)\n",
    "part_of_speech_vocabulary.build(data=[*set(part_of_speeches)], min_word_frequency=0)\n",
    "named_entity_types_vocabulary.build(data=[*set(named_entity_types)], min_word_frequency=0)\n",
    "\n",
    "print(f\"Length of id vocabulary: {len(id_vocabulary):,}\")\n",
    "print(f\"Length of text vocabulary: {len(text_vocabulary):,}\")\n",
    "print(f\"Length of part of speech vocabulary: {len(part_of_speech_vocabulary):,}\")\n",
    "print(f\"Length of named entity type vocabulary: {len(named_entity_types_vocabulary):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iotg02zlAflQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class DrQATensorDatasetItem(_UnpackingDataClassMixin):\n",
    "    id_: torch.LongTensor\n",
    "    context: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]\n",
    "    question: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]\n",
    "    target: torch.LongTensor\n",
    "    exact_match: torch.LongTensor\n",
    "    part_of_speech: torch.LongTensor\n",
    "    named_entity_type: torch.LongTensor\n",
    "    normalized_term_frequency: torch.FloatTensor\n",
    "\n",
    "\n",
    "class SquadV1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: List[DrQARawDatasetItem], id_vocab: Vocabulary, text_vocab: Vocabulary,\n",
    "                 pos_vocab: Vocabulary, ner_vocab: Vocabulary):\n",
    "        self.data = data\n",
    "        self.id_vocab = id_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.text_vocab = text_vocab\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> DrQATensorDatasetItem:\n",
    "        item: DrQARawDatasetItem = self.data[idx]\n",
    "        id_ = torch.LongTensor([self.id_vocab.stoi(item.id_)])\n",
    "        context = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item.context)])\n",
    "        question = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item.question)])\n",
    "        target = torch.LongTensor([item.target.start_index, item.target.end_index])\n",
    "        exact_match = torch.LongTensor(item.token_feature.exact_match)\n",
    "        part_of_speech = torch.LongTensor(\n",
    "            [*map(lambda token: self.pos_vocab.stoi(token), item.token_feature.part_of_speech)])\n",
    "        named_entity_type = torch.LongTensor(\n",
    "            [*map(lambda token: self.ner_vocab.stoi(token), item.token_feature.named_entity_type)])\n",
    "        normalized_term_frequency = torch.FloatTensor(item.token_feature.normalized_term_frequency)\n",
    "        return DrQATensorDatasetItem(\n",
    "            id_=id_,\n",
    "            context=context,\n",
    "            question=question,\n",
    "            target=target,\n",
    "            exact_match=exact_match,\n",
    "            part_of_speech=part_of_speech,\n",
    "            named_entity_type=named_entity_type,\n",
    "            normalized_term_frequency=normalized_term_frequency\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMgSisEt8ARe",
    "outputId": "735861e8-f6c2-49bb-b8e8-7d5da12ef11a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_ shape: torch.Size([1])\n",
      "context shape: torch.Size([142])\n",
      "question shape: torch.Size([14])\n",
      "target shape: torch.Size([2])\n",
      "exact_match shape: torch.Size([142])\n",
      "part_of_speech shape: torch.Size([142])\n",
      "named_entity_type shape: torch.Size([142])\n",
      "normalized_term_frequency shape: torch.Size([142])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SquadV1Dataset(\n",
    "    data=train_qas,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    pos_vocab=part_of_speech_vocabulary,\n",
    "    ner_vocab=named_entity_types_vocabulary\n",
    ")\n",
    "valid_dataset = SquadV1Dataset(\n",
    "    data=valid_qas,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    pos_vocab=part_of_speech_vocabulary,\n",
    "    ner_vocab=named_entity_types_vocabulary\n",
    ")\n",
    "\n",
    "train_dataset_item = train_dataset[0]\n",
    "print(f\"id_ shape: {train_dataset_item.id_.shape}\")\n",
    "print(f\"context shape: {train_dataset_item.context.shape}\")\n",
    "print(f\"question shape: {train_dataset_item.question.shape}\")\n",
    "print(f\"target shape: {train_dataset_item.target.shape}\")\n",
    "print(f\"exact_match shape: {train_dataset_item.exact_match.shape}\")\n",
    "print(f\"part_of_speech shape: {train_dataset_item.part_of_speech.shape}\")\n",
    "print(f\"named_entity_type shape: {train_dataset_item.named_entity_type.shape}\")\n",
    "print(f\"normalized_term_frequency shape: {train_dataset_item.normalized_term_frequency.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZQaVaHt_MDc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Build data loaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cYMYz3-SBYzf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DrQATensorDatasetBatch = DrQATensorDatasetItem\n",
    "\n",
    "def add_padding_and_batch_data(batch: List[DrQATensorDatasetItem], id_vocab: Vocabulary, text_vocab: Vocabulary,\n",
    "                               pos_vocab: Vocabulary, ner_vocab: Vocabulary, include_lengths: bool,\n",
    "                               device: torch.device) -> DrQATensorDatasetBatch:\n",
    "    batch_id = [item.id_ for item in batch]\n",
    "    batch_context = [item.context for item in batch]\n",
    "    batch_question = [item.question for item in batch]\n",
    "    batch_target = [item.target for item in batch]\n",
    "    batch_exact_match = [item.exact_match for item in batch]\n",
    "    batch_part_of_speech = [item.part_of_speech for item in batch]\n",
    "    batch_named_entity_type = [item.named_entity_type for item in batch]\n",
    "    batch_normalized_term_frequency = [item.normalized_term_frequency for item in batch]\n",
    "\n",
    "    length_context, length_question = None, None\n",
    "    if include_lengths:\n",
    "        length_context = torch.LongTensor([context.size(0) for context in batch_context])  # .to(device)\n",
    "        length_question = torch.LongTensor([question.size(0) for question in batch_question])  # .to(device)\n",
    "\n",
    "    batch_padded_id = pad_sequence(batch_id,\n",
    "                                   batch_first=True,\n",
    "                                   padding_value=id_vocab.stoi(id_vocab.padding_token)).to(device)\n",
    "    batch_padded_context = pad_sequence(batch_context,\n",
    "                                        batch_first=True,\n",
    "                                        padding_value=text_vocab.stoi(text_vocab.padding_token)).to(device)\n",
    "    batch_padded_question = pad_sequence(batch_question,\n",
    "                                         batch_first=True,\n",
    "                                         padding_value=text_vocab.stoi(text_vocab.padding_token)).to(device)\n",
    "    batch_padded_target = pad_sequence(batch_target, batch_first=True).to(device)\n",
    "    batch_padded_exact_match = pad_sequence(batch_exact_match, batch_first=True).to(device)\n",
    "    batch_padded_part_of_speech = pad_sequence(batch_part_of_speech,\n",
    "                                               batch_first=True,\n",
    "                                               padding_value=pos_vocab.stoi(pos_vocab.padding_token)).to(device)\n",
    "    batch_padded_normalized_term_frequency = pad_sequence(batch_normalized_term_frequency, batch_first=True).to(device)\n",
    "    batch_padded_named_entity_type = pad_sequence(batch_named_entity_type,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=ner_vocab.stoi(ner_vocab.padding_token)).to(device)\n",
    "    return DrQATensorDatasetBatch(\n",
    "        id_=batch_padded_id,\n",
    "        context=(batch_padded_context, length_context),\n",
    "        question=(batch_padded_question, length_question),\n",
    "        target=batch_padded_target,\n",
    "        exact_match=batch_padded_exact_match,\n",
    "        part_of_speech=batch_padded_part_of_speech,\n",
    "        named_entity_type=batch_padded_named_entity_type,\n",
    "        normalized_term_frequency=batch_padded_normalized_term_frequency\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zu2ovPqxA7Ix",
    "outputId": "02a52daa-a8ec-45de-c916-995fe7e860c4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs: torch.Size([32, 1])\n",
      "Context: torch.Size([32, 253]) torch.Size([32])\n",
      "Question: torch.Size([32, 19]) torch.Size([32])\n",
      "Target: torch.Size([32, 2])\n",
      "Exact match: torch.Size([32, 253])\n",
      "Part of speech: torch.Size([32, 253])\n",
      "Named entity type: torch.Size([32, 253])\n",
      "Normalized term frequency: torch.Size([32, 253])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "collate_function = functools.partial(add_padding_and_batch_data,\n",
    "                                     id_vocab=id_vocabulary,\n",
    "                                     text_vocab=text_vocabulary,\n",
    "                                     pos_vocab=part_of_speech_vocabulary,\n",
    "                                     ner_vocab=named_entity_types_vocabulary,\n",
    "                                     include_lengths=True,\n",
    "                                     device=DEVICE)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_function)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_function)\n",
    "\n",
    "for batch in train_dataloader:  # type: DrQATensorDatasetBatch\n",
    "    print(\"IDs:\", batch.id_.shape)\n",
    "    print(\"Context:\", batch.context[0].shape, batch.context[1].shape)\n",
    "    print(\"Question:\", batch.question[0].shape, batch.question[1].shape)\n",
    "    print(\"Target:\", batch.target.shape)\n",
    "    print(\"Exact match:\", batch.exact_match.shape)\n",
    "    print(\"Part of speech:\", batch.part_of_speech.shape)\n",
    "    print(\"Named entity type:\", batch.named_entity_type.shape)\n",
    "    print(\"Normalized term frequency:\", batch.normalized_term_frequency.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2O79r_CLvGu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Download pretrained GloVe embedding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrSXYalOmRak",
    "outputId": "bc303808-01ad-4f75-c884-0a337681eb7b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# !sudo wget --no-check-certificate \\\n",
    "#     http://nlp.stanford.edu/data/glove.840B.300d.zip \\\n",
    "#     -O ./data/glove.840B.300d.zip\n",
    "# !unzip -q ./data/glove.840B.300d.zip -d ./data\n",
    "# !rm -r ./data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BL0JZuEmmf5C",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path: str) -> Dict[str, np.ndarray]:\n",
    "    glove_embeddings = {}\n",
    "    try:\n",
    "        file = open(path, mode='r', encoding=\"utf-8\")\n",
    "        for line in tqdm.tqdm(file):\n",
    "            values = line.split(' ')\n",
    "            glove_embeddings[values[0]] = np.asarray(values[1:], dtype=\"float32\")\n",
    "        return glove_embeddings\n",
    "    except IOError:\n",
    "        raise IOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDX8b2EJm1uZ",
    "outputId": "c477bc5e-4b5f-4880-8916-fa53fd7ef300",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [03:22, 10861.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 18.8 s, total: 1min 53s\n",
      "Wall time: 3min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "glove_embeddings = load_glove_embeddings(path=\"./data/glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "ELVYepbbm7ny",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_embeddings(embeddings: Dict[str, np.ndarray], text_vocab: Vocabulary, embedding_size: int) -> Tuple[np.ndarray, List[int], List[int]]:\n",
    "    found_indexes, not_found_indexes = [], []\n",
    "    embedding_matrix = np.zeros((len(text_vocab), embedding_size))\n",
    "    most_common_indexes = []\n",
    "    for index, word in enumerate(text_vocab.vocabulary):\n",
    "        try:\n",
    "            if word in embeddings:\n",
    "                found_indexes.append(index)\n",
    "                embedding_matrix[index] = embeddings[word]\n",
    "            else:\n",
    "                not_found_indexes.append(index)\n",
    "        except KeyError:\n",
    "            raise KeyError\n",
    "        except ValueError:\n",
    "            raise ValueError\n",
    "    return embedding_matrix, found_indexes, not_found_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3CUDosl_n5HA",
    "outputId": "ce6edfc0-2a4e-41ba-dc6d-8ddf703b6501",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words found in GLoVE embeddings: 25411/26884 = 94.52%\n",
      "Number of words not found in GLoVE embeddings: 1473/26884 = 5.48%\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, found_indexes, not_found_indexes = extract_embeddings(\n",
    "    embeddings=glove_embeddings,\n",
    "    text_vocab=text_vocabulary,\n",
    "    embedding_size=300\n",
    ")\n",
    "print(f\"Number of words found in GLoVE embeddings: {len(found_indexes)}/{len(text_vocabulary)} = {100 * len(found_indexes) / len(text_vocabulary):.2f}%\")\n",
    "print(f\"Number of words not found in GLoVE embeddings: {len(not_found_indexes)}/{len(text_vocabulary)} = {100 * len(not_found_indexes) / len(text_vocabulary):.2f}%\")\n",
    "np.save(\"./data/GloVe_DrQA.npy\", embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/GloVe_DrQA.npy\", embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "JZzbAOFAmfnT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Free up the RAM\n",
    "# del glove_embeddings\n",
    "# del embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxnYdks-L31E",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeling\n",
    "\n",
    "***Stacked Bidirectional LSTM Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DoHYvqQQCEGw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StackedBiLSTMsLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size: int, hidden_size: int, n_layers: int, dropout: float):\n",
    "        \"\"\"\n",
    "        :param embedding_size: Size of word embedding.\n",
    "        :param hidden_size: Hidden size of lstm layers.\n",
    "        :param n_layers: Number of layers.\n",
    "        :param dropout: Dropout value in [0, 1).\n",
    "        \"\"\"\n",
    "        super(StackedBiLSTMsLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=embedding_size if i == 0 else hidden_size * 2, hidden_size=hidden_size,\n",
    "                batch_first=True, num_layers=n_layers, bidirectional=True\n",
    "            ) for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def __forward_lstm(self, layer: nn.Module, inputs: Tensor, lengths: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        :param layer: LSTM layer.\n",
    "        :param inputs: Sequence inputs. FloatTensor[batch_size, seq_len, embedding_size|hidden_size * 2]\n",
    "        :param lengths: Sequence lengths. LongTensor[batch_size,]\n",
    "        :return:\n",
    "            padded_outputs FloatTensor[batch_size, seq_len, hidden_size * 2]\n",
    "            outputs_lengths LongTensor[batch_size,]\n",
    "        \"\"\"\n",
    "        seq_len = inputs.size(1)\n",
    "        inputs = self.dropout(inputs)\n",
    "        packed_inputs = pack_padded_sequence(input=inputs, lengths=lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_outputs, _ = layer(packed_inputs)\n",
    "        padded_outputs, outputs_lengths = pad_packed_sequence(sequence=packed_outputs,\n",
    "                                                              batch_first=True,\n",
    "                                                              total_length=seq_len)\n",
    "        return padded_outputs, outputs_lengths\n",
    "\n",
    "    def forward(self, embedded_inputs: Tensor, sequence_lengths: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param embedded_inputs: Sequence inputs. FloatTensor[batch_size, seq_len, embedding_size]\n",
    "        :param sequence_lengths: Sequence lengths. LongTensor[batch_size,]\n",
    "        :return: FloatTensor[batch_size, sequence_lengths, n_layers * hidden_size * 2]\n",
    "        \"\"\"\n",
    "        outputs, lens = [embedded_inputs], sequence_lengths\n",
    "        for lstm_layer in self.lstm_layers:\n",
    "            out, lens = self.__forward_lstm(layer=lstm_layer, inputs=outputs[-1], lengths=lens)\n",
    "            outputs.append(out)\n",
    "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oazq30eW3_T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Aligned Question Embedding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ATOQC6-pWzq_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlignedQuestionEmbeddingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size: int, hidden_size: int):\n",
    "        \"\"\"\n",
    "        Aligned Question Embedding\n",
    "        $$f_{align}(p_i) = \\sum_j a_{i, j}E(q_j)$$\n",
    "        where the attention score $a_{i, j}$ captures the similarity between $p_i$ and each question words $q_j$.\n",
    "        Specifically, $a_{i, j}$ is computed by the dot products between nonlinear mappings of word embeddings:\n",
    "        $$a_{i, j} = \\frac{exp(\\alpha(E(p_i)).\\alpha(E(q_j)))}{\\sum_{j'}exp(\\alpha(E(p_i)).\\alpha(E(q_{j'})))}$$,\n",
    "        and $\\alpha(.)$ is a single dense layer with ReLU non-linearity. Compared to the exact match features, these\n",
    "        features add soft alignments between similar but non-identical words (e.g., car and vehicle)\n",
    "\n",
    "        :param embedding_size: Size of word embedding.\n",
    "        :param hidden_size: Hidden size of the dense layer.\n",
    "        \"\"\"\n",
    "        super(AlignedQuestionEmbeddingLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.dense = nn.Linear(in_features=embedding_size, out_features=hidden_size)\n",
    "\n",
    "    def forward(self, context_sequence: Tensor, question_sequence: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param context_sequence: Sequence context inputs. FloatTensor[batch_size, ctx_seq_len, embedding_size]\n",
    "        :param question_sequence: Sequence question inputs. FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, ctx_seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        context_logits = F.relu(self.dense(context_sequence))  # [batch_size, ctx_seq_len, hidden_size]\n",
    "        question_logits = F.relu(self.dense(question_sequence))  # [batch_size, qst_seq_len, hidden_size]\n",
    "        scores = torch.bmm(context_logits, question_logits.transpose(-1, -2))  # [batch_size, ctx_seq_len, qst_seq_len]\n",
    "        # Mask scores in order to force attention weights corresponding to padding tokens to be 0.\n",
    "        scores = scores.masked_fill(question_mask.unsqueeze(1) == 0, float(\"-inf\"))\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # [batch_size, ctx_seq_len, qst_seq_len]\n",
    "        return torch.bmm(attention_weights, question_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImX8ayztYjsK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Question Encoding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Whil-FgVYhgy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionEncodingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size: int, hidden_size: int, n_layers: int, dropout: float):\n",
    "        \"\"\"\n",
    "        The question encoding consists of applying a recurrent neural network on top of the word embeddings of $q_i$\n",
    "        and combine the resulting hidden units into one single vector: $\\{q_1, ..., q_l\\} \\rightarrow q$. We compute\n",
    "        $q = \\sum_j{b_j q_j}$ where $b_j$ encodes the importance of each question word:\n",
    "        $$b_j = \\frac{exp(w.q_j)}{\\sum_{j'}{exp(w.q_{j'})}}$$\n",
    "        and $w$ is a weight vector to learn\n",
    "\n",
    "        :param embedding_size:\n",
    "        :param hidden_size:\n",
    "        :param n_layers:\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super(QuestionEncodingLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.stacked_bilstm_layers = StackedBiLSTMsLayer(\n",
    "            embedding_size=embedding_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout\n",
    "        )\n",
    "        self.dense = nn.Linear(in_features=embedding_size, out_features=1, bias=False)\n",
    "\n",
    "    def __linear_self_attention(self, question_embedded: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param question_embedded: FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, qst_seq_len]\n",
    "        \"\"\"\n",
    "        scores = self.dense(question_embedded).squeeze(-1)  # [batch_size, qst_seq_len]\n",
    "        scores = scores.masked_fill(question_mask == 0, float(\"-inf\"))\n",
    "        return F.softmax(scores, dim=-1)\n",
    "\n",
    "    def forward(self, question_embedded: Tensor, question_lengths: Tensor, question_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param question_embedded: FloatTensor[batch_size, qst_seq_len, embedding_size]\n",
    "        :param question_lengths: Sequence question lengths. LongTensor[batch_size,]\n",
    "        :param question_mask: Mask of question regarding if it is a padding token or not.\n",
    "            IntTensor[batch_size, qst_seq_len]\n",
    "        :return: FloatTensor[batch_size, n_layers * hidden_size * 2]\n",
    "        \"\"\"\n",
    "        lstm_outputs = self.stacked_bilstm_layers(embedded_inputs=question_embedded, sequence_lengths=question_lengths)\n",
    "        # lstm_outputs: [batch_size, qst_seq_len, n_layers * hidden_size * 2]\n",
    "        attention_weights = self.__linear_self_attention(\n",
    "            question_embedded=question_embedded, question_mask=question_mask\n",
    "        )  # [batch_size, qst_seq_len]\n",
    "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hFIZnmUaFAu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***BiLinear Attention Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "JZGOH3IhaEZw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BiLinearAttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, context_hidden_size: int, question_hidden_size: int):\n",
    "        \"\"\"\n",
    "        At the paragraph level, the goal is to predict the span of tokens that is most likely the correct answer.\n",
    "        We take the paragraph vectors $\\{p_1, ... , p_m\\}$ and the question vector $q$ as input, and simply train two\n",
    "        classifiers independently for predicting the two ends of the span.\n",
    "        Concretely, we use a bi-linear term to capture the similarity between $p_i$ and $q$ and compute the\n",
    "        probabilities of each token being start and end as:\n",
    "        $$\n",
    "        P_{start}(i) \\propto exp(p_i W_s q) \\\\\n",
    "        P_{end}(i) \\propto exp(p_i W_e q)\n",
    "        $$\n",
    "\n",
    "        :param context_hidden_size:\n",
    "        :param question_hidden_size:\n",
    "        \"\"\"\n",
    "        super(BiLinearAttentionLayer, self).__init__()\n",
    "        self.context_hidden_size = context_hidden_size\n",
    "        self.question_hidden_size = question_hidden_size\n",
    "\n",
    "        self.dense = nn.Linear(in_features=question_hidden_size, out_features=context_hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, context_encoded: Tensor, question_encoded: Tensor, context_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param context_encoded: FloatTensor[batch_size, ctx_seq_len, ctx_hid_size]\n",
    "        :param question_encoded: FloatTensor[batch_size, qst_seq_len]\n",
    "        :param context_mask: IntTensor[batch_size, ctx_seq_len]\n",
    "        :return FloatTensor[batch_size, ctx_seq_len]\n",
    "        \"\"\"\n",
    "        question_encoded = self.dense(question_encoded)  # [batch_size, ctx_hid_size]\n",
    "        scores = torch.bmm(context_encoded, question_encoded.unsqueeze(-1)).squeeze(-1)  # [batch_size, ctx_seq_len]\n",
    "        return scores.masked_fill(context_mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzrmk6D7agHH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Document reader Question Answering Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "qlZlTFXOae_o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "    def make_sequence_mask(self, input_sequence: Tensor) -> Tensor:\n",
    "        return input_sequence != self.padding_index\n",
    "    \n",
    "    def load_word_embeddings(self, embedding_matrix: np.ndarray, tune: bool, found_indexes: List[int]):\n",
    "        def tune_embeddings(grad, word_indexes: List[int]):\n",
    "            grad[word_indexes] = 0\n",
    "            return grad\n",
    "\n",
    "        self.embedding_layer.weight = nn.Parameter(torch.FloatTensor(embedding_matrix))\n",
    "        if tune:\n",
    "            self.embedding_layer.weight.register_hook(\n",
    "                functools.partial(tune_embeddings, word_indexes=found_indexes)\n",
    "            )  # Only fine-tune the words that aren't present in embeddings matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(starts: Tensor, ends: Tensor) -> Tuple[List[int], List[int], List[float]]:\n",
    "        \"\"\"\n",
    "        :param starts: FloatTensor[batch_size, ctx_seq_len]\n",
    "        :param ends: FloatTensor[batch_size, ctx_seq_len]\n",
    "        :return: Tuple[List[int], List[int], List[float]]\n",
    "        \"\"\"\n",
    "        start_indexes, end_indexes, predicted_probabilities = [], [], []\n",
    "        for i in range(starts.size(0)):\n",
    "            probabilities = torch.ger(starts[i], ends[i])  # [ctx_seq_len, ctx_seq_len]\n",
    "            probability, index = torch.topk(probabilities.view(-1), k=1)\n",
    "\n",
    "            start_indexes.append(index.tolist()[0] // probabilities.size(0))\n",
    "            end_indexes.append(index.tolist()[0] % probabilities.size(1))\n",
    "\n",
    "            predicted_probabilities.append(probability.tolist()[0])\n",
    "\n",
    "        return start_indexes, end_indexes, predicted_probabilities\n",
    "\n",
    "    def count_parameters(self) -> int:\n",
    "        return sum(parameter.numel() for parameter in self.parameters() if parameter.requires_grad)\n",
    "\n",
    "\n",
    "class DrQA(BaseModel):\n",
    "    \n",
    "    def __init__(self, vocabulary_size: int, embedding_size, n_extra_features: int, hidden_size: int, n_layers: int,\n",
    "                 dropout: float, padding_index: int):\n",
    "        \"\"\"\n",
    "        During prediction, we choose the best span from token $i$ to token $i'$ such that $i ≤ i' ≤ i + 15$ and\n",
    "        $P_{start}(i)×P_{end}(i')$ is maximized. To make score compatible across paragraphs in one or several retrieved\n",
    "        documents, we use the un-normalized exponential and take argmax over all considered paragraph spans for our\n",
    "        final prediction.\n",
    "\n",
    "        :param vocabulary_size:\n",
    "        :param embedding_size:\n",
    "        :param n_extra_features:\n",
    "        :param hidden_size:\n",
    "        :param n_layers:\n",
    "        :param dropout:\n",
    "        :param padding_index:\n",
    "        \"\"\"\n",
    "        super(DrQA, self).__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_extra_features = n_extra_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.padding_index = padding_index\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=vocabulary_size,\n",
    "            embedding_dim=embedding_size,\n",
    "            padding_idx=padding_index\n",
    "        )\n",
    "        self.aligned_question_embedding_layer = AlignedQuestionEmbeddingLayer(\n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size\n",
    "        )\n",
    "        self.context_lstm_layer = StackedBiLSTMsLayer(\n",
    "            embedding_size=embedding_size + hidden_size + n_extra_features,\n",
    "            hidden_size=hidden_size,\n",
    "            n_layers=n_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.question_encoding_layer = QuestionEncodingLayer(\n",
    "            embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=dropout,\n",
    "            n_layers=n_layers\n",
    "        )\n",
    "        self.bilinear_attention_start_layer = BiLinearAttentionLayer(\n",
    "            context_hidden_size=hidden_size * n_layers * 2,\n",
    "            question_hidden_size=hidden_size * n_layers * 2\n",
    "        )\n",
    "        self.bilinear_attention_end_layer = BiLinearAttentionLayer(\n",
    "            context_hidden_size=hidden_size * n_layers * 2,\n",
    "            question_hidden_size=hidden_size * n_layers * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: DrQATensorDatasetBatch) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        :param batch: DrQATensorDatasetBatch\n",
    "        :return: Tuple[FloatTensor[batch_size, ctx_seq_len], FloatTensor[batch_size, ctx_seq_len]]\n",
    "        \"\"\"\n",
    "        context_sequence = batch.context[0]  # [batch_size, ctx_seq_len]\n",
    "        context_lengths = batch.context[1]  # [batch_size,]\n",
    "        question_sequence = batch.question[0]  # [batch_size, qst_seq_len]\n",
    "        question_lengths = batch.question[1]  # [batch_size,]\n",
    "        exact_matches = batch.exact_match  # [batch_size, ctx_seq_len]\n",
    "        part_of_speeches = batch.part_of_speech  # [batch_size, ctx_seq_len]\n",
    "        named_entity_types = batch.named_entity_type  # [batch_size, ctx_seq_len]\n",
    "        normalized_term_frequencies = batch.normalized_term_frequency  # [batch_size, ctx_seq_len]\n",
    "\n",
    "        context_mask = self.make_sequence_mask(input_sequence=context_sequence)  # [batch_size, ctx_seq_len]\n",
    "        question_mask = self.make_sequence_mask(input_sequence=question_sequence)  # [batch_size, qst_seq_len]\n",
    "\n",
    "        context_embedded = self.embedding_layer(context_sequence)  # [batch_size, ctx_seq_len, embedding_size]\n",
    "        question_embedded = self.embedding_layer(question_sequence)  # [batch_size, qst_seq_len, embedding_size]\n",
    "\n",
    "        context_aligned = self.aligned_question_embedding_layer(\n",
    "            context_sequence=context_embedded,\n",
    "            question_sequence=question_embedded,\n",
    "            question_mask=question_mask\n",
    "        )  # [batch_size, ctx_len, embedding_size]\n",
    "\n",
    "        context_inputs = torch.cat([\n",
    "            context_aligned, context_embedded, exact_matches.unsqueeze(-1), part_of_speeches.unsqueeze(-1),\n",
    "            named_entity_types.unsqueeze(-1), normalized_term_frequencies.unsqueeze(-1)\n",
    "        ], dim=-1)  # [batch_size, ctx_seq_len, embedding_size + hidden_size + 4]\n",
    "\n",
    "        context_encoded = self.context_lstm_layer(\n",
    "            embedded_inputs=context_inputs,\n",
    "            sequence_lengths=context_lengths\n",
    "        )  # [batch_size, ctx_seq_len, n_layers * hidden_size * 2]\n",
    "        question_encoded = self.question_encoding_layer(\n",
    "            question_embedded=question_embedded,\n",
    "            question_lengths=question_lengths,\n",
    "            question_mask=question_mask\n",
    "        )  # [batch_size, n_layers * hidden_size * 2]\n",
    "\n",
    "        start_scores = self.bilinear_attention_start_layer(\n",
    "            context_encoded=context_encoded,\n",
    "            question_encoded=question_encoded,\n",
    "            context_mask=context_mask\n",
    "        )  # [batch_size, ctx_seq_len]\n",
    "        end_scores = self.bilinear_attention_end_layer(\n",
    "            context_encoded=context_encoded,\n",
    "            question_encoded=question_encoded,\n",
    "            context_mask=context_mask\n",
    "        )  # [batch_size, ctx_seq_len]\n",
    "        return start_scores, end_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x575iXlz3w4m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Training routines***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "31k5BZf43uV4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    # TODO\n",
    "    #  Add typing\n",
    "\n",
    "    def __init__(self, keys: List[str]):\n",
    "        self.keys = keys\n",
    "        self.value = {key: 0. for key in keys}\n",
    "        self.sum = {key: 0. for key in keys}\n",
    "        self.count = {key: 0. for key in keys}\n",
    "        self.average = {key: 0. for key in keys}\n",
    "\n",
    "    def reset(self):\n",
    "        self.value = {key: 0. for key in self.keys}\n",
    "        self.sum = {key: 0. for key in self.keys}\n",
    "        self.count = {key: 0. for key in self.keys}\n",
    "        self.average = {key: 0. for key in self.keys}\n",
    "\n",
    "    def update(self, key: str, value: float, n: int = 1):\n",
    "        self.value[key] = value\n",
    "        self.sum[key] += value * n\n",
    "        self.count[key] += n\n",
    "        self.average[key] = self.sum[key] / self.count[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "qSmh2GmU4KXH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(answer: str) -> str:\n",
    "    \"\"\"Performs a series of cleaning steps on the ground truth and predicted answer.\"\"\"\n",
    "\n",
    "    def remove_articles(text: str) -> str:\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text: str) -> str:\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text: str) -> str:\n",
    "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "\n",
    "    def lower(text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(answer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "hi2JHYTX6F6A",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(prediction: str, ground_truth: str) -> Tuple[float, float]:\n",
    "    prediction, ground_truth = normalize(prediction), normalize(ground_truth)\n",
    "    prediction_tokens, ground_truth_tokens = prediction.split(), ground_truth.split()\n",
    "\n",
    "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
    "    number_same = sum(common.values())\n",
    "    f1_score = 0\n",
    "    if number_same != 0:\n",
    "        precision = 1.0 * number_same / len(prediction_tokens)\n",
    "        recall = 1.0 * number_same / len(ground_truth_tokens)\n",
    "        f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return prediction == ground_truth, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "tv9kxaI34_Oo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def max_metrics_over_ground_truths(prediction: str, ground_truths: List[str]) -> Tuple[float, float]:\n",
    "    scores = [get_scores(prediction, ground_truth) for ground_truth in ground_truths]\n",
    "    em_score = max(scores, key=lambda score: score[0])[0]\n",
    "    f1_score = max(scores, key=lambda score: score[1])[1]\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "KmxMG01B5JEx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(predictions: Dict[str, str], qas: List[RawDatasetItem]) -> Tuple[float, float]:\n",
    "    ground_truths = collections.defaultdict(lambda: [])\n",
    "    for qa in qas:\n",
    "        if qa.id_ in predictions:\n",
    "            ground_truths[qa.id_].append(qa.answer.text)\n",
    "\n",
    "    em_scores, f1_scores, total = [], [], 0\n",
    "    for id_ in predictions:\n",
    "        em_score, f1_score = max_metrics_over_ground_truths(predictions[id_], ground_truths[id_])\n",
    "        em_scores.append(em_score)\n",
    "        f1_scores.append(f1_score)\n",
    "        total += 1\n",
    "\n",
    "    em_score = 100.0 * sum(em_scores) / total\n",
    "    f1_score = 100.0 * sum(f1_scores) / total\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "GHUdYB6f-NRJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model: nn.Module, optimizer: optim.Optimizer, criterion: nn.Module, id_vocab: Vocabulary,\n",
    "                 text_vocab: Vocabulary, model_path: str):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.id_vocab = id_vocab\n",
    "        self.text_vocab = text_vocab\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def get_predictions(self, batch: DrQATensorDatasetBatch, starts: Tensor, ends: Tensor) -> Dict[str, str]:\n",
    "        start_indexes, end_indexes, _ = self.model.decode(\n",
    "            starts=F.softmax(starts, dim=-1),\n",
    "            ends=F.softmax(ends, dim=-1)\n",
    "        )\n",
    "\n",
    "        predictions = {}\n",
    "        for index in range(len(start_indexes)):\n",
    "            id_ = self.id_vocab.itos(batch.id_[index].item())\n",
    "            prediction = batch.context[0][index][start_indexes[index]:end_indexes[index] + 1]\n",
    "            predictions[id_] = ' '.join([self.text_vocab.itos(ind.item()) for ind in prediction])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def compute_metrics_and_update_tracker(self, batch: DrQATensorDatasetBatch, starts: Tensor, ends: Tensor,\n",
    "                                           tracker: AverageMeter, loader: DataLoader) -> None:\n",
    "        # TODO\n",
    "        #   Make batch type general not specific since the trainer will be use for different types of models\n",
    "        predictions = self.get_predictions(batch=batch, starts=starts, ends=ends)\n",
    "        em, f1 = metrics(predictions=predictions, qas=loader.dataset.data)\n",
    "\n",
    "        tracker.update(key=\"em\", value=em)\n",
    "        tracker.update(key=\"f1\", value=f1)\n",
    "\n",
    "    def train_step(self, loader: DataLoader, epoch: int, gradient_clipping: float) -> AverageMeter:\n",
    "        tracker = AverageMeter(keys=[\"loss\", \"em\", \"f1\"])\n",
    "        self.model.train()\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for index, batch in pbar:  # type: int, DrQATensorDatasetBatch\n",
    "            self.optimizer.zero_grad()\n",
    "            starts, ends = self.model(batch)  # [batch_size, ctx_len]\n",
    "            loss = self.criterion(starts, batch.target[:, 0]) + self.criterion(ends, batch.target[:, 1])\n",
    "            loss.backward()\n",
    "            if gradient_clipping is not None:\n",
    "                nn.utils.clip_grad_norm_(parameters=self.model.parameters(), max_norm=gradient_clipping)\n",
    "            self.optimizer.step()\n",
    "            tracker.update(key=\"loss\", value=loss.item())\n",
    "            self.compute_metrics_and_update_tracker(\n",
    "                batch=batch,\n",
    "                starts=starts,\n",
    "                ends=ends,\n",
    "                tracker=tracker,\n",
    "                loader=loader\n",
    "            )\n",
    "            pbar.set_description(\n",
    "                f\"Epoch: {epoch + 1:03d} |       loss: {tracker.average['loss']:6.3f} |       \"\n",
    "                f\"em: {tracker.average['em']:6.3f} |       f1: {tracker.average['f1']:6.3f}\"\n",
    "            )\n",
    "            break\n",
    "        return tracker\n",
    "\n",
    "    def validate(self, loader: DataLoader) -> AverageMeter:\n",
    "        tracker = AverageMeter(keys=[\"loss\", \"em\", \"f1\"])\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "            for _, batch in pbar:  # type: int, DrQATensorDatasetBatch\n",
    "                starts, ends = self.model(batch)  # [batch_size, ctx_len]\n",
    "                loss = self.criterion(starts, batch.target[:, 0]) + self.criterion(ends, batch.target[:, 1])\n",
    "                tracker.update(key=\"loss\", value=loss.item())\n",
    "                self.compute_metrics_and_update_tracker(\n",
    "                    batch=batch,\n",
    "                    starts=starts,\n",
    "                    ends=ends,\n",
    "                    tracker=tracker,\n",
    "                    loader=loader\n",
    "                )\n",
    "                pbar.set_description(\n",
    "                    f\"           | valid_loss: {tracker.average['loss']:6.3f} | valid_em: {tracker.average['em']:6.3f} \"\n",
    "                    f\"| valid_f1: {tracker.average['f1']:6.3f}\"\n",
    "                )\n",
    "                break\n",
    "        return tracker\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_loader: DataLoader, n_epochs: int, gradient_clipping: float) \\\n",
    "            -> Dict[str, List[float]]:\n",
    "        history = {\n",
    "            \"loss\": [], \"valid_loss\": [],\n",
    "            \"em\": [], \"valid_em\": [],\n",
    "            \"f1\": [], \"valid_f1\": []\n",
    "        }\n",
    "        # best_loss = float('inf')\n",
    "        for epoch in range(n_epochs):\n",
    "            print(\n",
    "                \"|----------------------------------------------------------------------------------------------------\"\n",
    "                \"---------|\"\n",
    "            )\n",
    "            train_tracker = self.train_step(loader=train_loader, epoch=epoch, gradient_clipping=gradient_clipping)\n",
    "            valid_tracker = self.validate(loader=valid_loader)\n",
    "\n",
    "            history[\"loss\"].append(train_tracker.average[\"loss\"])\n",
    "            history[\"valid_loss\"].append(valid_tracker.average[\"loss\"])\n",
    "            history[\"em\"].append(train_tracker.average[\"em\"])\n",
    "            history[\"valid_em\"].append(valid_tracker.average[\"loss\"])\n",
    "            history[\"f1\"].append(train_tracker.average[\"f1\"])\n",
    "            history[\"valid_f1\"].append(valid_tracker.average[\"f1\"])\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFzM-vWUAov9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Train the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "-YCmJQLhAlqo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_LAYERS = 1\n",
    "EMBED_SIZE = 300\n",
    "HIDDEN_SIZE = 64\n",
    "DROPOUT = 0.\n",
    "N_EPOCHS = 100\n",
    "GRAD_CLIP = None\n",
    "LEARNING_RATE = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ersGVmFxBwAV",
    "outputId": "f5c11bc4-a4bb-49cb-8fc1-c472323ec253",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 8,527,132\n",
      "DrQA(\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (embedding_layer): Embedding(26884, 300, padding_idx=0)\n",
      "  (aligned_question_embedding_layer): AlignedQuestionEmbeddingLayer(\n",
      "    (dense): Linear(in_features=300, out_features=64, bias=True)\n",
      "  )\n",
      "  (context_lstm_layer): StackedBiLSTMsLayer(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (lstm_layers): ModuleList(\n",
      "      (0): LSTM(368, 64, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (question_encoding_layer): QuestionEncodingLayer(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (stacked_bilstm_layers): StackedBiLSTMsLayer(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (lstm_layers): ModuleList(\n",
      "        (0): LSTM(300, 64, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "    (dense): Linear(in_features=300, out_features=1, bias=False)\n",
      "  )\n",
      "  (bilinear_attention_start_layer): BiLinearAttentionLayer(\n",
      "    (dense): Linear(in_features=128, out_features=128, bias=False)\n",
      "  )\n",
      "  (bilinear_attention_end_layer): BiLinearAttentionLayer(\n",
      "    (dense): Linear(in_features=128, out_features=128, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "padding_token_index = text_vocabulary.stoi(word=text_vocabulary.padding_token)\n",
    "model = DrQA(\n",
    "    vocabulary_size=len(text_vocabulary),\n",
    "    embedding_size=EMBED_SIZE,\n",
    "    n_extra_features=4,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    padding_index=padding_token_index\n",
    ")\n",
    "model.load_word_embeddings(embedding_matrix=embedding_matrix, tune=True, found_indexes=found_indexes)\n",
    "model.to(DEVICE)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=padding_token_index)\n",
    "print(f'Number of parameters of the model: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "print(model)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    id_vocab=id_vocabulary,\n",
    "    text_vocab=text_vocabulary,\n",
    "    model_path=\"./checkpoints/drqa.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giP1Ov5_DTGr",
    "outputId": "aa776c3f-80f1-4c9f-9abb-37e38eb2841c",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001 |       loss: 10.030 |       em:  0.000 |       f1:  3.692:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.910 | valid_em:  0.000 | valid_f1:  0.575:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 002 |       loss:  9.963 |       em:  0.000 |       f1:  8.128:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.885 | valid_em:  0.000 | valid_f1:  2.598:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 003 |       loss:  9.897 |       em:  0.000 |       f1:  7.515:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.861 | valid_em:  0.000 | valid_f1:  7.310:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 004 |       loss:  9.832 |       em:  0.000 |       f1:  8.944:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.838 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 005 |       loss:  9.767 |       em:  3.125 |       f1: 11.314:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.815 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 006 |       loss:  9.700 |       em:  3.125 |       f1: 13.709:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.793 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 007 |       loss:  9.631 |       em:  3.125 |       f1: 13.285:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.770 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 008 |       loss:  9.559 |       em:  3.125 |       f1: 13.584:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.748 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 009 |       loss:  9.485 |       em:  0.000 |       f1: 11.436:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.726 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 010 |       loss:  9.406 |       em:  0.000 |       f1: 10.279:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.704 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 011 |       loss:  9.324 |       em:  0.000 |       f1: 10.762:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.683 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 012 |       loss:  9.237 |       em:  0.000 |       f1: 10.059:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.661 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 013 |       loss:  9.145 |       em:  0.000 |       f1: 10.236:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.639 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 014 |       loss:  9.048 |       em:  0.000 |       f1: 10.820:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.618 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 015 |       loss:  8.945 |       em:  0.000 |       f1: 10.820:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.597 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 016 |       loss:  8.836 |       em:  0.000 |       f1:  9.211:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.577 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 017 |       loss:  8.720 |       em:  0.000 |       f1:  9.211:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.557 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 018 |       loss:  8.597 |       em:  0.000 |       f1:  9.906:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.537 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 019 |       loss:  8.466 |       em:  0.000 |       f1: 11.312:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.518 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 020 |       loss:  8.325 |       em:  0.000 |       f1: 11.312:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.498 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 021 |       loss:  8.175 |       em:  0.000 |       f1: 12.326:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.478 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 022 |       loss:  8.015 |       em:  0.000 |       f1: 12.683:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.457 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 023 |       loss:  7.844 |       em:  0.000 |       f1: 12.683:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.435 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 024 |       loss:  7.664 |       em:  3.125 |       f1: 17.967:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.411 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 025 |       loss:  7.477 |       em:  3.125 |       f1: 17.273:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.385 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 026 |       loss:  7.285 |       em:  6.250 |       f1: 15.509:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.357 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 027 |       loss:  7.094 |       em:  6.250 |       f1: 16.299:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.326 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 028 |       loss:  6.910 |       em:  6.250 |       f1: 16.002:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.294 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 029 |       loss:  6.739 |       em:  6.250 |       f1: 15.220:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.260 | valid_em:  0.000 | valid_f1:  5.556:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 030 |       loss:  6.583 |       em:  6.250 |       f1: 15.252:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.226 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 031 |       loss:  6.437 |       em:  6.250 |       f1: 15.252:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.194 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 032 |       loss:  6.293 |       em:  9.375 |       f1: 18.377:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.164 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 033 |       loss:  6.142 |       em:  6.250 |       f1: 14.153:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.140 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 034 |       loss:  5.978 |       em:  9.375 |       f1: 17.006:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.122 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 035 |       loss:  5.802 |       em:  9.375 |       f1: 17.304:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.113 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 036 |       loss:  5.618 |       em:  9.375 |       f1: 20.160:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.115 | valid_em:  0.000 | valid_f1:  0.000:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 037 |       loss:  5.432 |       em: 12.500 |       f1: 20.164:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.126 | valid_em:  0.000 | valid_f1:  1.282:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 038 |       loss:  5.248 |       em: 12.500 |       f1: 19.167:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.147 | valid_em:  0.000 | valid_f1:  1.282:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 039 |       loss:  5.069 |       em: 15.625 |       f1: 21.968:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.179 | valid_em:  0.000 | valid_f1:  1.282:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 040 |       loss:  4.895 |       em: 12.500 |       f1: 19.208:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.218 | valid_em:  0.000 | valid_f1:  1.282:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 041 |       loss:  4.724 |       em: 12.500 |       f1: 18.513:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.266 | valid_em:  0.000 | valid_f1:  2.564:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 042 |       loss:  4.551 |       em: 12.500 |       f1: 18.295:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.322 | valid_em:  0.000 | valid_f1:  2.564:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 043 |       loss:  4.372 |       em: 12.500 |       f1: 17.993:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.386 | valid_em:  0.000 | valid_f1:  2.564:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 044 |       loss:  4.183 |       em: 12.500 |       f1: 17.993:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.460 | valid_em:  0.000 | valid_f1:  2.564:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 045 |       loss:  3.987 |       em: 15.625 |       f1: 21.220:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.544 | valid_em:  0.000 | valid_f1:  2.564:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 046 |       loss:  3.789 |       em: 18.750 |       f1: 24.345:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.639 | valid_em:  0.000 | valid_f1:  2.262:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 047 |       loss:  3.594 |       em: 21.875 |       f1: 27.470:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.745 | valid_em:  0.000 | valid_f1:  3.224:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 048 |       loss:  3.404 |       em: 21.875 |       f1: 27.470:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.858 | valid_em:  0.000 | valid_f1:  1.942:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 049 |       loss:  3.215 |       em: 18.750 |       f1: 24.768:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss:  9.975 | valid_em:  0.000 | valid_f1:  0.980:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 050 |       loss:  3.023 |       em: 31.250 |       f1: 37.806:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.096 | valid_em:  0.000 | valid_f1:  0.980:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 051 |       loss:  2.826 |       em: 34.375 |       f1: 41.536:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.223 | valid_em:  0.000 | valid_f1:  0.980:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 052 |       loss:  2.630 |       em: 34.375 |       f1: 41.076:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.355 | valid_em:  0.000 | valid_f1:  2.262:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 053 |       loss:  2.439 |       em: 37.500 |       f1: 45.002:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.493 | valid_em:  0.000 | valid_f1:  3.544:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 054 |       loss:  2.253 |       em: 40.625 |       f1: 48.127:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.634 | valid_em:  0.000 | valid_f1:  3.544:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 055 |       loss:  2.067 |       em: 50.000 |       f1: 58.908:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.779 | valid_em:  0.000 | valid_f1:  3.544:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 056 |       loss:  1.881 |       em: 56.250 |       f1: 64.430:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 10.942 | valid_em:  0.000 | valid_f1:  3.544:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 057 |       loss:  1.698 |       em: 62.500 |       f1: 70.930:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.122 | valid_em:  0.000 | valid_f1:  2.589:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 058 |       loss:  1.530 |       em: 68.750 |       f1: 79.938:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.320 | valid_em:  0.000 | valid_f1:  5.801:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 059 |       loss:  1.375 |       em: 75.000 |       f1: 85.820:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.526 | valid_em:  0.000 | valid_f1:  4.820:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 060 |       loss:  1.228 |       em: 75.000 |       f1: 85.820:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.723 | valid_em:  0.000 | valid_f1:  4.820:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 061 |       loss:  1.084 |       em: 75.000 |       f1: 85.907:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 11.922 | valid_em:  0.000 | valid_f1:  4.820:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 062 |       loss:  0.943 |       em: 78.125 |       f1: 89.334:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.113 | valid_em:  0.000 | valid_f1:  4.820:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 063 |       loss:  0.828 |       em: 81.250 |       f1: 91.070:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.306 | valid_em:  0.000 | valid_f1:  4.820:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 064 |       loss:  0.773 |       em: 75.000 |       f1: 85.138:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.477 | valid_em:  0.000 | valid_f1:  4.820:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 065 |       loss:  0.635 |       em: 84.375 |       f1: 93.911:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.680 | valid_em:  0.000 | valid_f1:  4.493:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 066 |       loss:  0.589 |       em: 84.375 |       f1: 93.911:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 12.904 | valid_em:  0.000 | valid_f1:  4.493:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 067 |       loss:  0.491 |       em: 84.375 |       f1: 93.911:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.087 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 068 |       loss:  0.449 |       em: 84.375 |       f1: 93.911:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.245 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 069 |       loss:  0.381 |       em: 84.375 |       f1: 93.609:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.393 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 070 |       loss:  0.329 |       em: 81.250 |       f1: 91.786:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.535 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 071 |       loss:  0.300 |       em: 81.250 |       f1: 91.786:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.683 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 072 |       loss:  0.263 |       em: 84.375 |       f1: 93.824:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 13.847 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 073 |       loss:  0.229 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.036 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 074 |       loss:  0.205 |       em: 84.375 |       f1: 92.522:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.226 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 075 |       loss:  0.181 |       em: 84.375 |       f1: 92.522:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.370 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 076 |       loss:  0.163 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.455 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 077 |       loss:  0.143 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.526 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 078 |       loss:  0.130 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.643 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 079 |       loss:  0.117 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.797 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 080 |       loss:  0.102 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 14.953 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 081 |       loss:  0.091 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.084 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 082 |       loss:  0.080 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.200 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 083 |       loss:  0.072 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.280 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 084 |       loss:  0.064 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.336 | valid_em:  0.000 | valid_f1:  4.167:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 085 |       loss:  0.054 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.391 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 086 |       loss:  0.048 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.464 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 087 |       loss:  0.042 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.530 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 088 |       loss:  0.036 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.588 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 089 |       loss:  0.031 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.649 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 090 |       loss:  0.027 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.724 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 091 |       loss:  0.023 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.806 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 092 |       loss:  0.020 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.885 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 093 |       loss:  0.018 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 15.951 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 094 |       loss:  0.016 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.010 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 095 |       loss:  0.015 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.062 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 096 |       loss:  0.014 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.108 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 097 |       loss:  0.012 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.145 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 098 |       loss:  0.011 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.177 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 099 |       loss:  0.011 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.204 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------------------------------------------------------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100 |       loss:  0.010 |       em: 87.500 |       f1: 95.647:   0%|          | 0/2709 [00:00<?, ?it/s]\n",
      "           | valid_loss: 16.227 | valid_em:  0.000 | valid_f1:  2.778:   0%|          | 0/1074 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./checkpoints\n",
    "history = trainer.train(\n",
    "    train_loader=train_dataloader,\n",
    "    valid_loader=valid_dataloader,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    gradient_clipping=GRAD_CLIP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "8C-bSJpY-qZM",
    "outputId": "db26fdee-279c-4fe8-b5d6-7f26a8587271",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['valid_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['em'], label='train')\n",
    "axes[1].plot(history['valid_em'], label='valid')\n",
    "axes[1].set_title('Exact match history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Exact match (%)')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(history['f1'], label='train')\n",
    "axes[2].plot(history['valid_f1'], label='valid')\n",
    "axes[2].set_title('F1 history')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 (%)')\n",
    "axes[2].grid(True)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_99dtAVn5CL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Inference***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk9dSwSR_OM9",
    "outputId": "dfc3f33a-a716-44fd-ae2d-3ce5fdaa745f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"./checkpoints/drqa.pth\"))\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "p1CVgakLDtsU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def inference(model: nn.Module, context: spacy.tokens.doc.Doc, question: spacy.tokens.doc.Doc,\n",
    "              text_vocab: Vocabulary, pos_vocab: Vocabulary, ner_vocab: Vocabulary, device: torch.device):\n",
    "    # Build extra features\n",
    "    question = [token.text.lower() for token in question]\n",
    "    counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
    "    freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
    "    freqs_norm = sum(freqs.values())\n",
    "    em, pos, ner, ntf = zip(\n",
    "        *map(lambda index: [\n",
    "            context[index].text.lower() in question, context[index].tag_,\n",
    "            context[index].ent_type_ or 'None',\n",
    "            freqs[index] / freqs_norm\n",
    "        ], range(len(context)))\n",
    "    )\n",
    "\n",
    "    # Build tensors\n",
    "    batch = DrQATensorDatasetBatch(\n",
    "        id_=None,\n",
    "        context=(\n",
    "            torch.LongTensor([*map(lambda word: text_vocab.stoi(word), context)]).unsqueeze(0).to(device),\n",
    "            torch.LongTensor([len(context)])\n",
    "        ), question=(\n",
    "            torch.LongTensor([*map(lambda word: text_vocab.stoi(word), question)]).unsqueeze(0).to(device),\n",
    "            torch.LongTensor([len(question)])\n",
    "        ), target=None,\n",
    "        exact_match=torch.LongTensor(em).unsqueeze(0).to(device),\n",
    "        part_of_speech=torch.LongTensor([*map(lambda x: pos_vocab.stoi(x), pos)]).unsqueeze(0).to(device),\n",
    "        named_entity_type=torch.LongTensor([*map(lambda x: ner_vocab.stoi(x), ner)]).unsqueeze(0).to(device),\n",
    "        normalized_term_frequency=torch.LongTensor(ntf).unsqueeze(0).to(device)\n",
    "    )\n",
    "\n",
    "    # Prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Feed the model\n",
    "        start, end = model(batch)\n",
    "    \n",
    "        # Decode the result indexes\n",
    "        start_index, end_index, proba = model.decode(starts=F.softmax(start, dim=-1), ends=F.softmax(end, dim=-1))\n",
    "        print(start_index, end_index)\n",
    "\n",
    "        # Extract the answer\n",
    "        answer = context[start_index[0]:end_index[0] + 1]\n",
    "\n",
    "    return answer, proba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dI-ME2Q1-WzB",
    "outputId": "7ddd80ef-e885-476d-a8e7-32e1a031417b",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195] [122]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Larger drugs (>500 Da) can provoke a neutralizing immune response, particularly if the drugs are administered repeatedly, or in larger doses. This limits the effectiveness of drugs based on larger peptides and proteins (which are typically larger than 6000 Da). In some cases, the drug itself is not immunogenic, but may be co-administered with an immunogenic compound, as is sometimes the case for Taxol. Computational methods have been developed to predict the immunogenicity of peptides and proteins, which are particularly useful in designing therapeutic antibodies, assessing likely virulence of mutations in viral coat particles, and validation of proposed peptide-based drug treatments. Early techniques relied mainly on the observation that hydrophilic amino acids are overrepresented in epitope regions than hydrophobic amino acids; however, more recent developments rely on machine learning techniques using databases of existing known epitopes, usually on well-studied virus proteins, as a training set. A publicly accessible database has been established for the cataloguing of epitopes from pathogens known to be recognizable by B cells. The emerging field of bioinformatics-based studies of immunogenicity is referred to as immunoinformatics. Immunoproteomics is the study of large sets of proteins (proteomics) involved in the immune response.</span><br /><span><b>Question:</b> At what size and larger can drugs elicit a neutralizing immune response?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">>500 Da</li><li style=\"color:blue\">>500 Da</li><li style=\"color:blue\">>500 Da</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 0.005%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[126] [154]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Ctenophores may be abundant during the summer months in some coastal locations, but in other places they are uncommon and difficult to find. In bays where they occur in very high numbers, predation by ctenophores may control the populations of small zooplanktonic organisms such as copepods, which might otherwise wipe out the phytoplankton (planktonic plants), which are a vital part of marine food chains. One ctenophore, Mnemiopsis, has accidentally been introduced into the Black Sea, where it is blamed for causing fish stocks to collapse by eating both fish larvae and organisms that would otherwise have fed the fish. The situation was aggravated by other factors, such as over-fishing and long-term environmental changes that promoted the growth of the Mnemiopsis population. The later accidental introduction of Beroe helped to mitigate the problem, as Beroe preys on other ctenophores.</span><br /><span><b>Question:</b> Where do ctenophores be found in large numbers?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">In bays</li><li style=\"color:blue\">bays</li><li style=\"color:blue\">bays</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=-term environmental changes that promoted the growth of the Mnemiopsis population. The later accidental introduction of Beroe helped to mitigate the problem, as Beroe preys on=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.012%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[73] [84]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The Mongol Empire was governed by a civilian and military code, called the Yassa, created by Genghis Khan. The Mongol Empire did not emphasize the importance of ethnicity and race in the administrative realm, instead adopting an approach grounded in meritocracy. The exception was the role of Genghis Khan and his family. The Mongol Empire was one of the most ethnically and culturally diverse empires in history, as befitted its size. Many of the empire's nomadic inhabitants considered themselves Mongols in military and civilian life, including Mongols, Turks and others and included many diverse Khans of various ethnicities as part of the Mongol Empire such as Muhammad Khan.</span><br /><span><b>Question:</b> Who was exempt from the meritocratic principles of the Mongol Empire?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Genghis Khan and his family</li><li style=\"color:blue\">Genghis Khan and his family</li><li style=\"color:blue\">Genghis Khan and his family</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=, as befitted its size. Many of the empire's nomadic=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.070%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[9] [22]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Newcastle has three cathedrals, the Anglican St. Nicholas, with its elegant lantern tower of 1474, the Roman Catholic St. Mary's designed by Augustus Welby Pugin and the Coptic Cathedral located in Fenham. All three cathedrals began their lives as parish churches. St Mary's became a cathedral in 1850 and St Nicholas' in 1882. Another prominent church in the city centre is the Church of St Thomas the Martyr which is the only parish church in the Church of England without a parish and which is not a peculiar.</span><br /><span><b>Question:</b> What year was St. Nicholas' lantern tower made?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">1474</li><li style=\"color:blue\">1474</li><li style=\"color:blue\">1474</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=, with its elegant lantern tower of 1474, the Roman Catholic St. Mary=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.021%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[17] [17]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Through combining the definition of electric current as the time rate of change of electric charge, a rule of vector multiplication called Lorentz's Law describes the force on a charge moving in a magnetic field. The connection between electricity and magnetism allows for the description of a unified electromagnetic force that acts on a charge. This force can be written as a sum of the electrostatic force (due to the electric field) and the magnetic force (due to the magnetic field). Fully stated, this is the law:</span><br /><span><b>Question:</b> What magnetic and electric force acts on a charge?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">unified electromagnetic</li><li style=\"color:blue\">unified electromagnetic force</li><li style=\"color:blue\">electromagnetic</li><li style=\"color:blue\">unified electromagnetic force</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=a=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.017%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[203] [154]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> However, a problem emerged regarding the directions taken by ABC and UPT. In 1950, Noble appointed Robert Kintner to be ABC's president while he himself served as its CEO, a position he would hold until his death in 1958. Despite the promise of non-interference between ABC and UPT, Goldenson had to intervene in ABC's decisions because of financial problems and the FCC's long period of indecision. Goldenson added to the confusion when, in October 1954, he proposed a merger between UPT and the DuMont Television Network, which was also mired in financial trouble. As part of this merger, the network would have been renamed \"ABC-DuMont\" for five years, and DuMont would have received $5 million in cash, room on the schedule for existing DuMont programming, and guaranteed advertising time for DuMont Laboratories receivers. In addition, to comply with FCC ownership restrictions, it would have been required to sell either WABC-TV or DuMont owned-and-operated station WABD in the New York City market, as well as two other stations. The merged ABC-DuMont would have had the resources to compete with CBS and NBC.</span><br /><span><b>Question:</b> Goldenson proposed a merger between UPT and what network in October 1954?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">DuMont Television Network</li><li style=\"color:blue\">DuMont Television Network</li><li style=\"color:blue\">DuMont Television Network</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 0.008%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[80] [109]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Luther's Commentary on Genesis contains a passage which concludes that \"the soul does not sleep (anima non sic dormit), but wakes (sed vigilat) and experiences visions\". Francis Blackburne in 1765 argued that John Jortin misread this and other passages from Luther, while Gottfried Fritschel pointed out in 1867 that it actually refers to the soul of a man \"in this life\" (homo enim in hac vita) tired from his daily labour (defatigus diurno labore) who at night enters his bedchamber (sub noctem intrat in cubiculum suum) and whose sleep is interrupted by dreams.</span><br /><span><b>Question:</b> Who stated that John Jortin misunderstood Luther?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Francis Blackburne</li><li style=\"color:blue\">Francis Blackburne</li><li style=\"color:blue\">Blackburne</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=tired from his daily labour (defatigus diurno labore) who at night enters his bedchamber (sub noctem intrat in cubiculum suum) and whose sleep is interrupted by=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.026%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[0] [75]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The Mallee and upper Wimmera are Victoria's warmest regions with hot winds blowing from nearby semi-deserts. Average temperatures exceed 32 °C (90 °F) during summer and 15 °C (59 °F) in winter. Except at cool mountain elevations, the inland monthly temperatures are 2–7 °C (4–13 °F) warmer than around Melbourne (see chart). Victoria's highest maximum temperature since World War II, of 48.8 °C (119.8 °F) was recorded in Hopetoun on 7 February 2009, during the 2009 southeastern Australia heat wave.</span><br /><span><b>Question:</b> What is Victoria's highest monthly temperature?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">48.8 °C</li><li style=\"color:blue\">48.8 °C</li><li style=\"color:blue\">48.8 °C (119.8 °F)</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=The Mallee and upper Wimmera are Victoria's warmest regions with hot winds blowing from nearby semi-deserts. Average temperatures exceed 32 °C (90 °F) during summer and 15 °C (59 °F) in winter. Except at cool mountain elevations, the inland monthly temperatures are 2–7 °C (4–13 °F) warmer than around Melbourne (see chart). Victoria's highest=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.027%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[3] [125]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The sculpture collection at the V&A is the most comprehensive holding of post-classical European sculpture in the world. There are approximately 22,000 objects in the collection that cover the period from about 400 AD to 1914. This covers among other periods Byzantine and Anglo Saxon ivory sculptures, British, French and Spanish medieval statues and carvings, the Renaissance, Baroque, Neo-Classical, Victorian and Art Nouveau periods. All uses of sculpture are represented, from tomb and memorial, to portrait, allegorical, religious, mythical, statues for gardens including fountains, as well as architectural decorations. Materials used include, marble, alabaster, stone, terracotta, wood (history of wood carving), ivory, gesso, plaster, bronze, lead and ceramics.</span><br /><span><b>Question:</b> Approximately how many objects are in the V&A sculpture collection?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">22,000</li><li style=\"color:blue\">22,000 objects</li><li style=\"color:blue\">22,000</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=at the V&A is the most comprehensive holding of post-classical European sculpture in the world. There are approximately 22,000 objects in the collection that cover the period from about 400 AD to 1914. This covers among other periods Byzantine and Anglo Saxon ivory sculptures, British, French and Spanish medieval statues and carvings, the Renaissance, Baroque, Neo-Classical, Victorian and Art Nouveau periods. All uses of sculpture are represented, from tomb and memorial, to portrait, allegorical, religious, mythical, statues for gardens including fountains, as well as architectural decorations. Materials used include, marble, alabaster, stone, terracotta, wood (history of=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.016%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[8] [106]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> After an unmanned LM test flight AS-206, a crew would fly the first Block II CSM and LM in a dual mission known as AS-207/208, or AS-278 (each spacecraft would be launched on a separate Saturn IB.) The Block II crew positions were titled Commander (CDR) Command Module Pilot (CMP) and Lunar Module Pilot (LMP). The astronauts would begin wearing a new Apollo spacesuit, designed to accommodate lunar extravehicular activity (EVA). The traditional visor helmet was replaced with a clear \"fishbowl\" type for greater visibility, and the lunar surface EVA suit would include a water-cooled undergarment.</span><br /><span><b>Question:</b> What did the LMP acronym stand for regarding the Block II launch positions?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Lunar Module Pilot</li><li style=\"color:blue\">Lunar Module Pilot</li><li style=\"color:blue\">Lunar Module Pilot</li><li style=\"color:blue\">Lunar Module Pilot</li><li style=\"color:blue\">Lunar Module Pilot</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=a crew would fly the first Block II CSM and LM in a dual mission known as AS-207/208, or AS-278 (each spacecraft would be launched on a separate Saturn IB.) The Block II crew positions were titled Commander (CDR) Command Module Pilot (CMP) and Lunar Module Pilot (LMP). The astronauts would begin wearing a new Apollo spacesuit, designed to accommodate lunar extravehicular activity (EVA). The traditional visor helmet was replaced with a clear \"fishbowl\" type for greater visibility, and the lunar=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.025%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[0] [84]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Some of the oldest schools in South Africa are private church schools that were established by missionaries in the early nineteenth century. The private sector has grown ever since. After the abolition of apartheid, the laws governing private education in South Africa changed significantly. The South African Schools Act of 1996 recognises two categories of schools: \"public\" (state-controlled) and \"independent\" (which includes traditional private schools and schools which are privately governed[clarification needed].)</span><br /><span><b>Question:</b> What South African law recognized two types of schools?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">South African Schools Act</li><li style=\"color:blue\">South African Schools Act</li><li style=\"color:blue\">South African Schools Act</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=Some of the oldest schools in South Africa are private church schools that were established by missionaries in the early nineteenth century. The private sector has grown ever since. After the abolition of apartheid, the laws governing private education in South Africa changed significantly. The South African Schools Act of 1996 recognises two categories of schools: \"public\" (state-controlled) and \"independent\" (which includes traditional private schools and schools which are privately governed[clarification=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.287%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[36] [37]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> A B cell identifies pathogens when antibodies on its surface bind to a specific foreign antigen. This antigen/antibody complex is taken up by the B cell and processed by proteolysis into peptides. The B cell then displays these antigenic peptides on its surface MHC class II molecules. This combination of MHC and antigen attracts a matching helper T cell, which releases lymphokines and activates the B cell. As the activated B cell then begins to divide, its offspring (plasma cells) secrete millions of copies of the antibody that recognizes this antigen. These antibodies circulate in blood plasma and lymph, bind to pathogens expressing the antigen and mark them for destruction by complement activation or for uptake and destruction by phagocytes. Antibodies can also neutralize challenges directly, by binding to bacterial toxins or by interfering with the receptors that viruses and bacteria use to infect cells.</span><br /><span><b>Question:</b> What is the process by which the antigen/antibody complex is processed in to peptides?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">proteolysis</li><li style=\"color:blue\">proteolysis</li><li style=\"color:blue\">proteolysis</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=The B=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.011%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[134] [146]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> The main gallery was redesigned in 1994, the glass balustrade on the staircase and mezzanine are the work of Danny Lane, the gallery covering contemporary glass opened in 2004 and the sacred silver and stained-glass gallery in 2005. In this latter gallery stained glass is displayed alongside silverware starting in the 12th century and continuing to the present. Some of the most outstanding stained glass, dated 1243–48 comes from the Sainte-Chapelle, is displayed along with other examples in the new Medieval & Renaissance galleries. The important 13th-century glass beaker known as the Luck of Edenhall is also displayed in these galleries. Examples of British stained glass are displayed in the British Galleries. One of the most spectacular items in the collection is the chandelier by Dale Chihuly in the rotunda at the Museum's main entrance.</span><br /><span><b>Question:</b> Whose chandelier grace the rotunda at the V&A's main entrance?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Dale Chihuly</li><li style=\"color:blue\">Dale Chihuly</li><li style=\"color:blue\">Dale Chihuly</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=the collection is the chandelier by Dale Chihuly in the rotunda at the=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.013%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[38] [129]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> There is evidence that there have been significant changes in Amazon rainforest vegetation over the last 21,000 years through the Last Glacial Maximum (LGM) and subsequent deglaciation. Analyses of sediment deposits from Amazon basin paleolakes and from the Amazon Fan indicate that rainfall in the basin during the LGM was lower than for the present, and this was almost certainly associated with reduced moist tropical vegetation cover in the basin. There is debate, however, over how extensive this reduction was. Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today. This debate has proved difficult to resolve because the practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin, and both explanations are reasonably well supported by the available data.</span><br /><span><b>Question:</b> What has been analyzed to compare Amazon rainfall in the past and present?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">sediment deposits</li><li style=\"color:blue\">sediment deposits</li><li style=\"color:blue\">sediment deposits</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=and from the Amazon Fan indicate that rainfall in the basin during the LGM was lower than for the present, and this was almost certainly associated with reduced moist tropical vegetation cover in the basin. There is debate, however, over how extensive this reduction was. Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.011%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[165] [14]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b>  Seamans' establishment of an ad-hoc committee headed by his special technical assistant Nicholas E. Golovin in July 1961, to recommend a launch vehicle to be used in the Apollo program, represented a turning point in NASA's mission mode decision. This committee recognized that the chosen mode was an important part of the launch vehicle choice, and recommended in favor of a hybrid EOR-LOR mode. Its consideration of LOR —as well as Houbolt's ceaseless work— played an important role in publicizing the workability of the approach. In late 1961 and early 1962, members of the Manned Spacecraft Center began to come around to support LOR, including the newly hired deputy director of the Office of Manned Space Flight, Joseph Shea, who became a champion of LOR. The engineers at Marshall Space Flight Center (MSFC) took longer to become convinced of its merits, but their conversion was announced by Wernher von Braun at a briefing in June 1962.</span><br /><span><b>Question:</b> Who led the committee established by Seaman?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Nicholas E. Golovin</li><li style=\"color:blue\">Nicholas E. Golovin</li><li style=\"color:blue\">Nicholas E. Golovin</li><li style=\"color:blue\">Nicholas E. Golovin</li><li style=\"color:blue\">Nicholas E. Golovin</li><li style=\"color:blue\">Nicholas E. Golovin</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 0.009%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[112] [91]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> There are also several smaller freight operators and numerous tourist railways operating over lines which were once parts of a state-owned system. Victorian lines mainly use the 1,600 mm (5 ft 3 in) broad gauge. However, the interstate trunk routes, as well as a number of branch lines in the west of the state have been converted to 1,435 mm (4 ft 8 1⁄2 in) standard gauge. Two tourist railways operate over 760 mm (2 ft 6 in) narrow gauge lines, which are the remnants of five formerly government-owned lines which were built in mountainous areas.</span><br /><span><b>Question:</b> What gauge of rail lines do two tourist lines use?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">760 mm</li><li style=\"color:blue\">760 mm (2 ft 6 in) narrow gauge lines</li><li style=\"color:blue\">760 mm (2 ft 6 in) narrow gauge lines</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 0.051%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[91] [33]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Trevithick continued his own experiments using a trio of locomotives, concluding with the Catch Me Who Can in 1808. Only four years later, the successful twin-cylinder locomotive Salamanca by Matthew Murray was used by the edge railed rack and pinion Middleton Railway. In 1825 George Stephenson built the Locomotion for the Stockton and Darlington Railway. This was the first public steam railway in the world and then in 1829, he built The Rocket which was entered in and won the Rainhill Trials. The Liverpool and Manchester Railway opened in 1830 making exclusive use of steam power for both passenger and freight trains.</span><br /><span><b>Question:</b> On what railroad was Salamanca used?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Middleton Railway</li><li style=\"color:blue\">Middleton Railway</li><li style=\"color:blue\">Middleton Railway</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 0.028%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[91] [33]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Trevithick continued his own experiments using a trio of locomotives, concluding with the Catch Me Who Can in 1808. Only four years later, the successful twin-cylinder locomotive Salamanca by Matthew Murray was used by the edge railed rack and pinion Middleton Railway. In 1825 George Stephenson built the Locomotion for the Stockton and Darlington Railway. This was the first public steam railway in the world and then in 1829, he built The Rocket which was entered in and won the Rainhill Trials. The Liverpool and Manchester Railway opened in 1830 making exclusive use of steam power for both passenger and freight trains.</span><br /><span><b>Question:</b> On what railroad was Salamanca used?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Middleton Railway</li><li style=\"color:blue\">Middleton Railway</li><li style=\"color:blue\">Middleton Railway</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>==</span><br /><span style=\"color:green\"><b>Probability:</b> 0.028%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[37] [123]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Once Mutual's appeals against the FCC were rejected, RCA decided to sell NBC Blue in 1941, and gave the mandate to do so to Mark Woods. RCA converted the NBC Blue Network into an independent subsidiary, formally divorcing the operations of NBC Red and NBC Blue on January 8, 1942, with the Blue Network being referred to on-air as either \"Blue\" or \"Blue Network\". The newly separated NBC Red and NBC Blue divided their respective corporate assets. Between 1942 and 1943, Woods offered to sell the entire NBC Blue Network, a package that included leases on landlines, three pending television licenses (WJZ-TV in New York City, KGO-TV in San Francisco and WENR-TV in Chicago), 60 affiliates, four operations facilities (in New York City, Chicago, Los Angeles and Washington D.C.), contracts with actors, and the brand associated with the Blue Network. Investment firm Dillon, Read & Co. (which was later acquired by the Swiss Bank Corporation in 1997) offered $7.5 million to purchase the network, but the offer was rejected by Woods and RCA president David Sarnoff.</span><br /><span><b>Question:</b> What network was converted into an independent subsidiary by RCA in 1942?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">NBC Blue Network</li><li style=\"color:blue\">NBC Blue Network</li><li style=\"color:blue\">NBC Blue Network</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=an independent subsidiary, formally divorcing the operations of NBC Red and NBC Blue on January 8, 1942, with the Blue Network being referred to on-air as either \"Blue\" or \"Blue Network\". The newly separated NBC Red and NBC Blue divided their respective corporate assets. Between 1942 and 1943, Woods offered to sell the entire NBC Blue Network, a package that included leases on landlines, three pending television licenses (WJZ-TV in=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.004%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[58] [60]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In Germany, teachers are mainly civil servants recruited in special university classes, called Lehramtstudien (Teaching Education Studies). There are many differences between the teachers for elementary schools (Grundschule), lower secondary schools (Hauptschule), middle level secondary schools (Realschule) and higher level secondary schools (Gymnasium). Salaries for teachers depend on the civil servants' salary index scale (Bundesbesoldungsordnung).</span><br /><span><b>Question:</b> What are teachers considered to be in Germany?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">civil servants</li><li style=\"color:blue\">civil servants</li><li style=\"color:blue\">civil servants</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=. Salaries for=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.051%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[141] [164]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> A large body of mathematical work would still be valid when calling 1 a prime, but Euclid's fundamental theorem of arithmetic (mentioned above) would not hold as stated. For example, the number 15 can be factored as 3 · 5 and 1 · 3 · 5; if 1 were admitted as a prime, these two presentations would be considered different factorizations of 15 into prime numbers, so the statement of that theorem would have to be modified. Similarly, the sieve of Eratosthenes would not work correctly if 1 were considered a prime: a modified version of the sieve that considers 1 as prime would eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1. Furthermore, the prime numbers have several properties that the number 1 lacks, such as the relationship of the number to its corresponding value of Euler's totient function or the sum of divisors function.</span><br /><span><b>Question:</b> What is another function that primes have that the number 1 does not?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">Euler's totient function</li><li style=\"color:blue\">sum of divisors function</li><li style=\"color:blue\">sum of divisors function</li><li style=\"color:blue\">the sum of divisors function</li><li style=\"color:blue\">sum of divisors</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=the prime numbers have several properties that the number 1 lacks, such as the relationship of the number to its corresponding value of=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.008%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[33] [55]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> It has been claimed that the transmission of the first episode was delayed by ten minutes due to extended news coverage of the assassination of US President John F. Kennedy the previous day; whereas in fact it went out after a delay of eighty seconds. The BBC believed that many viewers had missed this introduction to a new series due to the coverage of the assassination, as well as a series of power blackouts across the country, and they broadcast it again on 30 November 1963, just before episode two.</span><br /><span><b>Question:</b> How long was the broadcast delay the first time the series premiered?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">eighty seconds</li><li style=\"color:blue\">ten minutes</li><li style=\"color:blue\">ten minutes</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=; whereas in fact it went out after a delay of eighty seconds. The BBC believed that many viewers had missed this=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.062%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[49] [98]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> In February 2010, in response to controversies regarding claims in the Fourth Assessment Report, five climate scientists – all contributing or lead IPCC report authors – wrote in the journal Nature calling for changes to the IPCC. They suggested a range of new organizational options, from tightening the selection of lead authors and contributors, to dumping it in favor of a small permanent body, or even turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC. Other recommendations included that the panel employ a full-time staff and remove government oversight from its processes to avoid political interference.</span><br /><span><b>Question:</b> How many scientists called to change the IPCC in Feb 2010?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">five</li><li style=\"color:blue\">five</li><li style=\"color:blue\">five</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=from tightening the selection of lead authors and contributors, to dumping it in favor of a small permanent body, or even turning the whole climate science assessment process into a moderated \"living\" Wikipedia-IPCC. Other recommendations included that the panel employ a full-=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.021%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[5] [103]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Tesla gained experience in telephony and electrical engineering before emigrating to the United States in 1884 to work for Thomas Edison in New York City. He soon struck out on his own with financial backers, setting up laboratories and companies to develop a range of electrical devices. His patented AC induction motor and transformer were licensed by George Westinghouse, who also hired Tesla for a short time as a consultant. His work in the formative years of electric power development was involved in a corporate alternating current/direct current \"War of Currents\" as well as various patent battles.</span><br /><span><b>Question:</b> What \"war\" was Tesla involved in?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">War of Currents</li><li style=\"color:blue\">War of Currents</li><li style=\"color:blue\">War of Currents</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=and electrical engineering before emigrating to the United States in 1884 to work for Thomas Edison in New York City. He soon struck out on his own with financial backers, setting up laboratories and companies to develop a range of electrical devices. His patented AC induction motor and transformer were licensed by George Westinghouse, who also hired Tesla for a short time as a consultant. His work in the formative years of electric power development was involved in a corporate alternating current/direct current \"War of Currents\" as well as various=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.031%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[0] [13]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><span><b>Context:</b> Environmentalists are concerned about loss of biodiversity that will result from destruction of the forest, and also about the release of the carbon contained within the vegetation, which could accelerate global warming. Amazonian evergreen forests account for about 10% of the world's terrestrial primary productivity and 10% of the carbon stores in ecosystems—of the order of 1.1 × 1011 metric tonnes of carbon. Amazonian forests are estimated to have accumulated 0.62 ± 0.37 tons of carbon per hectare per year between 1975 and 1996.</span><br /><span><b>Question:</b> The loss of biodiversity may be the result of what, according to environmentalists?</span><br /><span style=\"color:blue\"><b>Possible answers:</b><br /><ul><li style=\"color:blue\">destruction of the forest</li><li style=\"color:blue\">destruction of the forest</li><li style=\"color:blue\">destruction of the forest</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b>=Environmentalists are concerned about loss of biodiversity that will result from destruction of the=</span><br /><span style=\"color:green\"><b>Probability:</b> 0.230%</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for index in np.random.choice(len(valid_qas), size=25, replace=False):\n",
    "    id = valid_qas[index].id_\n",
    "    context = valid_qas[index].context\n",
    "    question = valid_qas[index].question\n",
    "\n",
    "    answers = []\n",
    "    for qa in valid_qas:\n",
    "        if id == qa.id_:\n",
    "            answers.append(qa.answer)\n",
    "\n",
    "    prediction, proba = inference(\n",
    "        model=model,\n",
    "        context=context,\n",
    "        question=question,\n",
    "        text_vocab=text_vocabulary,\n",
    "        pos_vocab=part_of_speech_vocabulary,\n",
    "        ner_vocab=named_entity_types_vocabulary,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    html = f'<p><span><b>Context:</b> {context.text}</span><br />'\n",
    "    html += f'<span><b>Question:</b> {question.text}</span><br />'\n",
    "    html += f'<span style=\"color:blue\"><b>Possible answers:</b><br /><ul>'\n",
    "    for answer in answers:\n",
    "        html += f'<li style=\"color:blue\">{answer.text}</li>'\n",
    "    html += '</ul></span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Prediction:</b>={prediction}=</span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Probability:</b> {proba * 100:.3f}%</span><br />'\n",
    "    display(HTML(html))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7JFJMsaEQAL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbESkBXxHvfxvShB4a49KZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1 - DrQA, Document reader Question Answering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
